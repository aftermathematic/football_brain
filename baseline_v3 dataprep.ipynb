{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = [\n",
    "    'E0', 'E1', \n",
    "    \n",
    "    #'E2', 'E3',\n",
    "    \n",
    "    'SC0', 'SC1',\n",
    "    'D1', 'D2',\n",
    "    'F1', 'F2',\n",
    "    'I1', 'I2',\n",
    "    'SP1', 'SP2',\n",
    "    'B1',\n",
    "    'G1',\n",
    "    'N1',\n",
    "    'P1',\n",
    "    'T1',\n",
    "]\n",
    "\n",
    "seasons = [\n",
    "    '2324', \n",
    "    '2223', '2122', '2021',\n",
    "    '1920', '1819', '1718', '1617',\n",
    "    '1516', '1415', '1314', '1213',\n",
    "    '1112', '1011', \n",
    "    '0910', '0809',\n",
    "    '0708', '0607', '0506', '0405',\n",
    "    '0304', '0203', '0102', '0001',\n",
    "]\n",
    "\n",
    "countries = [\n",
    "    \"ARG\", \"AUT\", \"BRA\", \"CHN\",\n",
    "    \"DNK\", \"FIN\", \"IRL\", \"JPN\",\n",
    "    \"MEX\", \"NOR\", \"POL\", \"ROU\",\n",
    "    \"RUS\", \"SWE\", \"SWZ\", \"USA\",\n",
    "]\n",
    "\n",
    "fixtures = [\n",
    "    \"fixtures\",\n",
    "    \"new_league_fixtures\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all filepaths into a list\n",
    "matches_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for season in seasons:    \n",
    "    for comp in comps:  \n",
    "        matches_files.append('data/scraped/%s/%s.csv' % (season, comp))\n",
    "        print()  # dummy line in case the line above is commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in countries:    \n",
    "    #matches_files.append('data/scraped/other/%s.csv' % (country))\n",
    "    print()  # dummy line in case the line above is commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: data/scraped/1819/SC0.csv not found\n",
      "Error: data/scraped/1819/I2.csv not found\n",
      "Error: data/scraped/0708/F2.csv not found\n",
      "Error: data/scraped/0708/SP2.csv not found\n",
      "Error: data/scraped/0708/N1.csv not found\n",
      "Error: data/scraped/0708/P1.csv not found\n",
      "Error: data/scraped/0607/T1.csv not found\n",
      "Error: data/scraped/0405/E0.csv not found\n",
      "Error: data/scraped/0405/E1.csv not found\n",
      "Error: data/scraped/0405/SC0.csv not found\n",
      "Error: data/scraped/0405/SC1.csv not found\n",
      "Error: data/scraped/0405/D2.csv not found\n",
      "Error: data/scraped/0405/I1.csv not found\n",
      "Error: data/scraped/0405/I2.csv not found\n",
      "Error: data/scraped/0405/SP1.csv not found\n",
      "Error: data/scraped/0405/B1.csv not found\n",
      "Error: data/scraped/0405/G1.csv not found\n",
      "Error: data/scraped/0405/N1.csv not found\n",
      "Error: data/scraped/0304/E0.csv not found\n",
      "Error: data/scraped/0304/SC0.csv not found\n",
      "Error: data/scraped/0304/D1.csv not found\n",
      "Error: data/scraped/0304/D2.csv not found\n",
      "Error: data/scraped/0304/F1.csv not found\n",
      "Error: data/scraped/0304/F2.csv not found\n",
      "Error: data/scraped/0304/I1.csv not found\n",
      "Error: data/scraped/0304/I2.csv not found\n",
      "Error: data/scraped/0304/SP2.csv not found\n",
      "Error: data/scraped/0304/P1.csv not found\n",
      "Error: data/scraped/0203/E1.csv not found\n",
      "Error: data/scraped/0203/SC0.csv not found\n",
      "Error: data/scraped/0203/SC1.csv not found\n",
      "Error: data/scraped/0203/D1.csv not found\n",
      "Error: data/scraped/0203/D2.csv not found\n",
      "Error: data/scraped/0203/F1.csv not found\n",
      "Error: data/scraped/0203/F2.csv not found\n",
      "Error: data/scraped/0203/I2.csv not found\n",
      "Error: data/scraped/0203/SP2.csv not found\n",
      "Error: data/scraped/0203/B1.csv not found\n",
      "Error: data/scraped/0203/N1.csv not found\n",
      "Error: data/scraped/0203/P1.csv not found\n",
      "Error: data/scraped/0203/T1.csv not found\n",
      "Error: data/scraped/0102/D1.csv not found\n",
      "Error: data/scraped/0102/D2.csv not found\n",
      "Error: data/scraped/0102/F2.csv not found\n",
      "Error: data/scraped/0102/I2.csv not found\n",
      "Error: data/scraped/0102/SP2.csv not found\n",
      "Error: data/scraped/0001/D1.csv not found\n",
      "Error: data/scraped/0001/D2.csv not found\n",
      "Data loaded: 120662 matches\n"
     ]
    }
   ],
   "source": [
    "# Load and concatenate matches data into a single DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in matches_files:\n",
    "\n",
    "    try:\n",
    "        df_temp = pd.read_csv(file)\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "    except:\n",
    "        # print an error message\n",
    "        print(f'Error: {file} not found')\n",
    "\n",
    "# print the amount of data loaded\n",
    "print(f\"Data loaded: {df.shape[0]} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns if they exist\n",
    "df.rename(columns={\n",
    "    'Country': 'Div',\n",
    "    'Home': 'HomeTeam',\n",
    "    'Away': 'AwayTeam',\n",
    "    'Res': 'FTR',\n",
    "\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>HHW</th>\n",
       "      <th>AHW</th>\n",
       "      <th>HO</th>\n",
       "      <th>AO</th>\n",
       "      <th>HBP</th>\n",
       "      <th>ABP</th>\n",
       "      <th>SYH</th>\n",
       "      <th>SYD</th>\n",
       "      <th>SYA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Luton</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>17:30</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/2023</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/2023</td>\n",
       "      <td>16:30</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E0</td>\n",
       "      <td>14/08/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E0</td>\n",
       "      <td>18/08/2023</td>\n",
       "      <td>19:45</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E0</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E0</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E0</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E0</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>17:30</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Man United</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E0</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E0</td>\n",
       "      <td>20/08/2023</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Everton</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E0</td>\n",
       "      <td>20/08/2023</td>\n",
       "      <td>16:30</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E0</td>\n",
       "      <td>21/08/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E0</td>\n",
       "      <td>25/08/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Luton</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Div        Date   Time          HomeTeam          AwayTeam  FTHG  FTAG FTR  \\\n",
       "0   E0  11/08/2023  20:00           Burnley          Man City   0.0   3.0   A   \n",
       "1   E0  12/08/2023  12:30           Arsenal     Nott'm Forest   2.0   1.0   H   \n",
       "2   E0  12/08/2023  15:00       Bournemouth          West Ham   1.0   1.0   D   \n",
       "3   E0  12/08/2023  15:00          Brighton             Luton   4.0   1.0   H   \n",
       "4   E0  12/08/2023  15:00           Everton            Fulham   0.0   1.0   A   \n",
       "5   E0  12/08/2023  15:00  Sheffield United    Crystal Palace   0.0   1.0   A   \n",
       "6   E0  12/08/2023  17:30         Newcastle       Aston Villa   5.0   1.0   H   \n",
       "7   E0  13/08/2023  14:00         Brentford         Tottenham   2.0   2.0   D   \n",
       "8   E0  13/08/2023  16:30           Chelsea         Liverpool   1.0   1.0   D   \n",
       "9   E0  14/08/2023  20:00        Man United            Wolves   1.0   0.0   H   \n",
       "10  E0  18/08/2023  19:45     Nott'm Forest  Sheffield United   2.0   1.0   H   \n",
       "11  E0  19/08/2023  15:00            Fulham         Brentford   0.0   3.0   A   \n",
       "12  E0  19/08/2023  15:00         Liverpool       Bournemouth   3.0   1.0   H   \n",
       "13  E0  19/08/2023  15:00            Wolves          Brighton   1.0   4.0   A   \n",
       "14  E0  19/08/2023  17:30         Tottenham        Man United   2.0   0.0   H   \n",
       "15  E0  19/08/2023  20:00          Man City         Newcastle   1.0   0.0   H   \n",
       "16  E0  20/08/2023  14:00       Aston Villa           Everton   4.0   0.0   H   \n",
       "17  E0  20/08/2023  16:30          West Ham           Chelsea   3.0   1.0   H   \n",
       "18  E0  21/08/2023  20:00    Crystal Palace           Arsenal   0.0   1.0   A   \n",
       "19  E0  25/08/2023  20:00           Chelsea             Luton   3.0   0.0   H   \n",
       "\n",
       "    HTHG  HTAG  ... Attendance HHW  AHW  HO  AO  HBP  ABP  SYH  SYD  SYA  \n",
       "0    0.0   2.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1    2.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2    0.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3    1.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4    0.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "5    0.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "6    2.0   1.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "7    2.0   2.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "8    1.0   1.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "9    0.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "10   1.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "11   0.0   1.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "12   2.0   1.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "13   0.0   1.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "14   0.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "15   1.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "16   2.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "17   1.0   1.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "18   0.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "19   1.0   0.0  ...        NaN NaN  NaN NaN NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[20 rows x 208 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Div' to a categorical type, a numeric representation of the division\n",
    "df['Div'] = df['Div'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'teams' is a list of team names\n",
    "teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).dropna().unique()\n",
    "teams.sort()\n",
    "\n",
    "# Creating a dictionary from team names to an incremental index number\n",
    "teams_dict = {team: index for index, team in enumerate(teams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a file\n",
    "with open('data/teams_dict.txt', 'w') as file:\n",
    "    file.write(str(teams_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique list of HomeTeam and AwayTeam names combined, and add an index to each team\n",
    "teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).dropna().unique()\n",
    "\n",
    "# Sort the teams alphabetically\n",
    "teams.sort()\n",
    "\n",
    "# Convert to an array of dictionaries\n",
    "teams = [{'team': team, 'index': index} for index, team in enumerate(teams)]\n",
    "\n",
    "df['Team_ID'] = df['HomeTeam'].map(teams_dict)\n",
    "df['Opp_ID'] = df['AwayTeam'].map(teams_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the column 'Referee' exists, convert it to a categorical type\n",
    "if 'Referee' in df.columns:\n",
    "    # Create a unique list of Referees, and add an index to each Referee\n",
    "    referees = pd.concat([df['Referee']]).unique()\n",
    "\n",
    "    # Convert to an array of dictionaries\n",
    "    referees = [{'referee': referee, 'index': index} for index, referee in enumerate(referees)]\n",
    "\n",
    "else:\n",
    "    df['Referee'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the team names to the index values in the 'teams' list\n",
    "#df['Team_ID'] = df['HomeTeam'].map({team['team']: team['index'] for team in teams})\n",
    "#df['Opp_ID'] = df['AwayTeam'].map({team['team']: team['index'] for team in teams})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the creation of a unique list of Referees and adding an index to each Referee\n",
    "referees = df['Referee'].unique()  # This should directly refer to the 'Referee' column\n",
    "\n",
    "if len(referees) > 0:\n",
    "    # Convert to a dictionary with referee names as keys and their indices as values\n",
    "    referee_dict = {referee: index for index, referee in enumerate(referees)}\n",
    "\n",
    "    # Now map the 'Referee' column to these indices\n",
    "    df['Ref_ID'] = df['Referee'].map(referee_dict)\n",
    "else:\n",
    "    # If there are no referees, create a dummy column with all zeros\n",
    "    df['Ref_ID'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_date_to_int(date_str):\n",
    "    # Split the date_str by the \"/\" character into day, month, year\n",
    "    components = date_str.split('/')\n",
    "    \n",
    "    # If split was successful but not in expected format, try splitting by absence of separator for '%d%m%Y' or '%d%m%y'\n",
    "    if len(components) == 1:\n",
    "        if len(date_str) in [6, 8]:  # Length 6 for '%d%m%y', 8 for '%d%m%Y'\n",
    "            day, month = int(date_str[:2]), int(date_str[2:4])\n",
    "            year = int(date_str[4:])\n",
    "        else:\n",
    "            return 19000101  # Return default if format does not match expected\n",
    "    else:\n",
    "        day, month = int(components[0]), int(components[1])\n",
    "        year = int(components[2])\n",
    "    \n",
    "    # Adjust the year if it was only 2 characters long\n",
    "    if year < 100:\n",
    "        year += 2000\n",
    "    \n",
    "    # Create a date variable by using the day, month, year integers\n",
    "    # Note: Direct creation of date variable skipped to avoid unnecessary complexity,\n",
    "    # directly formatting to YYYYMMDD integer format instead.\n",
    "    date_int = int(f\"{year:04d}{month:02d}{day:02d}\")\n",
    "    \n",
    "    return date_int\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'Date' is the column you want to convert\n",
    "# First, ensure the Date column is in a datetime format if it's not already\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Apply the modified function\n",
    "df['Date_temp'] = df['Date'].apply(lambda x: parse_date_to_int(x.strftime('%d/%m/%Y')) if pd.notnull(x) else 19000101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = df['Time'].fillna('00:00').str.replace(':', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [re.sub(r'[<]', '_st_', str(col)) for col in df.columns]\n",
    "df.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort df by Date_temp and Time\n",
    "df = df.sort_values(['Date_temp', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_vs_opponent_weighted(df, row, team_column):\n",
    "    # Initialize the total weighted score\n",
    "    weighted_score = 0\n",
    "    opponent_column = 'Opp_ID'\n",
    "\n",
    "    row_date_temp = row['Date'].year * 10000 + row['Date'].month * 100 + row['Date'].day\n",
    "\n",
    "    \n",
    "    # Filter the DataFrame for matches between the specified team and opponent from the same season, excluding the current match\n",
    "    filtered_matches = df[(df[team_column] == row[team_column]) & \n",
    "                          (df[opponent_column] == row[opponent_column]) &\n",
    "                          (df['Date_temp'] < row_date_temp)]\n",
    "    \n",
    "    recent_matches = filtered_matches.sort_values(by='Date', ascending=False).head(5)\n",
    "    \n",
    "    # Calculate weights - newer matches have higher weights\n",
    "    weights = range(len(recent_matches), 0, -1)  # Descending list based on the number of matches\n",
    "    \n",
    "    # Calculate score based on the match result\n",
    "    for match, weight in zip(recent_matches.itertuples(), weights):\n",
    "        if getattr(match, 'FTR') == 'H' and getattr(match, team_column) == getattr(match, 'Team_ID') or \\\n",
    "           getattr(match, 'FTR') == 'A' and getattr(match, team_column) != getattr(match, 'Team_ID'):\n",
    "            weighted_score += 3 * weight  # Team won\n",
    "        elif getattr(match, 'FTR') == 'A':\n",
    "            weighted_score += 1 * weight  # Draw\n",
    "        \n",
    "    # Normalize the weighted score by the sum of weights\n",
    "    normalized_weighted_score = weighted_score / sum(weights) if weights else 0\n",
    "\n",
    "    #print(f\"Weighted score: {weighted_score}, Normalized weighted score: {normalized_weighted_score}\")\n",
    "\n",
    "    return normalized_weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the modified function to create new columns\n",
    "df['team_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Team_ID'), axis=1)\n",
    "#df['opp_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Opp_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function adapted for DataFrame application\n",
    "def convert_odds(row):\n",
    "    odds_win, odds_draw, odds_lose = row['AvgH'], row['AvgD'], row['AvgA']\n",
    "    prob_win = 1 / odds_win\n",
    "    prob_draw = 1 / odds_draw\n",
    "    prob_lose = 1 / odds_lose\n",
    "    prob_not_win = prob_draw + prob_lose\n",
    "    return pd.Series([prob_win, prob_not_win], index=['probs_win', 'probs_not_win'])\n",
    "\n",
    "# Apply the function and create new columns\n",
    "#df[['probs_win', 'probs_not_win']] = df.apply(convert_odds, axis=1)\n",
    "\n",
    "#df = df.drop(columns=['AvgH', 'AvgD', 'AvgA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_form(df, row, perspective):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Initialize points\n",
    "    points = 0\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Calculate points with weights\n",
    "    weighted_points_sum = 0\n",
    "    total_weights = sum(weights[:len(past_matches)])  # Adjust the total weight in case of less than 5 matches\n",
    "    \n",
    "    for match, weight in zip(past_matches.itertuples(), weights):\n",
    "        if (match.Team_ID == team_id and match.FTR == 'H') or (match.Opp_ID == team_id and match.FTR == 'A'):\n",
    "            points += 3\n",
    "        elif match.FTR == 'D':\n",
    "            points += 1\n",
    "        else:\n",
    "            points += 0\n",
    "\n",
    "        weighted_points_sum += points * weight\n",
    "    \n",
    "    if total_weights > 0:\n",
    "        return weighted_points_sum / total_weights\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to each row for 'Team'\n",
    "#df['team_form_team'] = df.apply(lambda row: team_form(df, row, 'Team'), axis=1)\n",
    "\n",
    "# Applying the function to each row for 'Opp'\n",
    "#df['team_form_opp'] = df.apply(lambda row: team_form(df, row, 'Opp'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avgs(df, row, perspective, home_column, away_column):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past 5 matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    values = []\n",
    "    \n",
    "    # Determine which column to use and collect the values\n",
    "    for match in past_matches.itertuples():\n",
    "        if match.Team_ID == team_id:\n",
    "            values.append(getattr(match, home_column))  # Use home_column for home team\n",
    "        else:\n",
    "            values.append(getattr(match, away_column))  # Use away_column for away team\n",
    "    \n",
    "    # Calculate the weighted average of the values\n",
    "    weighted_sum = sum(value * weight for value, weight in zip(values, weights))\n",
    "    total_weights = sum(weights[:len(values)])  # Adjust total weight if there are less than 5 matches\n",
    "    \n",
    "    if total_weights > 0:\n",
    "        return weighted_sum / total_weights\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['team_shots'] = df.apply(lambda row: rolling_avgs(df, row, 'Team', 'HS', 'AS'), axis=1)\n",
    "#df['opp_shots'] = df.apply(lambda row: rolling_avgs(df, row, 'Opp', 'HS', 'AS'), axis=1)\n",
    "\n",
    "#df['team_shots_target'] = df.apply(lambda row: rolling_avgs(df, row, 'Team', 'HST', 'AST'), axis=1)\n",
    "#df['opp_shots_target'] = df.apply(lambda row: rolling_avgs(df, row, 'Opp', 'HST', 'AST'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def avg_games_played(df, row, team_column):\n",
    "    team = row[team_column]\n",
    "    # Ensure current_match_date is a Timestamp for comparison\n",
    "    current_match_date = pd.to_datetime(row['Date'], dayfirst=True)  # Assuming 'Date' format is 'dd/mm/yy'\n",
    "\n",
    "    delta = 30\n",
    "    start_date = current_match_date - timedelta(days=delta)\n",
    "\n",
    "    # Ensure 'Date' column is in datetime format for comparison\n",
    "    #df['Date_temp'] = pd.to_datetime(df['Date'], dayfirst=True)  # Convert 'Date' column to datetime if not already done\n",
    "\n",
    "    # Filter the DataFrame for matches within the last 30 days\n",
    "    if team_column == 'Team_ID':\n",
    "        past_matches = df[((df[team_column] == team) | (df['Opp_ID'] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "    else:\n",
    "        past_matches = df[((df['Team_ID'] == team) | (df[team_column] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "\n",
    "    # If no matches were played in the last 30 days\n",
    "    if past_matches.empty:\n",
    "        return 0\n",
    "\n",
    "    # Calculate weights based on the recency of each match\n",
    "    weights = (current_match_date - past_matches['Date']).dt.days\n",
    "    weighted_count = sum(delta - weights + 1)  # '+ 1' to include the match day in the weight\n",
    "\n",
    "    # Normalize weights to sum to 1 and calculate the weighted average\n",
    "    total_weight = sum(delta - weights + 1)\n",
    "    weighted_avg = weighted_count / total_weight\n",
    "\n",
    "    return weighted_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function for each team and opponent\n",
    "#df['team_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Team_ID'), axis=1)\n",
    "#df['opp_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Opp_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means only for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "means = df[numeric_cols].mean()\n",
    "\n",
    "# Fill missing values in numeric columns with their respective means\n",
    "df[numeric_cols] = df[numeric_cols].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop every row where 'FTR' is not 'H', 'D', or 'A'\n",
    "df = df[df['FTR'].isin(['H', 'D', 'A'])]\n",
    "\n",
    "# FTR2 to store the FTR as '0', '1', or '2' for future reference\n",
    "df['FTR2'] = df['FTR'].map({'H': 1, 'D': 0, 'A': 2}).astype(int)\n",
    "\n",
    "# Map 'H', 'D', and 'A' to 1, 0, and 0 respectively\n",
    "df['FTR'] = df['FTR'].map({'H': 1, 'D': 0, 'A': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>ABP</th>\n",
       "      <th>SYH</th>\n",
       "      <th>SYD</th>\n",
       "      <th>SYA</th>\n",
       "      <th>Team_ID</th>\n",
       "      <th>Opp_ID</th>\n",
       "      <th>Ref_ID</th>\n",
       "      <th>Date_temp</th>\n",
       "      <th>team_hist_vs</th>\n",
       "      <th>FTR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Ajaccio</td>\n",
       "      <td>Auxerre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.10833</td>\n",
       "      <td>2.17512</td>\n",
       "      <td>3.454825</td>\n",
       "      <td>3.979865</td>\n",
       "      <td>13.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.10833</td>\n",
       "      <td>2.17512</td>\n",
       "      <td>3.454825</td>\n",
       "      <td>3.979865</td>\n",
       "      <td>277.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2000</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Hull</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.10833</td>\n",
       "      <td>2.17512</td>\n",
       "      <td>3.454825</td>\n",
       "      <td>3.979865</td>\n",
       "      <td>316.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>18</td>\n",
       "      <td>20240401</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2000</td>\n",
       "      <td>Villarreal</td>\n",
       "      <td>Ath Madrid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.10833</td>\n",
       "      <td>2.17512</td>\n",
       "      <td>3.454825</td>\n",
       "      <td>3.979865</td>\n",
       "      <td>577.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>11</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Portimonense</td>\n",
       "      <td>Sp Braga</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.10833</td>\n",
       "      <td>2.17512</td>\n",
       "      <td>3.454825</td>\n",
       "      <td>3.979865</td>\n",
       "      <td>443.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Div       Date  Time      HomeTeam    AwayTeam  FTHG  FTAG  FTR  HTHG  \\\n",
       "2135    6 2024-04-01  1945       Ajaccio     Auxerre   0.0   1.0    0   0.0   \n",
       "2434    8 2024-04-01  1945         Inter      Empoli   2.0   0.0    1   1.0   \n",
       "769     4 2024-04-01  2000         Leeds        Hull   3.0   1.0    1   1.0   \n",
       "3043   14 2024-04-01  2000    Villarreal  Ath Madrid   1.0   2.0    0   0.0   \n",
       "4332   11 2024-04-01  2015  Portimonense    Sp Braga   3.0   5.0    0   1.0   \n",
       "\n",
       "      HTAG  ...       ABP      SYH       SYD       SYA  Team_ID  Opp_ID  \\\n",
       "2135   1.0  ...  20.10833  2.17512  3.454825  3.979865     13.0    59.0   \n",
       "2434   0.0  ...  20.10833  2.17512  3.454825  3.979865    277.0   181.0   \n",
       "769    1.0  ...  20.10833  2.17512  3.454825  3.979865    316.0   274.0   \n",
       "3043   1.0  ...  20.10833  2.17512  3.454825  3.979865    577.0    56.0   \n",
       "4332   2.0  ...  20.10833  2.17512  3.454825  3.979865    443.0   514.0   \n",
       "\n",
       "      Ref_ID  Date_temp  team_hist_vs  FTR2  \n",
       "2135      80   20240401      0.666667     2  \n",
       "2434      80   20240401      2.333333     1  \n",
       "769       18   20240401      2.333333     1  \n",
       "3043      80   20240401      0.200000     2  \n",
       "4332      80   20240401      0.733333     2  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    \n",
    "        'Div', 'Date_temp', 'Time', 'Team_ID', 'Opp_ID', 'Ref_ID', 'FTR', 'FTR2',\n",
    "        'team_hist_vs', \n",
    "        #'opp_hist_vs',\n",
    "\n",
    "        #'probs_win',         \n",
    "        #'probs_not_win', \n",
    "        \n",
    "        #'team_form_team', \n",
    "        #'team_form_opp',\n",
    "         \n",
    "        #'team_shots', 'opp_shots',\n",
    "        #'team_shots_target', 'opp_shots_target',\n",
    "\n",
    "        #'team_avg_games', 'opp_avg_games',\n",
    "\n",
    "        'AvgH', 'AvgD', 'AvgA'\n",
    "         \n",
    "         \n",
    "         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Date_temp' to 'Date'\n",
    "df.rename(columns={'Date_temp': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df to a CSV file\n",
    "df.to_csv('data/processed/processed_data_comps.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 400  # Set Frequency To 2500 Hertz\n",
    "duration = 200  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
