{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = [\n",
    "        \n",
    "            'E0', 'E1', \n",
    "            'SC0', 'SC1', \n",
    "            \n",
    "            'D1', 'D2',\n",
    "            'F1', 'F2',\n",
    "            'I1', 'I2',\n",
    "            'SP1', 'SP2',\n",
    "\n",
    "            'B1',\n",
    "            'G1',\n",
    "            'N1',\n",
    "            'P1',\n",
    "            'T1',           \n",
    "            \n",
    "        ]\n",
    "         \n",
    "         \n",
    "seasons = [2324, 2223, 2122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all filepaths for the competitions and seasons into a list\n",
    "matches_files = []\n",
    "\n",
    "for season in seasons:    \n",
    "    for comp in comps:  \n",
    "        matches_files.append('data/zip/%s/%s.csv' % (season, comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 16297 matches\n"
     ]
    }
   ],
   "source": [
    "# Load and concatenate matches data into a single DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in matches_files:\n",
    "\n",
    "    try:\n",
    "        df_temp = pd.read_csv(file)\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "    except:\n",
    "        # print an error message\n",
    "        print(f'Error: {file} not found')\n",
    "\n",
    "# print the amount of data loaded\n",
    "print(f\"Data loaded: {df.shape[0]} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Luton</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time     HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
       "0  E0  11/08/2023  20:00      Burnley       Man City     0     3   A   0.0   \n",
       "1  E0  12/08/2023  12:30      Arsenal  Nott'm Forest     2     1   H   2.0   \n",
       "2  E0  12/08/2023  15:00  Bournemouth       West Ham     1     1   D   0.0   \n",
       "3  E0  12/08/2023  15:00     Brighton          Luton     4     1   H   1.0   \n",
       "4  E0  12/08/2023  15:00      Everton         Fulham     0     1   A   0.0   \n",
       "\n",
       "   HTAG  ...  AHCh B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  MaxCAHA  \\\n",
       "0   2.0  ...  1.50     1.95      1.98   1.95   1.97      NaN      NaN   \n",
       "1   0.0  ... -2.00     1.95      1.98   1.93   1.97     2.01     2.09   \n",
       "2   0.0  ...  0.00     2.02      1.91   2.01   1.92     2.06     1.96   \n",
       "3   0.0  ... -1.75     2.01      1.92   2.00   1.91     2.14     1.93   \n",
       "4   0.0  ... -0.25     2.06      1.87   2.04   1.88     2.08     1.99   \n",
       "\n",
       "   AvgCAHH  AvgCAHA  Unnamed: 105  \n",
       "0     1.92     1.95           NaN  \n",
       "1     1.95     1.92           NaN  \n",
       "2     1.96     1.91           NaN  \n",
       "3     2.00     1.86           NaN  \n",
       "4     1.98     1.88           NaN  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Div' to a categorical type, a numeric representation of the division\n",
    "df['Div'] = df['Div'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'teams' is a list of team names\n",
    "teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "teams.sort()\n",
    "\n",
    "# Creating a dictionary from team names to an incremental index number\n",
    "teams_dict = {team: index for index, team in enumerate(teams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique list of HomeTeam and AwayTeam names combined, and add an index to each team\n",
    "teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "\n",
    "# Sort the teams alphabetically\n",
    "teams.sort()\n",
    "\n",
    "# Convert to an array of dictionaries\n",
    "teams = [{'team': team, 'index': index} for index, team in enumerate(teams)]\n",
    "\n",
    "df['Team_ID'] = df['HomeTeam'].map(teams_dict)\n",
    "df['Opp_ID'] = df['AwayTeam'].map(teams_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR',\n",
       "       'HTHG', 'HTAG',\n",
       "       ...\n",
       "       'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH',\n",
       "       'AvgCAHA', 'Unnamed: 105', 'Team_ID', 'Opp_ID'],\n",
       "      dtype='object', length=109)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique list of Referees, and add an index to each Referee\n",
    "referees = pd.concat([df['Referee']]).unique()\n",
    "\n",
    "# Convert to an array of dictionaries\n",
    "referees = [{'referee': referee, 'index': index} for index, referee in enumerate(referees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the team names to the index values in the 'teams' list\n",
    "#df['Team_ID'] = df['HomeTeam'].map({team['team']: team['index'] for team in teams})\n",
    "#df['Opp_ID'] = df['AwayTeam'].map({team['team']: team['index'] for team in teams})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the creation of a unique list of Referees and adding an index to each Referee\n",
    "referees = df['Referee'].unique()  # This should directly refer to the 'Referee' column\n",
    "\n",
    "# Convert to a dictionary with referee names as keys and their indices as values\n",
    "referee_dict = {referee: index for index, referee in enumerate(referees)}\n",
    "\n",
    "# Now map the 'Referee' column to these indices\n",
    "df['Ref_ID'] = df['Referee'].map(referee_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_to_int(date_str):\n",
    "    for fmt in ('%d/%m/%Y', '%d/%m/%y'):  # Add more formats here as needed\n",
    "        try:\n",
    "            # Parse the date\n",
    "            dt = pd.to_datetime(date_str, format=fmt)\n",
    "            # Format as 'YYYYMMDD' and convert to int\n",
    "            return int(dt.strftime('%Y%m%d'))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None  # Return None if all formats fail\n",
    "\n",
    "# First, ensure the Date column is in a datetime format if it's not already\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "\n",
    "df['Date_temp'] = df['Date'].apply(parse_date_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Declare Date_temp as a temporary column, an 8 digit integer representation of the date\n",
    "#df['Date_temp'] = df['Date'].dt.year * 10000 + df['Date'].dt.month * 100 + df['Date'].dt.day\n",
    "\n",
    "# Parse Date_temp to an 8 digit integer\n",
    "#df['Date_temp'] = df['Date_temp'].astype(int)\n",
    "\n",
    "# Connvert 'Time', which is now in HH:MM format to a 4 digit integer\n",
    "# Assuming a default time of 00:00 for missing values\n",
    "df['Time'] = df['Time'].fillna('00:00').str.replace(':', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [re.sub(r'[<]', '_st_', str(col)) for col in df.columns]\n",
    "df.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort df by Date_temp and Time\n",
    "df = df.sort_values(['Date_temp', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_vs_opponent_weighted(df, row, team_column):\n",
    "    # Initialize the total weighted score\n",
    "    weighted_score = 0\n",
    "    opponent_column = 'Opp_ID'\n",
    "\n",
    "    row_date_temp = row['Date'].year * 10000 + row['Date'].month * 100 + row['Date'].day\n",
    "\n",
    "    \n",
    "    # Filter the DataFrame for matches between the specified team and opponent from the same season, excluding the current match\n",
    "    filtered_matches = df[(df[team_column] == row[team_column]) & \n",
    "                          (df[opponent_column] == row[opponent_column]) &\n",
    "                          (df['Date_temp'] < row_date_temp)]\n",
    "    \n",
    "    recent_matches = filtered_matches.sort_values(by='Date', ascending=False).head(5)\n",
    "    \n",
    "    # Calculate weights - newer matches have higher weights\n",
    "    weights = range(len(recent_matches), 0, -1)  # Descending list based on the number of matches\n",
    "    \n",
    "    # Calculate score based on the match result\n",
    "    for match, weight in zip(recent_matches.itertuples(), weights):\n",
    "        if getattr(match, 'FTR') == 'H' and getattr(match, team_column) == getattr(match, 'Team_ID') or \\\n",
    "           getattr(match, 'FTR') == 'A' and getattr(match, team_column) != getattr(match, 'Team_ID'):\n",
    "            weighted_score += 3 * weight  # Team won\n",
    "        elif getattr(match, 'FTR') == 'A':\n",
    "            weighted_score += 1 * weight  # Draw\n",
    "        \n",
    "    # Normalize the weighted score by the sum of weights\n",
    "    normalized_weighted_score = weighted_score / sum(weights) if weights else 0\n",
    "\n",
    "    #print(f\"Weighted score: {weighted_score}, Normalized weighted score: {normalized_weighted_score}\")\n",
    "\n",
    "    return normalized_weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the modified function to create new columns\n",
    "df['team_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Team_ID'), axis=1)\n",
    "#df['opp_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Opp_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function adapted for DataFrame application\n",
    "def convert_odds(row):\n",
    "    odds_win, odds_draw, odds_lose = row['AvgH'], row['AvgD'], row['AvgA']\n",
    "    prob_win = 1 / odds_win\n",
    "    prob_draw = 1 / odds_draw\n",
    "    prob_lose = 1 / odds_lose\n",
    "    prob_not_win = prob_draw + prob_lose\n",
    "    return pd.Series([prob_win, prob_not_win], index=['probs_win', 'probs_not_win'])\n",
    "\n",
    "# Apply the function and create new columns\n",
    "#df[['probs_win', 'probs_not_win']] = df.apply(convert_odds, axis=1)\n",
    "\n",
    "#df = df.drop(columns=['AvgH', 'AvgD', 'AvgA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "#df = df.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "      <th>Team_ID</th>\n",
       "      <th>Opp_ID</th>\n",
       "      <th>Ref_ID</th>\n",
       "      <th>Date_temp</th>\n",
       "      <th>team_hist_vs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Ajaccio</td>\n",
       "      <td>Auxerre</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2000</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Hull</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>163</td>\n",
       "      <td>18</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2000</td>\n",
       "      <td>Villarreal</td>\n",
       "      <td>Ath Madrid</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>342</td>\n",
       "      <td>34</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>11</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Portimonense</td>\n",
       "      <td>Sp Braga</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262</td>\n",
       "      <td>303</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Div       Date  Time      HomeTeam    AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
       "2135    6 2024-04-01  1945       Ajaccio     Auxerre     0     1   A   0.0   \n",
       "2434    8 2024-04-01  1945         Inter      Empoli     2     0   H   1.0   \n",
       "769     4 2024-04-01  2000         Leeds        Hull     3     1   H   1.0   \n",
       "3043   14 2024-04-01  2000    Villarreal  Ath Madrid     1     2   A   0.0   \n",
       "4332   11 2024-04-01  2015  Portimonense    Sp Braga     3     5   A   1.0   \n",
       "\n",
       "      HTAG  ... MaxCAHH MaxCAHA  AvgCAHH  AvgCAHA  Unnamed: 105  Team_ID  \\\n",
       "2135   1.0  ...    1.85    2.12     1.76     2.06           NaN        5   \n",
       "2434   0.0  ...    2.00    2.00     1.95     1.91           NaN      166   \n",
       "769    1.0  ...    2.14    1.86     2.05     1.80           NaN      188   \n",
       "3043   1.0  ...    2.12    1.95     1.99     1.84           NaN      342   \n",
       "4332   2.0  ...    1.99    1.96     1.93     1.90           NaN      262   \n",
       "\n",
       "      Opp_ID  Ref_ID  Date_temp  team_hist_vs  \n",
       "2135      37      80   20240401      0.666667  \n",
       "2434     107      80   20240401      1.666667  \n",
       "769      163      18   20240401      0.000000  \n",
       "3043      34      80   20240401      0.000000  \n",
       "4332     303      80   20240401      1.000000  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_form(df, row, perspective):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Initialize points\n",
    "    points = 0\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Calculate points with weights\n",
    "    weighted_points_sum = 0\n",
    "    total_weights = sum(weights[:len(past_matches)])  # Adjust the total weight in case of less than 5 matches\n",
    "    \n",
    "    for match, weight in zip(past_matches.itertuples(), weights):\n",
    "        if (match.Team_ID == team_id and match.FTR == 'H') or (match.Opp_ID == team_id and match.FTR == 'A'):\n",
    "            points += 3\n",
    "        elif match.FTR == 'D':\n",
    "            points += 1\n",
    "        else:\n",
    "            points += 0\n",
    "\n",
    "        weighted_points_sum += points * weight\n",
    "    \n",
    "    if total_weights > 0:\n",
    "        return weighted_points_sum / total_weights\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to each row for 'Team'\n",
    "#df['team_form_team'] = df.apply(lambda row: team_form(df, row, 'Team'), axis=1)\n",
    "\n",
    "# Applying the function to each row for 'Opp'\n",
    "#df['team_form_opp'] = df.apply(lambda row: team_form(df, row, 'Opp'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avgs(df, row, perspective, home_column, away_column):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past 5 matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    values = []\n",
    "    \n",
    "    # Determine which column to use and collect the values\n",
    "    for match in past_matches.itertuples():\n",
    "        if match.Team_ID == team_id:\n",
    "            values.append(getattr(match, home_column))  # Use home_column for home team\n",
    "        else:\n",
    "            values.append(getattr(match, away_column))  # Use away_column for away team\n",
    "    \n",
    "    # Calculate the weighted average of the values\n",
    "    weighted_sum = sum(value * weight for value, weight in zip(values, weights))\n",
    "    total_weights = sum(weights[:len(values)])  # Adjust total weight if there are less than 5 matches\n",
    "    \n",
    "    if total_weights > 0:\n",
    "        return weighted_sum / total_weights\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['team_shots'] = df.apply(lambda row: rolling_avgs(df, row, 'Team', 'HS', 'AS'), axis=1)\n",
    "#df['opp_shots'] = df.apply(lambda row: rolling_avgs(df, row, 'Opp', 'HS', 'AS'), axis=1)\n",
    "\n",
    "#df['team_shots_target'] = df.apply(lambda row: rolling_avgs(df, row, 'Team', 'HST', 'AST'), axis=1)\n",
    "#df['opp_shots_target'] = df.apply(lambda row: rolling_avgs(df, row, 'Opp', 'HST', 'AST'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def avg_games_played(df, row, team_column):\n",
    "    team = row[team_column]\n",
    "    # Ensure current_match_date is a Timestamp for comparison\n",
    "    current_match_date = pd.to_datetime(row['Date'], dayfirst=True)  # Assuming 'Date' format is 'dd/mm/yy'\n",
    "\n",
    "    delta = 30\n",
    "    start_date = current_match_date - timedelta(days=delta)\n",
    "\n",
    "    # Ensure 'Date' column is in datetime format for comparison\n",
    "    #df['Date_temp'] = pd.to_datetime(df['Date'], dayfirst=True)  # Convert 'Date' column to datetime if not already done\n",
    "\n",
    "    # Filter the DataFrame for matches within the last 30 days\n",
    "    if team_column == 'Team_ID':\n",
    "        past_matches = df[((df[team_column] == team) | (df['Opp_ID'] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "    else:\n",
    "        past_matches = df[((df['Team_ID'] == team) | (df[team_column] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "\n",
    "    # If no matches were played in the last 30 days\n",
    "    if past_matches.empty:\n",
    "        return 0\n",
    "\n",
    "    # Calculate weights based on the recency of each match\n",
    "    weights = (current_match_date - past_matches['Date']).dt.days\n",
    "    weighted_count = sum(delta - weights + 1)  # '+ 1' to include the match day in the weight\n",
    "\n",
    "    # Normalize weights to sum to 1 and calculate the weighted average\n",
    "    total_weight = sum(delta - weights + 1)\n",
    "    weighted_avg = weighted_count / total_weight\n",
    "\n",
    "    return weighted_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function for each team and opponent\n",
    "#df['team_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Team_ID'), axis=1)\n",
    "#df['opp_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Opp_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means only for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "means = df[numeric_cols].mean()\n",
    "\n",
    "# Fill missing values in numeric columns with their respective means\n",
    "df[numeric_cols] = df[numeric_cols].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop every row where 'FTR' is not 'H', 'D', or 'A'\n",
    "df = df[df['FTR'].isin(['H', 'D', 'A'])]\n",
    "\n",
    "# Map 'H', 'D', and 'A' to 1, 0, and 0 respectively\n",
    "df['FTR'] = df['FTR'].map({'H': 1, 'D': 0, 'A': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "      <th>Team_ID</th>\n",
       "      <th>Opp_ID</th>\n",
       "      <th>Ref_ID</th>\n",
       "      <th>Date_temp</th>\n",
       "      <th>team_hist_vs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Ajaccio</td>\n",
       "      <td>Auxerre</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2000</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Hull</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>163</td>\n",
       "      <td>18</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2000</td>\n",
       "      <td>Villarreal</td>\n",
       "      <td>Ath Madrid</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>342</td>\n",
       "      <td>34</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>11</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Portimonense</td>\n",
       "      <td>Sp Braga</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262</td>\n",
       "      <td>303</td>\n",
       "      <td>80</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Div       Date  Time      HomeTeam    AwayTeam  FTHG  FTAG  FTR  HTHG  \\\n",
       "2135    6 2024-04-01  1945       Ajaccio     Auxerre     0     1    0   0.0   \n",
       "2434    8 2024-04-01  1945         Inter      Empoli     2     0    1   1.0   \n",
       "769     4 2024-04-01  2000         Leeds        Hull     3     1    1   1.0   \n",
       "3043   14 2024-04-01  2000    Villarreal  Ath Madrid     1     2    0   0.0   \n",
       "4332   11 2024-04-01  2015  Portimonense    Sp Braga     3     5    0   1.0   \n",
       "\n",
       "      HTAG  ... MaxCAHH MaxCAHA  AvgCAHH  AvgCAHA  Unnamed: 105  Team_ID  \\\n",
       "2135   1.0  ...    1.85    2.12     1.76     2.06           NaN        5   \n",
       "2434   0.0  ...    2.00    2.00     1.95     1.91           NaN      166   \n",
       "769    1.0  ...    2.14    1.86     2.05     1.80           NaN      188   \n",
       "3043   1.0  ...    2.12    1.95     1.99     1.84           NaN      342   \n",
       "4332   2.0  ...    1.99    1.96     1.93     1.90           NaN      262   \n",
       "\n",
       "      Opp_ID  Ref_ID  Date_temp  team_hist_vs  \n",
       "2135      37      80   20240401      0.666667  \n",
       "2434     107      80   20240401      1.666667  \n",
       "769      163      18   20240401      0.000000  \n",
       "3043      34      80   20240401      0.000000  \n",
       "4332     303      80   20240401      1.000000  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    \n",
    "        'Div', 'Date_temp', 'Time', 'Team_ID', 'Opp_ID', 'Ref_ID', 'FTR', \n",
    "        'team_hist_vs', \n",
    "        #'opp_hist_vs',\n",
    "\n",
    "        #'probs_win',         \n",
    "        #'probs_not_win', \n",
    "        \n",
    "        #'team_form_team', \n",
    "        #'team_form_opp',\n",
    "         \n",
    "        #'team_shots', 'opp_shots',\n",
    "        #'team_shots_target', 'opp_shots_target',\n",
    "\n",
    "        #'team_avg_games', 'opp_avg_games',\n",
    "\n",
    "        'AvgH', 'AvgD', 'AvgA'\n",
    "         \n",
    "         \n",
    "         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by Date_temp and separate the 200 most recent matches into a validation set\n",
    "df.sort_values('Date_temp', inplace=True)\n",
    "\n",
    "# Set the 'Date_temp' column as the index\n",
    "df.set_index('Date_temp', inplace=True)\n",
    "\n",
    "# Drop the 'Date_temp' column\n",
    "#df.drop('Date_temp', axis=1, inplace=True)\n",
    "\n",
    "df_val = df.tail(250)\n",
    "df = df.iloc[:-250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X and y\n",
    "X = df.drop('FTR', axis=1)\n",
    "y = df['FTR']\n",
    "\n",
    "X.columns = [re.sub(r'[<]', '_st_', str(col)) for col in X.columns]\n",
    "X.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in X.columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12837, 3210)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[(&#x27;target_encoder&#x27;,\n",
       "                                              TargetEncoder()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;xgb&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        &#x27;xgb__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB20C50&gt;,\n",
       "                                        &#x27;xgb__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB219A0&gt;,\n",
       "                                        &#x27;xgb__scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB218E0&gt;,\n",
       "                                        &#x27;xgb__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000220113A70B0&gt;},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[(&#x27;target_encoder&#x27;,\n",
       "                                              TargetEncoder()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;xgb&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        &#x27;xgb__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB20C50&gt;,\n",
       "                                        &#x27;xgb__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB219A0&gt;,\n",
       "                                        &#x27;xgb__scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB218E0&gt;,\n",
       "                                        &#x27;xgb__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000220113A70B0&gt;},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;target_encoder&#x27;, TargetEncoder()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">TargetEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>TargetEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[('target_encoder',\n",
       "                                              TargetEncoder()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('xgb',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        'xgb__reg_alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB20C50>,\n",
       "                                        'xgb__reg_lambda': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB219A0>,\n",
       "                                        'xgb__scale_pos_weight': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002202AB218E0>,\n",
       "                                        'xgb__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000220113A70B0>},\n",
       "                   random_state=42, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('target_encoder', TargetEncoder()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters\n",
    "\n",
    "param_distributions = {\n",
    "\n",
    "    'target_encoder__smoothing': randint(1, 100),\n",
    "    'xgb__n_estimators': randint(100, 1000),\n",
    "    'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.6),\n",
    "    'xgb__subsample': uniform(0.3, 0.7),\n",
    "    'xgb__colsample_bytree': uniform(0.3, 0.7),\n",
    "    'xgb__gamma': randint(0, 5),\n",
    "    'xgb__reg_alpha': uniform(0, 1),\n",
    "    'xgb__reg_lambda': uniform(0, 1),\n",
    "    'xgb__min_child_weight': randint(1, 10),\n",
    "    'xgb__scale_pos_weight': uniform(0.5, 1.5)\n",
    "  \n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=5,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60      1772\n",
      "           1       0.53      0.59      0.56      1438\n",
      "\n",
      "    accuracy                           0.58      3210\n",
      "   macro avg       0.58      0.58      0.58      3210\n",
      "weighted avg       0.59      0.58      0.58      3210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(classification_report(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_windows(X, window_size, step):\n",
    "    n_samples = len(X)\n",
    "    windows = []\n",
    "    for start_idx in range(0, n_samples - window_size + 1, step):\n",
    "        end_idx = start_idx + window_size\n",
    "        if end_idx > n_samples:\n",
    "            break  # Avoid going beyond the dataset\n",
    "        train_indices = list(range(max(0, start_idx - window_size), start_idx))\n",
    "        test_indices = list(range(start_idx, end_idx))\n",
    "        windows.append((train_indices, test_indices))\n",
    "    return windows\n",
    "\n",
    "negative_count = len(df[df['FTR'] == 0])\n",
    "positive_count = len(df[df['FTR'] == 1])\n",
    "scale_pos_weight_value = negative_count / positive_count\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_dist = {\n",
    "    \n",
    "    'xgb__clf__max_depth': [1,2,3],\n",
    "    'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "    'rf__clf__max_depth': [None, 4, 6],\n",
    "    'rf__clf__min_samples_split': [2, 5],\n",
    "    'rf__clf__min_samples_leaf': [1, 2],\n",
    "    'rf__clf__bootstrap': [True, False],\n",
    "    'rf__clf__n_estimators': [50, 100, 200],\n",
    "\n",
    "    'lr__clf__C': [0.1, 1, 10],  # Inverse of regularization strength; smaller values specify stronger regularization.\n",
    "    'lr__clf__penalty': ['l1', 'l2', 'elasticnet'],  # Specify the norm of the penalty.\n",
    "    'lr__clf__solver': ['saga'],  # Algorithm to use in the optimization problem, 'saga' supports all penalties.\n",
    "    'lr__clf__l1_ratio': [0.5],  # The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'.\n",
    "\n",
    "    'cat__clf__depth': [1,2,3,4],\n",
    "    'cat__clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'cat__clf__iterations': [50, 100, 200],\n",
    "    'cat__clf__l2_leaf_reg': [1, 3, 5],\n",
    "\n",
    "    'gb__clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gb__clf__n_estimators': [50, 100, 200],\n",
    "    'gb__clf__max_depth': [3, 5, 7],\n",
    "    'gb__clf__min_samples_split': [2, 5],\n",
    "    'gb__clf__min_samples_leaf': [1, 2],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "param_test = {\n",
    "    \n",
    "    'xgb__clf__max_depth': [1,2,3],\n",
    "    'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a custom scoring function\n",
    "def xgb_early_stopping_score(y, estimator, X, y_true, sample_weight=None):\n",
    "    \"\"\"\n",
    "    Custom scorer that uses early stopping.\n",
    "    \"\"\"\n",
    "    # Split X into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_true, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit with early stopping\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    estimator.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_set, verbose=False)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = estimator.predict(X_val)\n",
    "    \n",
    "    # Return the F1 score\n",
    "    return f1_score(y_val, y_pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Training Data Shape: (3209, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 1, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.001, 'xgb__clf__lambda': 1, 'xgb__clf__alpha': 0}\n",
      "Precision: 0.6319725771268307\n",
      "\n",
      "Iteration 2 Training Data Shape: (6418, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 5, 'xgb__clf__max_depth': 2, 'xgb__clf__learning_rate': 0.1, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 1}\n",
      "Precision: 0.6463072608289187\n",
      "\n",
      "Iteration 3 Training Data Shape: (9627, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 100, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.01, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 0.5}\n",
      "Precision: 0.6463072608289187\n",
      "\n",
      "Iteration 4 Training Data Shape: (12836, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 100, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.01, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 0.5}\n",
      "Precision: 0.6360236833904643\n",
      "\n",
      "Iteration 5 Training Data Shape: (16045, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 100, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.01, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 0.5}\n",
      "Precision: 0.6463072608289187\n",
      "\n",
      "\n",
      "Best F1 Score: 0.6161650321271559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67      1812\n",
      "           1       0.58      0.65      0.62      1397\n",
      "\n",
      "    accuracy                           0.65      3209\n",
      "   macro avg       0.64      0.65      0.64      3209\n",
      "weighted avg       0.65      0.65      0.65      3209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the F1 score for the '1' class\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_f1_params = None\n",
    "best_window_size = None\n",
    "best_precision = 0\n",
    "best_model = None \n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "\n",
    "\n",
    "# Make the custom scorer\n",
    "custom_scorer = make_scorer(xgb_early_stopping_score, greater_is_better=True, needs_proba=False, X=X, y_true=y)\n",
    "\n",
    "# Set the window_size and step to 5% of the dataset\n",
    "window_size = int(len(X) * 0.2)\n",
    "step = int(len(X) * 0.2)\n",
    "\n",
    "# Initialize an empty list to store precision scores\n",
    "precision_scores = []\n",
    "\n",
    "# Initialize an empty dataframe to store misclassified samples\n",
    "misclassified_samples = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "# Generate windows\n",
    "window_splits = generate_sliding_windows(X, window_size, step)\n",
    "\n",
    "# Initialize training indices with the first window\n",
    "train_end_index = window_size\n",
    "\n",
    "# Iterate over each sliding window\n",
    "for i, (train_index, test_index) in enumerate(window_splits):\n",
    "\n",
    "    # Update training indices to include the next window\n",
    "    train_index = list(range(train_end_index))\n",
    "    train_end_index += window_size\n",
    "\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"Iteration {i+1} Training Data Shape: {X_train.shape}\")\n",
    "\n",
    "    # Combine misclassified samples from previous iterations with current training data\n",
    "    if not misclassified_samples.empty:\n",
    "        X_train_combined = pd.concat([X_train, misclassified_samples[X_train.columns]], axis=0)\n",
    "        y_train_combined = pd.concat([y_train, misclassified_samples['FTR']], axis=0)\n",
    "    else:\n",
    "        X_train_combined = X_train\n",
    "        y_train_combined = y_train\n",
    "\n",
    "    # Calculate misclassification frequency\n",
    "    misclassified_freq = y_train_combined.value_counts(normalize=True)\n",
    "\n",
    "    # Define class weights based on misclassification frequency\n",
    "    class_weights = {0: 1, 1: max(0.6, 1 - misclassified_freq.get(1, 0.5))}  # Adjust dynamically to penalize misclassification of class 1 more heavily\n",
    "\n",
    "    # Define pipelines for each classifier with SMOTE and TargetEncoder\n",
    "    pipeline_xgb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', XGBClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    pipeline_gb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', GradientBoostingClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for logistic regression\n",
    "    pipeline_lr = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for catboost classifier\n",
    "    pipeline_cat = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', CatBoostClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for random forest\n",
    "    pipeline_rf = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', RandomForestClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # LightGBM pipeline\n",
    "    pipeline_lgbm = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LGBMClassifier(random_state=42, force_col_wise='true', verbose=0))\n",
    "    ])\n",
    "\n",
    "    # Adaboost pipeline\n",
    "    pipeline_ada = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', AdaBoostClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Combine them into an ensemble classifier\n",
    "    ensemble_clf = VotingClassifier(estimators=[\n",
    "        ('xgb', pipeline_xgb),\n",
    "        #('gb', pipeline_gb),\n",
    "        ('lr', pipeline_lr),\n",
    "        #('cat', pipeline_cat),\n",
    "        #\n",
    "        #('rf', pipeline_rf),\n",
    "        #('lgbm', pipeline_lgbm),\n",
    "        ('ada', pipeline_ada)\n",
    "    ], voting='soft')\n",
    "\n",
    "    # Setup RandomizedSearchCV\n",
    "    clf = RandomizedSearchCV(\n",
    "        estimator=ensemble_clf,\n",
    "        param_distributions=param_test,\n",
    "        n_iter=5,\n",
    "        scoring=f1_scorer,\n",
    "        cv=TimeSeriesSplit(n_splits=3),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )  \n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = clf.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    # Use the best estimator\n",
    "    best_pipe = clf.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    y_proba = best_pipe.predict_proba(X_test)\n",
    "\n",
    "    # Apply threshold\n",
    "    threshold = 0.5  # You can adjust this threshold as needed\n",
    "    y_pred = (y_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    current_f1_score = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    if current_f1_score > best_f1_score:\n",
    "        best_f1_score = current_f1_score\n",
    "        best_f1_params = clf.best_params_\n",
    "        #best_model = clf.best_estimator_ \n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    best_model = clf.best_estimator_ \n",
    "\n",
    "    # Calculate precision score\n",
    "    precision = np.mean(y_test == y_pred)\n",
    "    precision_scores.append(precision)\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    print()\n",
    "\n",
    "# Print the best F1 score and its corresponding parameters\n",
    "print()\n",
    "print(\"Best F1 Score:\", best_f1_score)\n",
    "\n",
    "# print the classification report of the best model on the full dataset\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Put the target column to the front\n",
    "cols = list(corr.columns)\n",
    "cols.insert(0, cols.pop(cols.index('FTR')))\n",
    "corr = corr.loc[cols, cols]\n",
    "\n",
    "# Plot the correlation matrix\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=2)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "importances = search.best_estimator_.named_steps['xgb'].feature_importances_\n",
    "features = X_train.columns\n",
    "importances_df = pd.DataFrame({'features': features, 'importances': importances})\n",
    "importances_df = importances_df.sort_values('importances', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.barplot(x='importances', y='features', data=importances_df)\n",
    "#plt.title('Feature Importances')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 250 entries, 20240316 to 20240401\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Div           250 non-null    int8   \n",
      " 1   Time          250 non-null    int32  \n",
      " 2   Team_ID       250 non-null    int64  \n",
      " 3   Opp_ID        250 non-null    int64  \n",
      " 4   Ref_ID        250 non-null    int64  \n",
      " 5   FTR           250 non-null    int32  \n",
      " 6   team_hist_vs  250 non-null    float64\n",
      " 7   AvgH          250 non-null    float64\n",
      " 8   AvgD          250 non-null    float64\n",
      " 9   AvgA          250 non-null    float64\n",
      "dtypes: float64(4), int32(2), int64(3), int8(1)\n",
      "memory usage: 17.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.583\n",
      "Best Accuracy: 0.644\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Apply the best threshold to generate final predictions\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Now considering both HomeTeam win probability (index 1) and AwayTeam win probability (index 2)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m df_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproba_home_win\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_val_proba[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Probability of home win\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproba_away_win\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43my_val_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Probability of away win\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Initialize prediction column with 0 (which we'll use to indicate no prediction above threshold/draw)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m df_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Presuming best_model and df_val are already correctly defined and available\n",
    "\n",
    "# Calculate the predicted probabilities for the validation set\n",
    "y_val_proba = best_model.predict_proba(df_val.drop(columns=['FTR']))\n",
    "\n",
    "# Initialize variables to track the best threshold and its corresponding accuracy\n",
    "best_threshold = 0.5\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over potential threshold values\n",
    "for threshold in np.arange(0.58, 0.8, 0.001):\n",
    "    # Apply the current threshold to generate predictions\n",
    "    y_val_pred = (y_val_proba[:, 1] >= threshold).astype(int)\n",
    "    \n",
    "    # Evaluate accuracy for the current set of predictions\n",
    "    accuracy = accuracy_score(df_val['FTR'], y_val_pred)\n",
    "    \n",
    "    # Update the best threshold and accuracy as needed\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold \n",
    "\n",
    "# Print the best threshold and its accuracy\n",
    "print(f\"Best Threshold: {best_threshold}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Apply the best threshold to generate final predictions\n",
    "# Now considering both HomeTeam win probability (index 1) and AwayTeam win probability (index 2)\n",
    "df_val['proba_home_win'] = y_val_proba[:, 1]  # Probability of home win\n",
    "df_val['proba_away_win'] = y_val_proba[:, 2]  # Probability of away win\n",
    "\n",
    "# Initialize prediction column with 0 (which we'll use to indicate no prediction above threshold/draw)\n",
    "df_val['Prediction'] = 0\n",
    "\n",
    "# Update Prediction to 1 if HomeTeam win probability is above the threshold\n",
    "df_val.loc[df_val['proba_home_win'] > best_threshold, 'Prediction'] = 1\n",
    "\n",
    "# Update Prediction to 2 if AwayTeam win probability is above the threshold\n",
    "df_val.loc[df_val['proba_away_win'] > best_threshold, 'Prediction'] = 2\n",
    "\n",
    "# Filter out draws and rows where neither team's win probability exceeds the threshold\n",
    "filtered_df_val = df_val[(df_val['Prediction'] == 1) | (df_val['Prediction'] == 2)].copy()\n",
    "\n",
    "# Reset index and map team IDs back to team names for clarity\n",
    "filtered_df_val.reset_index(inplace=True)\n",
    "filtered_df_val['Team'] = filtered_df_val['Team_ID'].map(index_to_team)\n",
    "filtered_df_val['Opponent'] = filtered_df_val['Opp_ID'].map(index_to_team)\n",
    "\n",
    "# Determine whether the prediction was correct\n",
    "filtered_df_val['Actual Result'] = df_val['FTR']\n",
    "filtered_df_val['Correct Prediction'] = ((filtered_df_val['Prediction'] == 1) & (filtered_df_val['Actual Result'] == 1)) | \\\n",
    "                                        ((filtered_df_val['Prediction'] == 2) & (filtered_df_val['Actual Result'] == 0))\n",
    "\n",
    "# Define columns to display\n",
    "display_columns = [\n",
    "    'Date_temp', 'Team', 'Opponent', 'proba_home_win', 'proba_away_win', 'Prediction',\n",
    "    'Actual Result', 'Correct Prediction', 'AvgH', 'AvgD', 'AvgA'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = filtered_df_val[display_columns]\n",
    "output = output.sort_values('Date_temp', ascending=False)\n",
    "\n",
    "output = output[output['proba_1'] > best_threshold].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_temp</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>proba_1</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual Result</th>\n",
       "      <th>Correct Prediction</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>0.603776</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.28</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>Salernitana</td>\n",
       "      <td>0.685998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.44</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>0.584141</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Cremonese</td>\n",
       "      <td>FeralpiSalo</td>\n",
       "      <td>0.589177</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>0.715984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7.04</td>\n",
       "      <td>13.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Hull</td>\n",
       "      <td>0.637767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.75</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>Darmstadt</td>\n",
       "      <td>0.583614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.18</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Almere City</td>\n",
       "      <td>Volendam</td>\n",
       "      <td>0.624196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.59</td>\n",
       "      <td>6.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Heidenheim</td>\n",
       "      <td>0.677108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6.35</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Oviedo</td>\n",
       "      <td>Villarreal B</td>\n",
       "      <td>0.596605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.52</td>\n",
       "      <td>3.98</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Aris</td>\n",
       "      <td>Lamia</td>\n",
       "      <td>0.626446</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>0.600114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Feyenoord</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>0.663067</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Twente</td>\n",
       "      <td>Heracles</td>\n",
       "      <td>0.691481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.22</td>\n",
       "      <td>6.46</td>\n",
       "      <td>11.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>0.647665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.37</td>\n",
       "      <td>5.63</td>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Go Ahead Eagles</td>\n",
       "      <td>Excelsior</td>\n",
       "      <td>0.593060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4.31</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Luton</td>\n",
       "      <td>0.687436</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.22</td>\n",
       "      <td>7.47</td>\n",
       "      <td>11.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Rangers</td>\n",
       "      <td>Hibernian</td>\n",
       "      <td>0.680762</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.26</td>\n",
       "      <td>6.09</td>\n",
       "      <td>10.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Leganes</td>\n",
       "      <td>Cartagena</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>0.673958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.96</td>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20240330</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>Mainz</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5.30</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>0.702294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.22</td>\n",
       "      <td>7.36</td>\n",
       "      <td>11.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Holstein Kiel</td>\n",
       "      <td>Hansa Rostock</td>\n",
       "      <td>0.583715</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.30</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Las Palmas</td>\n",
       "      <td>0.678288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6.34</td>\n",
       "      <td>10.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>0.585547</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>0.630262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.40</td>\n",
       "      <td>5.71</td>\n",
       "      <td>6.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20240330</td>\n",
       "      <td>AZ Alkmaar</td>\n",
       "      <td>Vitesse</td>\n",
       "      <td>0.685926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.26</td>\n",
       "      <td>5.85</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20240329</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>0.616391</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.66</td>\n",
       "      <td>6.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20240329</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>0.623096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.02</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20240329</td>\n",
       "      <td>Benfica</td>\n",
       "      <td>Chaves</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.01</td>\n",
       "      <td>23.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20240329</td>\n",
       "      <td>Gent</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0.584363</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20240323</td>\n",
       "      <td>Dundee United</td>\n",
       "      <td>Inverness C</td>\n",
       "      <td>0.622424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.27</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Wehen</td>\n",
       "      <td>0.586252</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Sp Lisbon</td>\n",
       "      <td>Boavista</td>\n",
       "      <td>0.738035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.13</td>\n",
       "      <td>8.59</td>\n",
       "      <td>18.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>0.586115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Gent</td>\n",
       "      <td>Charleroi</td>\n",
       "      <td>0.594253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.11</td>\n",
       "      <td>5.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20240317</td>\n",
       "      <td>PSV Eindhoven</td>\n",
       "      <td>Twente</td>\n",
       "      <td>0.633849</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.41</td>\n",
       "      <td>4.91</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Napoli</td>\n",
       "      <td>0.598786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4.18</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Reims</td>\n",
       "      <td>Metz</td>\n",
       "      <td>0.595754</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>RWD Molenbeek</td>\n",
       "      <td>0.650059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.16</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>Genoa</td>\n",
       "      <td>0.637607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.52</td>\n",
       "      <td>3.99</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>0.660613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.34</td>\n",
       "      <td>5.39</td>\n",
       "      <td>8.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Millwall</td>\n",
       "      <td>0.667089</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.98</td>\n",
       "      <td>9.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Roma</td>\n",
       "      <td>Sassuolo</td>\n",
       "      <td>0.652982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.37</td>\n",
       "      <td>5.09</td>\n",
       "      <td>7.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240316</td>\n",
       "      <td>Celtic</td>\n",
       "      <td>St Johnstone</td>\n",
       "      <td>0.744429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.10</td>\n",
       "      <td>9.19</td>\n",
       "      <td>22.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240316</td>\n",
       "      <td>Hibernian</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>0.604206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.51</td>\n",
       "      <td>4.25</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240316</td>\n",
       "      <td>Ipswich</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>0.597433</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.32</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240316</td>\n",
       "      <td>Airdrie Utd</td>\n",
       "      <td>Arbroath</td>\n",
       "      <td>0.594949</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Date_temp             Team        Opponent   proba_1  Prediction  \\\n",
       "47   20240401         Coventry         Cardiff  0.603776           1   \n",
       "46   20240401          Bologna     Salernitana  0.685998           1   \n",
       "45   20240401        Leicester         Norwich  0.584141           1   \n",
       "44   20240401        Cremonese     FeralpiSalo  0.589177           1   \n",
       "43   20240401            Inter          Empoli  0.715984           1   \n",
       "42   20240401            Leeds            Hull  0.637767           1   \n",
       "36   20240331           Bochum       Darmstadt  0.583614           1   \n",
       "33   20240331      Almere City        Volendam  0.624196           1   \n",
       "34   20240331        Stuttgart      Heidenheim  0.677108           1   \n",
       "35   20240331           Oviedo    Villarreal B  0.596605           1   \n",
       "37   20240331             Aris           Lamia  0.626446           1   \n",
       "38   20240331      Real Madrid      Ath Bilbao  0.600114           1   \n",
       "39   20240331        Feyenoord         Utrecht  0.663067           1   \n",
       "40   20240331           Twente        Heracles  0.691481           1   \n",
       "41   20240331        Liverpool        Brighton  0.647665           1   \n",
       "25   20240330  Go Ahead Eagles       Excelsior  0.593060           1   \n",
       "32   20240330        Tottenham           Luton  0.687436           1   \n",
       "31   20240330          Rangers       Hibernian  0.680762           1   \n",
       "30   20240330          Leganes       Cartagena  0.585396           1   \n",
       "29   20240330          Chelsea         Burnley  0.673958           1   \n",
       "28   20240330       RB Leipzig           Mainz  0.648337           1   \n",
       "27   20240330       Leverkusen      Hoffenheim  0.702294           1   \n",
       "26   20240330    Holstein Kiel   Hansa Rostock  0.583715           1   \n",
       "24   20240330        Barcelona      Las Palmas  0.678288           1   \n",
       "22   20240330      Aston Villa          Wolves  0.585547           1   \n",
       "21   20240330    Bayern Munich        Dortmund  0.630262           1   \n",
       "23   20240330       AZ Alkmaar         Vitesse  0.685926           1   \n",
       "20   20240329          Norwich        Plymouth  0.616391           1   \n",
       "19   20240329          Preston       Rotherham  0.623096           1   \n",
       "18   20240329          Benfica          Chaves  0.744277           1   \n",
       "17   20240329             Gent        Standard  0.584363           1   \n",
       "16   20240323    Dundee United     Inverness C  0.622424           1   \n",
       "12   20240317          Hamburg           Wehen  0.586252           1   \n",
       "9    20240317        Sp Lisbon        Boavista  0.738035           1   \n",
       "5    20240317         Dortmund   Ein Frankfurt  0.586115           1   \n",
       "6    20240317             Gent       Charleroi  0.594253           1   \n",
       "7    20240317    PSV Eindhoven          Twente  0.633849           1   \n",
       "8    20240317            Inter          Napoli  0.598786           1   \n",
       "14   20240317            Reims            Metz  0.595754           1   \n",
       "10   20240317    Cercle Brugge   RWD Molenbeek  0.650059           1   \n",
       "11   20240317         Juventus           Genoa  0.637607           1   \n",
       "13   20240317           Monaco         Lorient  0.660613           1   \n",
       "15   20240317            Leeds        Millwall  0.667089           1   \n",
       "4    20240317             Roma        Sassuolo  0.652982           1   \n",
       "2    20240316           Celtic    St Johnstone  0.744429           1   \n",
       "1    20240316        Hibernian      Livingston  0.604206           1   \n",
       "3    20240316          Ipswich  Sheffield Weds  0.597433           1   \n",
       "0    20240316      Airdrie Utd        Arbroath  0.594949           1   \n",
       "\n",
       "    Actual Result  Correct Prediction  AvgH   AvgD   AvgA  \n",
       "47              0               False  1.53   4.28   6.00  \n",
       "46              1                True  1.29   5.44  11.25  \n",
       "45              1                True  1.65   4.17   4.83  \n",
       "44              0               False  1.56   4.00   5.48  \n",
       "43              1                True  1.20   7.04  13.25  \n",
       "42              1                True  1.43   4.75   6.98  \n",
       "36              0               False  1.65   4.18   5.06  \n",
       "33              0               False  1.44   4.59   6.88  \n",
       "34              0               False  1.27   6.35  10.32  \n",
       "35              1                True  1.52   3.98   6.10  \n",
       "37              1                True  1.47   4.10   6.51  \n",
       "38              1                True  1.55   4.29   5.87  \n",
       "39              1                True  1.32   5.42   8.77  \n",
       "40              1                True  1.22   6.46  11.66  \n",
       "41              1                True  1.37   5.63   7.37  \n",
       "25              1                True  1.58   4.31   5.21  \n",
       "32              1                True  1.22   7.47  11.31  \n",
       "31              1                True  1.26   6.09  10.17  \n",
       "30              0               False  1.61   3.50   6.22  \n",
       "29              0               False  1.30   5.96   9.44  \n",
       "28              0               False  1.38   5.30   7.65  \n",
       "27              1                True  1.22   7.36  11.77  \n",
       "26              1                True  1.55   4.30   5.37  \n",
       "24              1                True  1.27   6.34  10.15  \n",
       "22              1                True  1.64   4.38   4.86  \n",
       "21              0               False  1.40   5.71   6.47  \n",
       "23              1                True  1.26   5.85  10.68  \n",
       "20              1                True  1.47   4.66   6.37  \n",
       "19              1                True  1.53   4.02   6.63  \n",
       "18              1                True  1.10  10.01  23.04  \n",
       "17              1                True  1.65   4.03   4.85  \n",
       "16              0               False  1.43   4.27   6.61  \n",
       "12              1                True  1.48   4.70   5.79  \n",
       "9               1                True  1.13   8.59  18.20  \n",
       "5               1                True  1.62   4.43   4.92  \n",
       "6               1                True  1.56   4.11   5.55  \n",
       "7               1                True  1.41   4.91   6.97  \n",
       "8               0               False  1.58   4.18   5.62  \n",
       "14              1                True  1.56   4.10   6.09  \n",
       "10              1                True  1.35   5.16   7.73  \n",
       "11              0               False  1.52   3.99   7.24  \n",
       "13              0               False  1.34   5.39   8.53  \n",
       "15              1                True  1.34   4.98   9.01  \n",
       "4               1                True  1.37   5.09   7.90  \n",
       "2               1                True  1.10   9.19  22.68  \n",
       "1               1                True  1.51   4.25   6.17  \n",
       "3               1                True  1.53   4.32   6.00  \n",
       "0               1                True  1.54   3.92   5.45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.58\n",
      "Best Accuracy: 0.64\n",
      "\n",
      "Total Predictions: 48\n",
      "Total Correct Predictions: 35\n",
      "Percentage of Correct Predictions: 72.92%\n"
     ]
    }
   ],
   "source": [
    "# Display the Correct Prediction True / False ratio, and ther percentage of correct predictions\n",
    "correct_predictions = output['Correct Prediction'].sum()\n",
    "total_predictions = len(output)\n",
    "correct_ratio = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
    "print()\n",
    "print(f\"Total Predictions: {total_predictions}\")\n",
    "print(f\"Total Correct Predictions: {correct_predictions}\")\n",
    "print(f\"Percentage of Correct Predictions: {correct_ratio * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filtered_df_val[display_columns] to a CSV file\n",
    "output.to_csv('filtered_predictions_dual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 400  # Set Frequency To 2500 Hertz\n",
    "duration = 200  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
