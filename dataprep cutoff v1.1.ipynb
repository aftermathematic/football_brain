{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = [\n",
    "    'E0', \n",
    "    'E1', \n",
    "    \n",
    "    'E2', 'E3',\n",
    "        \n",
    "    'SC0', \n",
    "    'SC1',\n",
    "\n",
    "    'D1', 'D2',\n",
    "    'F1', 'F2',\n",
    "    'I1', 'I2',\n",
    "    'SP1','SP2',\n",
    "    'B1',\n",
    "    'G1',\n",
    "    'N1',\n",
    "    'P1',\n",
    "    'T1',\n",
    "]\n",
    "\n",
    "seasons = [\n",
    "    '2324', \n",
    "    '2223', \n",
    "    '2122', \n",
    "    '2021',\n",
    "    '1920', \n",
    "    '1819', \n",
    "    #'1718', \n",
    "    #'1617',\n",
    "    #'1516', '1415', '1314', '1213',\n",
    "    #'1112', '1011', \n",
    "    #'0910', '0809',\n",
    "    #'0708', '0607', '0506', '0405',\n",
    "    #'0304', '0203', '0102', '0001',\n",
    "]\n",
    "\n",
    "countries = [\n",
    "    \"ARG\", \"AUT\", \"BRA\", \"CHN\",\n",
    "    \"DNK\", \"FIN\", \"IRL\", \"JPN\",\n",
    "    \"MEX\", \"NOR\", \"POL\", \"ROU\",\n",
    "    \"RUS\", \"SWE\", \"SWZ\", \"USA\",\n",
    "]\n",
    "\n",
    "fixtures = [\n",
    "    #\"fixtures\",\n",
    "    #\"new_league_fixtures\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataprep_start_date to the date the data preparation should start\n",
    "# If None, the data preparation will start from the beginning of the data\n",
    "\n",
    "# Make sure the file below already exists if you want to start from a specific date\n",
    "# file should be in the format \"processed_data_<content>.csv\"\n",
    "content = \"euro_6s\"\n",
    "\n",
    "dataprep_start_date = pd.Timestamp(year=2024, month=4, day=1)\n",
    "#dataprep_start_date = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all filepaths into a list\n",
    "matches_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season in seasons:    \n",
    "    for comp in comps:  \n",
    "        matches_files.append('data/scraped/%s/%s.csv' % (season, comp))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:    \n",
    "    #matches_files.append('data/scraped/other/%s.csv' % (country))\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fixture in fixtures:    \n",
    "    matches_files.append(f'data/scraped/{seasons[0]}/{fixture}.csv')\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/scraped/2324/E0.csv\n",
      "Loading data/scraped/2324/E1.csv\n",
      "Loading data/scraped/2324/E2.csv\n",
      "Loading data/scraped/2324/E3.csv\n",
      "Loading data/scraped/2324/SC0.csv\n",
      "Loading data/scraped/2324/SC1.csv\n",
      "Loading data/scraped/2324/D1.csv\n",
      "Loading data/scraped/2324/D2.csv\n",
      "Loading data/scraped/2324/F1.csv\n",
      "Loading data/scraped/2324/F2.csv\n",
      "Loading data/scraped/2324/I1.csv\n",
      "Loading data/scraped/2324/I2.csv\n",
      "Loading data/scraped/2324/SP1.csv\n",
      "Loading data/scraped/2324/SP2.csv\n",
      "Loading data/scraped/2324/B1.csv\n",
      "Loading data/scraped/2324/G1.csv\n",
      "Loading data/scraped/2324/N1.csv\n",
      "Loading data/scraped/2324/P1.csv\n",
      "Loading data/scraped/2324/T1.csv\n",
      "Loading data/scraped/2223/E0.csv\n",
      "Loading data/scraped/2223/E1.csv\n",
      "Loading data/scraped/2223/E2.csv\n",
      "Loading data/scraped/2223/E3.csv\n",
      "Loading data/scraped/2223/SC0.csv\n",
      "Loading data/scraped/2223/SC1.csv\n",
      "Loading data/scraped/2223/D1.csv\n",
      "Loading data/scraped/2223/D2.csv\n",
      "Loading data/scraped/2223/F1.csv\n",
      "Loading data/scraped/2223/F2.csv\n",
      "Loading data/scraped/2223/I1.csv\n",
      "Loading data/scraped/2223/I2.csv\n",
      "Loading data/scraped/2223/SP1.csv\n",
      "Loading data/scraped/2223/SP2.csv\n",
      "Loading data/scraped/2223/B1.csv\n",
      "Loading data/scraped/2223/G1.csv\n",
      "Loading data/scraped/2223/N1.csv\n",
      "Loading data/scraped/2223/P1.csv\n",
      "Loading data/scraped/2223/T1.csv\n",
      "Loading data/scraped/2122/E0.csv\n",
      "Loading data/scraped/2122/E1.csv\n",
      "Loading data/scraped/2122/E2.csv\n",
      "Loading data/scraped/2122/E3.csv\n",
      "Loading data/scraped/2122/SC0.csv\n",
      "Loading data/scraped/2122/SC1.csv\n",
      "Loading data/scraped/2122/D1.csv\n",
      "Loading data/scraped/2122/D2.csv\n",
      "Loading data/scraped/2122/F1.csv\n",
      "Loading data/scraped/2122/F2.csv\n",
      "Loading data/scraped/2122/I1.csv\n",
      "Loading data/scraped/2122/I2.csv\n",
      "Loading data/scraped/2122/SP1.csv\n",
      "Loading data/scraped/2122/SP2.csv\n",
      "Loading data/scraped/2122/B1.csv\n",
      "Loading data/scraped/2122/G1.csv\n",
      "Loading data/scraped/2122/N1.csv\n",
      "Loading data/scraped/2122/P1.csv\n",
      "Loading data/scraped/2122/T1.csv\n",
      "Loading data/scraped/2021/E0.csv\n",
      "Loading data/scraped/2021/E1.csv\n",
      "Loading data/scraped/2021/E2.csv\n",
      "Loading data/scraped/2021/E3.csv\n",
      "Loading data/scraped/2021/SC0.csv\n",
      "Loading data/scraped/2021/SC1.csv\n",
      "Loading data/scraped/2021/D1.csv\n",
      "Loading data/scraped/2021/D2.csv\n",
      "Loading data/scraped/2021/F1.csv\n",
      "Loading data/scraped/2021/F2.csv\n",
      "Loading data/scraped/2021/I1.csv\n",
      "Loading data/scraped/2021/I2.csv\n",
      "Loading data/scraped/2021/SP1.csv\n",
      "Loading data/scraped/2021/SP2.csv\n",
      "Loading data/scraped/2021/B1.csv\n",
      "Loading data/scraped/2021/G1.csv\n",
      "Loading data/scraped/2021/N1.csv\n",
      "Loading data/scraped/2021/P1.csv\n",
      "Loading data/scraped/2021/T1.csv\n",
      "Loading data/scraped/1920/E0.csv\n",
      "Loading data/scraped/1920/E1.csv\n",
      "Loading data/scraped/1920/E2.csv\n",
      "Loading data/scraped/1920/E3.csv\n",
      "Loading data/scraped/1920/SC0.csv\n",
      "Loading data/scraped/1920/SC1.csv\n",
      "Loading data/scraped/1920/D1.csv\n",
      "Loading data/scraped/1920/D2.csv\n",
      "Loading data/scraped/1920/F1.csv\n",
      "Loading data/scraped/1920/F2.csv\n",
      "Loading data/scraped/1920/I1.csv\n",
      "Loading data/scraped/1920/I2.csv\n",
      "Loading data/scraped/1920/SP1.csv\n",
      "Loading data/scraped/1920/SP2.csv\n",
      "Loading data/scraped/1920/B1.csv\n",
      "Loading data/scraped/1920/G1.csv\n",
      "Loading data/scraped/1920/N1.csv\n",
      "Loading data/scraped/1920/P1.csv\n",
      "Loading data/scraped/1920/T1.csv\n",
      "Loading data/scraped/1819/E0.csv\n",
      "Loading data/scraped/1819/E1.csv\n",
      "Loading data/scraped/1819/E2.csv\n",
      "Loading data/scraped/1819/E3.csv\n",
      "Loading data/scraped/1819/SC0.csv\n",
      "Error: data/scraped/1819/SC0.csv not found\n",
      "Loading data/scraped/1819/SC1.csv\n",
      "Loading data/scraped/1819/D1.csv\n",
      "Loading data/scraped/1819/D2.csv\n",
      "Loading data/scraped/1819/F1.csv\n",
      "Loading data/scraped/1819/F2.csv\n",
      "Loading data/scraped/1819/I1.csv\n",
      "Loading data/scraped/1819/I2.csv\n",
      "Error: data/scraped/1819/I2.csv not found\n",
      "Loading data/scraped/1819/SP1.csv\n",
      "Loading data/scraped/1819/SP2.csv\n",
      "Loading data/scraped/1819/B1.csv\n",
      "Loading data/scraped/1819/G1.csv\n",
      "Loading data/scraped/1819/N1.csv\n",
      "Loading data/scraped/1819/P1.csv\n",
      "Loading data/scraped/1819/T1.csv\n",
      "Data loaded: 39379 matches\n"
     ]
    }
   ],
   "source": [
    "# Load and concatenate matches data into a single DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in matches_files:\n",
    "\n",
    "    try:\n",
    "\n",
    "        year = re.search(r'(\\d{4})', file).group(1)\n",
    "        print(f'Loading {file}')\n",
    "\n",
    "        df_temp = pd.read_csv(file)\n",
    "\n",
    "        # add the year to the dataframe as a column 'Season'\n",
    "        df_temp['Season'] = year\n",
    "\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "    except:\n",
    "        # print an error message\n",
    "        print(f'Error: {file} not found')\n",
    "\n",
    "# print the amount of data loaded\n",
    "print(f\"Data loaded: {df.shape[0]} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns if they exist\n",
    "df.rename(columns={\n",
    "    'Country': 'Div',\n",
    "    'Home': 'HomeTeam',\n",
    "    'Away': 'AwayTeam',\n",
    "    'Res': 'FTR',\n",
    "\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate column names\n",
    "print(df.columns[df.columns.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Div' to a categorical type, a numeric representation of the division\n",
    "df['Div'] = df['Div'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max index: 493\n"
     ]
    }
   ],
   "source": [
    "file_path = f\"data/teams_dict_{content}.txt\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load the dictionary from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        teams_dict = eval(file.read())  # Using eval to convert string back to dictionary\n",
    "    # Find the maximum index currently in the dictionary\n",
    "    max_index = max(teams_dict.values())\n",
    "\n",
    "    print(f\"max index: {max_index}\")\n",
    "else:\n",
    "    teams_dict = {}\n",
    "    max_index = -1  # Start from -1 so the first new index will be 0\n",
    "\n",
    "# Get all teams from DataFrame\n",
    "all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).dropna().unique()\n",
    "all_teams.sort()\n",
    "\n",
    "# Create a dictionary of new teams alone\n",
    "new_teams = {team: index for index, team in enumerate(all_teams) if team not in teams_dict}\n",
    "\n",
    "# Update dictionary only with new teams, starting indices from max_index + 1\n",
    "start_index = max_index + 1\n",
    "teams_dict.update({team: index + start_index for index, team in enumerate(new_teams) if team not in teams_dict})\n",
    "\n",
    "# Save the updated dictionary to a file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(str(teams_dict))\n",
    "\n",
    "# Add team ID columns to DataFrame\n",
    "df['Team_ID'] = df['HomeTeam'].map(teams_dict)\n",
    "df['Opp_ID'] = df['AwayTeam'].map(teams_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ELO ratings for each team\n",
    "\n",
    "# Initialize ratings dictionary\n",
    "teams = pd.concat([df['Team_ID'], df['Opp_ID']]).unique()\n",
    "ratings = {team: 1500 for team in teams}\n",
    "\n",
    "def calculate_expected_score(rating_a, rating_b):\n",
    "    return 1 / (1 + 10 ** ((rating_b - rating_a) / 400))\n",
    "\n",
    "def update_elo(rating, actual_score, expected_score, k=30):\n",
    "\n",
    "    rating = rating + k * (actual_score - expected_score)\n",
    "\n",
    "    # Parse the rating as an integer with no decimal points\n",
    "    return int(rating)\n",
    "\n",
    "# Iterate over the DataFrame and update ELO ratings after each match\n",
    "elo_team = []\n",
    "elo_opp = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    home_team, away_team, home_score, away_score = row['Team_ID'], row['Opp_ID'], row['FTHG'], row['FTAG']\n",
    "    home_rating = ratings[home_team]\n",
    "    away_rating = ratings[away_team]\n",
    "    \n",
    "    # Calculate expected scores\n",
    "    expected_home = calculate_expected_score(home_rating, away_rating)\n",
    "    expected_away = calculate_expected_score(away_rating, home_rating)\n",
    "    \n",
    "    # Calculate actual scores\n",
    "    actual_home = 1 if home_score > away_score else 0.5 if home_score == away_score else 0\n",
    "    actual_away = 1 - actual_home\n",
    "    \n",
    "    # Update ratings\n",
    "    new_home_rating = update_elo(home_rating, actual_home, expected_home)\n",
    "    new_away_rating = update_elo(away_rating, actual_away, expected_away)\n",
    "    \n",
    "    # Store updated ratings in the ratings dictionary\n",
    "    ratings[home_team] = new_home_rating\n",
    "    ratings[away_team] = new_away_rating\n",
    "    \n",
    "    # Append current ratings to list\n",
    "    elo_team.append(new_home_rating)\n",
    "    elo_opp.append(new_away_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign new ELO ratings to the DataFrame\n",
    "df['team_elo'] = elo_team\n",
    "df['opp_elo'] = elo_opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home field advantage: Add 100 to 'team_elo'\n",
    "#df['team_elo'] = df['team_elo'] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_to_int(date_str):\n",
    "    # Split the date_str by the \"/\" character into day, month, year\n",
    "    components = date_str.split('/')\n",
    "    \n",
    "    # If split was successful but not in expected format, try splitting by absence of separator for '%d%m%Y' or '%d%m%y'\n",
    "    if len(components) == 1:\n",
    "        if len(date_str) in [6, 8]:  # Length 6 for '%d%m%y', 8 for '%d%m%Y'\n",
    "            day, month = int(date_str[:2]), int(date_str[2:4])\n",
    "            year = int(date_str[4:])\n",
    "        else:\n",
    "            return 19000101  # Return default if format does not match expected\n",
    "    else:\n",
    "        day, month = int(components[0]), int(components[1])\n",
    "        year = int(components[2])\n",
    "    \n",
    "    # Adjust the year if it was only 2 characters long\n",
    "    if year < 100:\n",
    "        year += 2000\n",
    "    \n",
    "    # Create a date variable by using the day, month, year integers\n",
    "    # Note: Direct creation of date variable skipped to avoid unnecessary complexity,\n",
    "    # directly formatting to YYYYMMDD integer format instead.\n",
    "    date_int = int(f\"{year:04d}{month:02d}{day:02d}\")\n",
    "    \n",
    "    return date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Apply the modified function\n",
    "df['Date_temp'] = df['Date'].apply(lambda x: parse_date_to_int(x.strftime('%d/%m/%Y')) if pd.notnull(x) else 19000101)\n",
    "\n",
    "# Day of the week as an integer\n",
    "df['DayOTW'] = df['Date'].dt.dayofweek\n",
    "\n",
    "df['Time'] = df['Time'].fillna('00:00').str.replace(':', '').astype(int)\n",
    "\n",
    "# Only keep the first 2 digits of the Time column, no decimals\n",
    "df['Time'] = df['Time'] // 100\n",
    "\n",
    "# Sort df by Date_temp and Time\n",
    "df = df.sort_values(['Date_temp', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [re.sub(r'[<]', '_st_', str(col)) for col in df.columns]\n",
    "df.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points(df, row, team_column):\n",
    "    # Initialize points\n",
    "    total_points = 0\n",
    "\n",
    "    # Season of the current match\n",
    "    current_season = row['Season']\n",
    "\n",
    "    # Date of the current match\n",
    "    current_date = row['Date']\n",
    "\n",
    "    # Define the opponent column based on the team column\n",
    "    if team_column == 'Team_ID':\n",
    "        home_team_col = 'Team_ID'\n",
    "        away_team_col = 'Opp_ID'\n",
    "    else:\n",
    "        home_team_col = 'Opp_ID'\n",
    "        away_team_col = 'Team_ID'\n",
    "\n",
    "    # Filter DataFrame for matches from the same season before the current date\n",
    "    past_matches = df[\n",
    "        (df['Season'] == current_season) & \n",
    "        (df['Date'] < current_date) &\n",
    "        ((df[home_team_col] == row[team_column]) | (df[away_team_col] == row[team_column]))\n",
    "    ]\n",
    "\n",
    "    # Calculate points based on the results\n",
    "    for match in past_matches.itertuples():\n",
    "        if (getattr(match, home_team_col) == row[team_column] and getattr(match, 'FTR') == 'H') or \\\n",
    "           (getattr(match, away_team_col) == row[team_column] and getattr(match, 'FTR') == 'A'):\n",
    "            total_points += 3  # Win\n",
    "        elif getattr(match, 'FTR') == 'D':\n",
    "            total_points += 1  # Draw\n",
    "\n",
    "    total_points = round(total_points, 0)\n",
    "\n",
    "    return total_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_points'] = df.apply(lambda x: points(df, x, 'Team_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)\n",
    "df['opp_points'] = df.apply(lambda x: points(df, x, 'Opp_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_vs_opponent_weighted(df, row, team_column):\n",
    "    # Determine opponent column based on team column\n",
    "    opponent_column = 'Team_ID' if team_column == 'Opp_ID' else 'Opp_ID'\n",
    "\n",
    "    # Combine year, month, and day into an integer 'Date_temp'\n",
    "    row_date_temp = row['Date'].year * 10000 + row['Date'].month * 100 + row['Date'].day\n",
    "\n",
    "    # Filter for matches between specified teams, excluding current match\n",
    "    mask = (\n",
    "        ((df[team_column] == row[team_column]) & (df[opponent_column] == row[opponent_column])) |\n",
    "        ((df[team_column] == row[opponent_column]) & (df[opponent_column] == row[team_column]))\n",
    "    ) & (df['Date_temp'] < row_date_temp)\n",
    "\n",
    "    filtered_matches = df[mask]\n",
    "    \n",
    "    if filtered_matches.empty:\n",
    "        return 0  # Return early if no matches found\n",
    "\n",
    "    # Sort by date and select top 5 recent matches\n",
    "    recent_matches = filtered_matches.sort_values(by='Date', ascending=False).head(5)\n",
    "    weights = list(range(len(recent_matches), 0, -1))  # Descending weights\n",
    "\n",
    "    # Calculate weighted score based on match results\n",
    "    weighted_score = sum(\n",
    "        (3 * weight if match.FTR == 'H' and match.__getattribute__(team_column) == match.Team_ID or\n",
    "                      match.FTR == 'A' and match.__getattribute__(team_column) != match.Team_ID else\n",
    "         1 * weight if match.FTR == 'D' else 0)\n",
    "        for match, weight in zip(recent_matches.itertuples(), weights)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize the weighted score by the sum of weights\n",
    "    return round(weighted_score / sum(weights), 3) if weights else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Team_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)\n",
    "df['opp_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Opp_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_odds(row):\n",
    "    odds_win, odds_draw, odds_lose = row['AvgH'], row['AvgD'], row['AvgA']\n",
    "    prob_win = 1 / odds_win\n",
    "    prob_draw = 1 / odds_draw\n",
    "    prob_lose = 1 / odds_lose\n",
    "    prob_not_win = prob_draw + prob_lose\n",
    "    return pd.Series([prob_win, prob_not_win], index=['probs_win', 'probs_not_win'])\n",
    "\n",
    "# Apply the function and create new columns\n",
    "#df[['probs_win', 'probs_not_win']] = df.apply(convert_odds, axis=1)\n",
    "\n",
    "#df = df.drop(columns=['AvgH', 'AvgD', 'AvgA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_form(df, row, perspective):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Initialize points\n",
    "    points = 0\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Calculate points with weights\n",
    "    weighted_points_sum = 0\n",
    "    total_weights = sum(weights[:len(past_matches)])  # Adjust the total weight in case of less than 5 matches\n",
    "    \n",
    "    for match, weight in zip(past_matches.itertuples(), weights):\n",
    "        if (match.Team_ID == team_id and match.FTR == 'H') or (match.Opp_ID == team_id and match.FTR == 'A'):\n",
    "            points += 3\n",
    "        elif match.FTR == 'D':\n",
    "            points += 1\n",
    "        else:\n",
    "            points += 0\n",
    "\n",
    "        weighted_points_sum += points * weight\n",
    "    \n",
    "    if total_weights > 0:\n",
    "\n",
    "        team_form = round(weighted_points_sum / total_weights, 2)\n",
    "\n",
    "        return team_form\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_form'] = df.apply(lambda x: team_form(df, x, 'Team') if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)\n",
    "df['opp_form'] = df.apply(lambda x: team_form(df, x, 'Opp') if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avgs_combined(df, row, perspective):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past 5 matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Initialize sums and weighted sums\n",
    "    shots = []\n",
    "    shots_target = []\n",
    "    \n",
    "    # Determine which columns to use and collect the values\n",
    "    for match in past_matches.itertuples():\n",
    "        if match.Team_ID == team_id:\n",
    "            shots.append(getattr(match, 'HS'))  # Home shots\n",
    "            shots_target.append(getattr(match, 'HST'))  # Home shots on target\n",
    "        else:\n",
    "            shots.append(getattr(match, 'AS'))  # Away shots\n",
    "            shots_target.append(getattr(match, 'AST'))  # Away shots on target\n",
    "    \n",
    "    # Calculate the weighted averages of the values\n",
    "    weighted_shots = sum(s * w for s, w in zip(shots, weights))\n",
    "    weighted_shots_target = sum(st * w for st, w in zip(shots_target, weights))\n",
    "    total_weights = sum(weights[:len(shots)])  # Adjust total weight if there are less than 5 matches\n",
    "    \n",
    "    avg_shots = weighted_shots / total_weights if total_weights > 0 else 0\n",
    "    avg_shots_target = weighted_shots_target / total_weights if total_weights > 0 else 0\n",
    "\n",
    "    # Round the averages to 2 decimal places\n",
    "    avg_shots = round(avg_shots, 2)\n",
    "    avg_shots_target = round(avg_shots_target, 2)\n",
    "    \n",
    "    return avg_shots, avg_shots_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_shots'], df['team_shots_target'] = zip(*df.apply(lambda x: rolling_avgs_combined(df, x, 'Team') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))\n",
    "df['opp_shots'], df['opp_shots_target'] = zip(*df.apply(lambda x: rolling_avgs_combined(df, x, 'Opp') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Average games played in the last 50 days\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "def avg_games_played(df, row, team_column):\n",
    "    team = row[team_column]\n",
    "    # Ensure current_match_date is a Timestamp for comparison\n",
    "    current_match_date = pd.to_datetime(row['Date'], dayfirst=True)  # Assuming 'Date' format is 'dd/mm/yy'\n",
    "\n",
    "    delta = 60\n",
    "    start_date = current_match_date - timedelta(days=delta)\n",
    "\n",
    "    # Ensure 'Date' column is in datetime format for comparison\n",
    "    #df['Date_temp'] = pd.to_datetime(df['Date'], dayfirst=True)  # Convert 'Date' column to datetime if not already done\n",
    "\n",
    "    # Filter the DataFrame for matches within the last 30 days\n",
    "    if team_column == 'Team_ID':\n",
    "        past_matches = df[((df[team_column] == team) | (df['Opp_ID'] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "    else:\n",
    "        past_matches = df[((df['Team_ID'] == team) | (df[team_column] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "\n",
    "    # If no matches were played in the last 30 days\n",
    "    if past_matches.empty:\n",
    "        return 0\n",
    "\n",
    "    # Calculate weights based on the recency of each match\n",
    "    weights = (current_match_date - past_matches['Date']).dt.days\n",
    "    weighted_count = sum(delta - weights + 1)  # '+ 1' to include the match day in the weight\n",
    "\n",
    "    # Normalize weights to sum to 1 and calculate the weighted average\n",
    "    total_weight = sum(delta - weights + 1)\n",
    "    weighted_avg = weighted_count / total_weight\n",
    "\n",
    "    return weighted_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function for each team and opponent\n",
    "df['team_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Team_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)\n",
    "df['opp_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Opp_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_goals(df, row, team_column):\n",
    "    # Season and date of the current match\n",
    "    current_season = row['Season']\n",
    "    current_date = row['Date']\n",
    "\n",
    "    # Determine the columns for goals scored and conceded based on perspective\n",
    "    if team_column == 'Team_ID':\n",
    "        goals_scored_column = 'FTHG'  # Assuming FTHG is the column for home team goals\n",
    "        goals_conceded_column = 'FTAG'  # Assuming FTAG is the column for away team goals\n",
    "    else:\n",
    "        goals_scored_column = 'FTAG'  # Flip the columns if we are looking from the opponent's perspective\n",
    "        goals_conceded_column = 'FTHG'\n",
    "\n",
    "    # Filter matches from the same season and before the current date\n",
    "    past_matches = df[\n",
    "        (df['Season'] == current_season) & \n",
    "        (df['Date'] < current_date) & \n",
    "        ((df['Team_ID'] == row[team_column]) | (df['Opp_ID'] == row[team_column]))\n",
    "    ]\n",
    "\n",
    "    # Calculate the average goals scored and conceded\n",
    "    goals_scored = 0\n",
    "    goals_conceded = 0\n",
    "    total_matches = len(past_matches)\n",
    "\n",
    "    for match in past_matches.itertuples():\n",
    "        if getattr(match, 'Team_ID') == row[team_column]:  # Team is playing at home\n",
    "            goals_scored += getattr(match, goals_scored_column)\n",
    "            goals_conceded += getattr(match, goals_conceded_column)\n",
    "        else:  # Team is playing away\n",
    "            goals_scored += getattr(match, goals_scored_column)\n",
    "            goals_conceded += getattr(match, goals_conceded_column)\n",
    "\n",
    "    avg_goals_for = goals_scored / total_matches if total_matches > 0 else 0\n",
    "    avg_goals_against = goals_conceded / total_matches if total_matches > 0 else 0\n",
    "\n",
    "    # Round the averages to 3 decimal places\n",
    "    avg_goals_for = round(avg_goals_for, 2)\n",
    "    avg_goals_against = round(avg_goals_against, 2)\n",
    "\n",
    "    return avg_goals_for, avg_goals_against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function and create new columns\n",
    "df['team_avg_goals_for'], df['team_avg_goals_against'] = zip(*df.apply(lambda x: avg_goals(df, x, 'Team_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))\n",
    "df['opp_avg_goals_for'], df['opp_avg_goals_against'] = zip(*df.apply(lambda x: avg_goals(df, x, 'Opp_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected goals for each team in a match\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit a logistic regression model to the entire dataset\n",
    "X_home = df[['HST']]  # Predictor for home team\n",
    "X_away = df[['AST']]  # Predictor for away team\n",
    "y_home = np.where(df['FTHG'] > df['FTAG'], 1, 0)  # Home wins\n",
    "y_away = np.where(df['FTAG'] > df['FTHG'], 1, 0)  # Away wins\n",
    "\n",
    "# Impute missing values with the mean\n",
    "X_home = X_home.fillna(X_home.mean())\n",
    "X_away = X_away.fillna(X_away.mean())\n",
    "\n",
    "model_home = LogisticRegression()\n",
    "model_away = LogisticRegression()\n",
    "model_home.fit(X_home, y_home)\n",
    "model_away.fit(X_away, y_away)\n",
    "\n",
    "team_xg = np.round(model_home.predict_proba(X_home)[:, 1], 3)\n",
    "opp_xg = np.round(model_away.predict_proba(X_away)[:, 1], 3)\n",
    "\n",
    "# Predicting probabilities for xG\n",
    "df['team_xg'] = team_xg\n",
    "df['opp_xg'] = opp_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means only for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "means = df[numeric_cols].mean()\n",
    "\n",
    "# Fill missing values in numeric columns with their respective means\n",
    "df[numeric_cols] = df[numeric_cols].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the FTR to 'X' where the value is currently NaN\n",
    "df['FTR'] = df['FTR'].fillna('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop every row where 'FTR' is not 'H', 'D', or 'A', or 'X' (if future matches are included)\n",
    "df = df[df['FTR'].isin(['H', 'D', 'A', 'X'])]\n",
    "\n",
    "# Map 'H', 'D', and 'A' to 0, 1, and 2 respectively\n",
    "df['FTR'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2, 'X': -1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    \n",
    "        'Div', 'Season', 'Date_temp', 'Time', 'DayOTW', 'Team_ID', 'Opp_ID', 'FTR',\n",
    "\n",
    "        'team_elo', 'opp_elo',\n",
    "\n",
    "        'team_xg', 'opp_xg',\n",
    "        \n",
    "        'team_hist_vs', \n",
    "        'opp_hist_vs',\n",
    "\n",
    "        'team_points',\n",
    "        'opp_points',\n",
    "        \n",
    "        'team_form', \n",
    "        'opp_form',\n",
    "\n",
    "        'team_avg_goals_for', \n",
    "        'team_avg_goals_against',\n",
    "        'opp_avg_goals_for',\n",
    "        'opp_avg_goals_against',\n",
    "         \n",
    "        'team_shots', 'opp_shots',\n",
    "        'team_shots_target', 'opp_shots_target',\n",
    "\n",
    "        'team_avg_games', 'opp_avg_games',\n",
    "\n",
    "        'AvgH', 'AvgD', 'AvgA'\n",
    "         \n",
    "         \n",
    "         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date_temp</th>\n",
       "      <th>Time</th>\n",
       "      <th>DayOTW</th>\n",
       "      <th>Team_ID</th>\n",
       "      <th>Opp_ID</th>\n",
       "      <th>FTR</th>\n",
       "      <th>team_elo</th>\n",
       "      <th>opp_elo</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_avg_goals_against</th>\n",
       "      <th>team_shots</th>\n",
       "      <th>opp_shots</th>\n",
       "      <th>team_shots_target</th>\n",
       "      <th>opp_shots_target</th>\n",
       "      <th>team_avg_games</th>\n",
       "      <th>opp_avg_games</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36379</th>\n",
       "      <td>8</td>\n",
       "      <td>1819</td>\n",
       "      <td>20180727</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>448</td>\n",
       "      <td>2</td>\n",
       "      <td>1475</td>\n",
       "      <td>1520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6326</td>\n",
       "      <td>3.745034</td>\n",
       "      <td>3.950591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36380</th>\n",
       "      <td>8</td>\n",
       "      <td>1819</td>\n",
       "      <td>20180727</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>344</td>\n",
       "      <td>1</td>\n",
       "      <td>1495</td>\n",
       "      <td>1405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6326</td>\n",
       "      <td>3.745034</td>\n",
       "      <td>3.950591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36381</th>\n",
       "      <td>8</td>\n",
       "      <td>1819</td>\n",
       "      <td>20180727</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>1525</td>\n",
       "      <td>1368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6326</td>\n",
       "      <td>3.745034</td>\n",
       "      <td>3.950591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36382</th>\n",
       "      <td>8</td>\n",
       "      <td>1819</td>\n",
       "      <td>20180727</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>204</td>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>1427</td>\n",
       "      <td>1361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6326</td>\n",
       "      <td>3.745034</td>\n",
       "      <td>3.950591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36383</th>\n",
       "      <td>8</td>\n",
       "      <td>1819</td>\n",
       "      <td>20180727</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>309</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>1373</td>\n",
       "      <td>1510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6326</td>\n",
       "      <td>3.745034</td>\n",
       "      <td>3.950591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Div Season  Date_temp  Time  DayOTW  Team_ID  Opp_ID  FTR  team_elo  \\\n",
       "36379    8   1819   20180727     0       4        7     448    2      1475   \n",
       "36380    8   1819   20180727     0       4        8     344    1      1495   \n",
       "36381    8   1819   20180727     0       4      113     106    1      1525   \n",
       "36382    8   1819   20180727     0       4      204     406    0      1427   \n",
       "36383    8   1819   20180727     0       4      309      61    2      1373   \n",
       "\n",
       "       opp_elo  ...  opp_avg_goals_against  team_shots  opp_shots  \\\n",
       "36379     1520  ...                    0.0         0.0        0.0   \n",
       "36380     1405  ...                    0.0         0.0        0.0   \n",
       "36381     1368  ...                    0.0         0.0        0.0   \n",
       "36382     1361  ...                    0.0         0.0        0.0   \n",
       "36383     1510  ...                    0.0         0.0        0.0   \n",
       "\n",
       "       team_shots_target  opp_shots_target  team_avg_games  opp_avg_games  \\\n",
       "36379                0.0               0.0             1.0            1.0   \n",
       "36380                0.0               0.0             1.0            1.0   \n",
       "36381                0.0               0.0             1.0            1.0   \n",
       "36382                0.0               0.0             1.0            1.0   \n",
       "36383                0.0               0.0             1.0            1.0   \n",
       "\n",
       "         AvgH      AvgD      AvgA  \n",
       "36379  2.6326  3.745034  3.950591  \n",
       "36380  2.6326  3.745034  3.950591  \n",
       "36381  2.6326  3.745034  3.950591  \n",
       "36382  2.6326  3.745034  3.950591  \n",
       "36383  2.6326  3.745034  3.950591  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Date_temp' to 'Date'\n",
    "df.rename(columns={'Date_temp': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved: 39379 matches\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "   \n",
    "    if dataprep_start_date is not None:\n",
    "        # Convert date columns to datetime\n",
    "        df['Date_temp'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
    "        \n",
    "        # Filter new data based on start date\n",
    "        df_new = df[df['Date_temp'] >= dataprep_start_date].copy()\n",
    "\n",
    "        # Load existing data\n",
    "        df_existing = pd.read_csv(f'data/processed/processed_data_{content}.csv')\n",
    "        df_existing['Date_temp'] = pd.to_datetime(df_existing['Date'], format='%Y%m%d')\n",
    "        \n",
    "        # Filter existing data to remove overlap with new data\n",
    "        df_existing = df_existing[df_existing['Date_temp'] < dataprep_start_date]\n",
    "\n",
    "        # Combine and sort data\n",
    "        df_final = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        df_final.sort_values(['Date_temp', 'Time'], inplace=True)\n",
    "\n",
    "        # Clean up temporary columns\n",
    "        df_final.drop(columns='Date_temp', inplace=True)\n",
    "    else:\n",
    "        df_final = df.copy()\n",
    "\n",
    "    # Save the final DataFrame\n",
    "    df_final.to_csv(f'data/processed/processed_data_{content}.csv', index=False)\n",
    "    print(f\"Data saved: {df_final.shape[0]} matches\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 400  # Set Frequency To 2500 Hertz\n",
    "duration = 200  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
