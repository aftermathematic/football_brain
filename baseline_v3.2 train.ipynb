{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"big5_7s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data csv into a DataFrame\n",
    "df = pd.read_csv(f'data/processed/processed_data_{content}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the date_temp column, which is in YYYYMMDD format, into a datetime object, and store in a new column 'date_temporary'\n",
    "df['date_temporary'] = pd.to_datetime(df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the current date dynamically\n",
    "date_today = pd.Timestamp.now().normalize()  # .normalize() sets the time to 00:00:00\n",
    "\n",
    "# Calculate the date 2 weeks ago from the current date\n",
    "date_2_weeks_ago = date_today - pd.DateOffset(days=10)\n",
    "\n",
    "date_cutoff = date_today - pd.DateOffset(days=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows where the date_temporary column is older than date_cutoff\n",
    "df = df[df['date_temporary'] >= date_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_validationset = df.tail(250)\n",
    "#df = df.iloc[:-250]\n",
    "\n",
    "# define df_validationset as all the rows in df where the date_temporary column is greater than date_2_weeks_ago\n",
    "df_validationset = df[df['date_temporary'] > date_2_weeks_ago]\n",
    "\n",
    "# define df as all the rows in df where the date_temporary column is less than or equal to date_2_weeks_ago\n",
    "df = df[df['date_temporary'] <= date_2_weeks_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5221, 73)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(df_validationset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the date_temporary column\n",
    "df.drop(columns=['date_temporary'], inplace=True)\n",
    "df_validationset.drop(columns=['date_temporary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "teams_dict = {}\n",
    "\n",
    "# Assuming 'teams_dict.txt' contains the dictionary as a single string\n",
    "with open(f'data/teams_dict_{content}.txt', 'r') as file:\n",
    "    # Read the entire file content into a single string\n",
    "    data = file.read()\n",
    "    # Safely evaluate the string as a Python dictionary\n",
    "    teams_dict = ast.literal_eval(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the df and df_validationset DataFrames by the 'Date', 'Div', 'Time' columns\n",
    "df.sort_values(['Date', 'Div', 'Time'], inplace=True)\n",
    "df_validationset.sort_values(['Date', 'Div', 'Time'], inplace=True)\n",
    "\n",
    "# Set the 'Date' and 'FTR2' column as the index\n",
    "df.set_index(['Date', 'FTR2'], inplace=True)\n",
    "df_validationset.set_index(['Date', 'FTR2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X and y\n",
    "X = df.drop('FTR', axis=1)\n",
    "y = df['FTR']\n",
    "\n",
    "X.columns = [re.sub(r'[<]', '_st_', str(col)) for col in X.columns]\n",
    "X.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in X.columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_windows(X, window_size, step):\n",
    "    n_samples = len(X)\n",
    "    windows = []\n",
    "    for start_idx in range(0, n_samples - window_size + 1, step):\n",
    "        end_idx = start_idx + window_size\n",
    "        if end_idx > n_samples:\n",
    "            break  # Avoid going beyond the dataset\n",
    "        train_indices = list(range(max(0, start_idx - window_size), start_idx))\n",
    "        test_indices = list(range(start_idx, end_idx))\n",
    "        windows.append((train_indices, test_indices))\n",
    "    return windows\n",
    "\n",
    "negative_count = len(df[df['FTR'] == 0])\n",
    "positive_count = len(df[df['FTR'] == 1])\n",
    "scale_pos_weight_value = negative_count / positive_count\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_dist = {\n",
    "    \n",
    "    'xgb__clf__max_depth': [1,2,3],\n",
    "    'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "    #'rf__clf__max_depth': [None, 4, 6],\n",
    "    #'rf__clf__min_samples_split': [2, 5],\n",
    "    #'rf__clf__min_samples_leaf': [1, 2],\n",
    "    #'rf__clf__bootstrap': [True, False],\n",
    "    #'rf__clf__n_estimators': [50, 100, 200],\n",
    "\n",
    "    'lr__clf__C': [0.1, 1, 10],  # Inverse of regularization strength; smaller values specify stronger regularization.\n",
    "    'lr__clf__penalty': ['l1', 'l2', 'elasticnet'],  # Specify the norm of the penalty.\n",
    "    'lr__clf__solver': ['saga'],  # Algorithm to use in the optimization problem, 'saga' supports all penalties.\n",
    "    'lr__clf__l1_ratio': [0.5],  # The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'.\n",
    "\n",
    "    #'cat__clf__depth': [1,2,3,4],\n",
    "    #'cat__clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    #'cat__clf__iterations': [50, 100, 200],\n",
    "    #'cat__clf__l2_leaf_reg': [1, 3, 5],\n",
    "\n",
    "    'gb__clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gb__clf__n_estimators': [50, 100, 200],\n",
    "    'gb__clf__max_depth': [3, 5, 7],\n",
    "    'gb__clf__min_samples_split': [2, 5],\n",
    "    'gb__clf__min_samples_leaf': [1, 2],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "param_test = {\n",
    "    \n",
    "    'xgb__clf__max_depth': [1,2,3],\n",
    "    'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a custom scoring function\n",
    "def xgb_early_stopping_score(y, estimator, X, y_true, sample_weight=None):\n",
    "    \"\"\"\n",
    "    Custom scorer that uses early stopping.\n",
    "    \"\"\"\n",
    "    # Split X into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_true, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit with early stopping\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    estimator.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_set, verbose=False)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = estimator.predict(X_val)\n",
    "    \n",
    "    # Return the F1 score\n",
    "    return f1_score(y_val, y_pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Training Data Shape: (5221, 17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 100, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.1, 'xgb__clf__lambda': 1.5, 'xgb__clf__alpha': 1, 'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 10, 'gb__clf__n_estimators': 100, 'gb__clf__min_samples_split': 2, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 5, 'gb__clf__learning_rate': 0.1}\n",
      "Precision: 0.8816318712890251\n",
      "\n",
      "\n",
      "Best F1 Score: 0.8671539122957868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      2912\n",
      "           1       0.86      0.87      0.87      2309\n",
      "\n",
      "    accuracy                           0.88      5221\n",
      "   macro avg       0.88      0.88      0.88      5221\n",
      "weighted avg       0.88      0.88      0.88      5221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the F1 score for the '1' class\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_f1_params = None\n",
    "best_window_size = None\n",
    "best_precision = 0\n",
    "best_model = None \n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Make the custom scorer\n",
    "custom_scorer = make_scorer(xgb_early_stopping_score, greater_is_better=True, needs_proba=False, X=X, y_true=y)\n",
    "\n",
    "# Set the window_size and step to 5% of the dataset\n",
    "window_size = int(len(X) * 1)\n",
    "step = int(len(X) * 1)\n",
    "\n",
    "# Initialize an empty list to store precision scores\n",
    "precision_scores = []\n",
    "\n",
    "# Initialize an empty dataframe to store misclassified samples\n",
    "misclassified_samples = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "# Generate windows\n",
    "window_splits = generate_sliding_windows(X, window_size, step)\n",
    "\n",
    "# Initialize training indices with the first window\n",
    "train_end_index = window_size\n",
    "\n",
    "# Iterate over each sliding window\n",
    "for i, (train_index, test_index) in enumerate(window_splits):\n",
    "\n",
    "    # Update training indices to include the next window\n",
    "    train_index = list(range(train_end_index))\n",
    "    train_end_index += window_size\n",
    "\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"Iteration {i+1} Training Data Shape: {X_train.shape}\")\n",
    "\n",
    "    # Combine misclassified samples from previous iterations with current training data\n",
    "    if not misclassified_samples.empty:\n",
    "        X_train_combined = pd.concat([X_train, misclassified_samples[X_train.columns]], axis=0)\n",
    "        y_train_combined = pd.concat([y_train, misclassified_samples['FTR']], axis=0)\n",
    "    else:\n",
    "        X_train_combined = X_train\n",
    "        y_train_combined = y_train\n",
    "\n",
    "    # Calculate misclassification frequency\n",
    "    misclassified_freq = y_train_combined.value_counts(normalize=True)\n",
    "\n",
    "    # Define class weights based on misclassification frequency\n",
    "    class_weights = {0: 1, 1: max(0.6, 5 - misclassified_freq.get(1, 0.5))}  # Adjust dynamically to penalize misclassification of class 1 more heavily\n",
    "\n",
    "    # Define pipelines for each classifier with SMOTE and TargetEncoder\n",
    "    pipeline_xgb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', XGBClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    pipeline_gb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', GradientBoostingClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for logistic regression\n",
    "    pipeline_lr = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for catboost classifier\n",
    "    pipeline_cat = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', CatBoostClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for random forest\n",
    "    pipeline_rf = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', RandomForestClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # LightGBM pipeline\n",
    "    pipeline_lgbm = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LGBMClassifier(random_state=42, force_col_wise='true', verbose=0))\n",
    "    ])\n",
    "\n",
    "    # Adaboost pipeline\n",
    "    pipeline_ada = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', AdaBoostClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Combine them into an ensemble classifier\n",
    "    ensemble_clf = VotingClassifier(estimators=[\n",
    "        ('xgb', pipeline_xgb),\n",
    "        ('gb', pipeline_gb),\n",
    "        ('lr', pipeline_lr),\n",
    "        ('cat', pipeline_cat),\n",
    "        ('rf', pipeline_rf),\n",
    "        ('lgbm', pipeline_lgbm),\n",
    "        ('ada', pipeline_ada)\n",
    "    ], voting='soft')\n",
    "\n",
    "    # Setup RandomizedSearchCV\n",
    "    clf = RandomizedSearchCV(\n",
    "        estimator=ensemble_clf,\n",
    "        param_distributions=param_dist,\n",
    "        #param_distributions=param_test,\n",
    "        n_iter=2,\n",
    "        scoring=f1_scorer,\n",
    "        cv=TimeSeriesSplit(n_splits=2),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )  \n",
    "\n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = clf.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    # Use the best estimator\n",
    "    best_pipe = clf.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    y_proba = best_pipe.predict_proba(X_test)\n",
    "\n",
    "    # Apply threshold\n",
    "    threshold = 0.5  # You can adjust this threshold as needed\n",
    "    y_pred = (y_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    current_f1_score = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    if current_f1_score > best_f1_score:\n",
    "        best_f1_score = current_f1_score\n",
    "        best_f1_params = clf.best_params_\n",
    "        #best_model = clf.best_estimator_ \n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    best_model = clf.best_estimator_ \n",
    "\n",
    "    # Calculate precision score\n",
    "    precision = np.mean(y_test == y_pred)\n",
    "    precision_scores.append(precision)\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    print()\n",
    "\n",
    "# Print the best F1 score and its corresponding parameters\n",
    "print()\n",
    "print(\"Best F1 Score:\", best_f1_score)\n",
    "\n",
    "# print the classification report of the best model on the full dataset\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Put the target column to the front\n",
    "cols = list(corr.columns)\n",
    "cols.insert(0, cols.pop(cols.index('FTR')))\n",
    "corr = corr.loc[cols, cols]\n",
    "\n",
    "# Plot the correlation matrix\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=2)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "#importances = search.best_estimator_.named_steps['xgb'].feature_importances_\n",
    "#features = X_train.columns\n",
    "#importances_df = pd.DataFrame({'features': features, 'importances': importances})\n",
    "#importances_df = importances_df.sort_values('importances', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.barplot(x='importances', y='features', data=importances_df)\n",
    "#plt.title('Feature Importances')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_value_bet(row):\n",
    "    \"\"\"\n",
    "    Calculate the value bet based on the model's probability and the bookmaker's odds.\n",
    "    \n",
    "    Parameters:\n",
    "    - row: A row from a DataFrame, containing the 'Probability' and 'AvgH' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - The calculated value of the bet.\n",
    "    \"\"\"\n",
    "    decimal_odds = row['AvgH']\n",
    "    model_probability = row['Probability']\n",
    "    value = (decimal_odds * model_probability) - 1\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.5880000000000001\n",
      "Best Accuracy: 0.6986301369863014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "df_val = df_validationset.copy()\n",
    "\n",
    "# Calculate the predicted probabilities for the validation set\n",
    "y_val_proba = best_model.predict_proba(df_val.drop(columns=['FTR']))\n",
    "\n",
    "# Initialize variables to track the best threshold and its corresponding accuracy\n",
    "best_threshold = 0.5\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over potential threshold values\n",
    "for threshold in np.arange(0.5, 0.85, 0.001):\n",
    "    # Apply the current threshold to generate predictions\n",
    "    y_val_pred = (y_val_proba[:, 1] >= threshold).astype(int)\n",
    "    \n",
    "    # Evaluate accuracy for the current set of predictions\n",
    "    accuracy = accuracy_score(df_val['FTR'], y_val_pred)\n",
    "    \n",
    "    # Update the best threshold and accuracy as needed\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold \n",
    "\n",
    "# Print the best threshold and its accuracy\n",
    "print(f\"Best Threshold: {best_threshold}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Apply the best threshold to generate the final set of predictions\n",
    "y_val_pred_best = (y_val_proba[:, 1] >= best_threshold).astype(int)\n",
    "\n",
    "# Add the prediction probabilities and final predictions to df_val\n",
    "#df_val['proba_0'] = y_val_proba[:, 0].round(3)\n",
    "df_val['Probability'] = y_val_proba[:, 1].round(3)\n",
    "df_val['Prediction'] = y_val_pred_best\n",
    "\n",
    "\n",
    "# Directly filter df_val and add necessary columns without separate reindexing steps\n",
    "#filtered_df_val = df_val[df_val['Probability'] > best_threshold].copy()\n",
    "\n",
    "# Display all predictions\n",
    "filtered_df_val = df_val.copy()\n",
    "\n",
    "filtered_df_val.reset_index(inplace=True)\n",
    "\n",
    "filtered_df_val['Prediction'] = (filtered_df_val['Probability'] >= best_threshold).astype(int)\n",
    "#filtered_df_val['Actual Result'] = filtered_df_val['FTR']\n",
    "filtered_df_val['Correct Prediction'] = (filtered_df_val['Prediction'] == filtered_df_val['FTR']).astype(bool)\n",
    "\n",
    "index_to_team = {v: k for k, v in teams_dict.items()}\n",
    "filtered_df_val['Team'] = filtered_df_val['Team_ID'].map(index_to_team)\n",
    "filtered_df_val['Opponent'] = filtered_df_val['Opp_ID'].map(index_to_team)\n",
    "\n",
    "# Apply the calculate_value_bet function to each row in filtered_df_val to calculate the 'value bet'\n",
    "filtered_df_val['Value Bet'] = filtered_df_val.apply(calculate_value_bet, axis=1).round(2)\n",
    "\n",
    "display_columns = [\n",
    "    'Div', 'Date', 'Team', 'Opponent', 'Probability', 'Prediction',\n",
    "    #'FTR', \n",
    "    'FTR2', 'Correct Prediction', 'AvgH', 'AvgD', 'AvgA', 'Value Bet'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = filtered_df_val[display_columns]\n",
    "\n",
    "output = output.sort_values('Date', ascending=False)\n",
    "\n",
    "#output = output[output['Probability'] > best_threshold].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Div, Date, Time, Team\n",
    "output.sort_values(['Div', 'Date', 'Team'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>FTR2</th>\n",
       "      <th>Correct Prediction</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>Value Bet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>20240405</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.79</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Freiburg</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.27</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Heidenheim</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>7.21</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>Augsburg</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20240402</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>0.648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20240402</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.53</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20240402</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20240402</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>20240403</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.79</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20240404</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Man United</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5.15</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10.30</td>\n",
       "      <td>5.59</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.37</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Luton</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4.04</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.28</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.40</td>\n",
       "      <td>5.30</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>20240405</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>Hull</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>Millwall</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>0.659</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.82</td>\n",
       "      <td>3.79</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Ipswich</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3.61</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>20240406</td>\n",
       "      <td>QPR</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>20240409</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>QPR</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>20240409</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>20240409</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>20240409</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>0.594</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2</td>\n",
       "      <td>20240410</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.54</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>20240410</td>\n",
       "      <td>Bristol City</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.49</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2</td>\n",
       "      <td>20240410</td>\n",
       "      <td>Hull</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>20240410</td>\n",
       "      <td>Ipswich</td>\n",
       "      <td>Watford</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.46</td>\n",
       "      <td>4.61</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>20240410</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>20240405</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>0.609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Brest</td>\n",
       "      <td>Metz</td>\n",
       "      <td>0.696</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.52</td>\n",
       "      <td>4.01</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.82</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>20240405</td>\n",
       "      <td>Salernitana</td>\n",
       "      <td>Sassuolo</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>Torino</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.51</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>20240406</td>\n",
       "      <td>Roma</td>\n",
       "      <td>Lazio</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Cagliari</td>\n",
       "      <td>Atalanta</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Frosinone</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.13</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>Fiorentina</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Monza</td>\n",
       "      <td>Napoli</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.72</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4</td>\n",
       "      <td>20240407</td>\n",
       "      <td>Verona</td>\n",
       "      <td>Genoa</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>20240408</td>\n",
       "      <td>Udinese</td>\n",
       "      <td>Inter</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>20240404</td>\n",
       "      <td>Granada</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Div      Date              Team        Opponent  Probability  Prediction  \\\n",
       "11    0  20240405     Ein Frankfurt   Werder Bremen        0.580           0   \n",
       "16    0  20240406          Freiburg      RB Leipzig        0.263           0   \n",
       "17    0  20240406        Heidenheim   Bayern Munich        0.207           0   \n",
       "44    0  20240407        Hoffenheim        Augsburg        0.457           0   \n",
       "2     1  20240402       Bournemouth  Crystal Palace        0.648           1   \n",
       "3     1  20240402           Burnley          Wolves        0.572           0   \n",
       "1     1  20240402     Nott'm Forest          Fulham        0.461           0   \n",
       "4     1  20240402          West Ham       Tottenham        0.456           0   \n",
       "6     1  20240403         Brentford        Brighton        0.538           0   \n",
       "9     1  20240404           Chelsea      Man United        0.575           0   \n",
       "27    1  20240406          Brighton         Arsenal        0.321           0   \n",
       "21    1  20240406    Crystal Palace        Man City        0.140           0   \n",
       "24    1  20240406            Fulham       Newcastle        0.479           0   \n",
       "25    1  20240406             Luton     Bournemouth        0.345           0   \n",
       "26    1  20240406            Wolves        West Ham        0.553           0   \n",
       "46    1  20240407        Man United       Liverpool        0.320           0   \n",
       "47    1  20240407  Sheffield United         Chelsea        0.157           0   \n",
       "48    1  20240407         Tottenham   Nott'm Forest        0.730           1   \n",
       "12    2  20240405         Rotherham        Plymouth        0.327           0   \n",
       "30    2  20240406           Cardiff            Hull        0.382           0   \n",
       "32    2  20240406      Huddersfield        Millwall        0.420           0   \n",
       "34    2  20240406     Middlesbrough         Swansea        0.659           1   \n",
       "28    2  20240406           Norwich         Ipswich        0.439           0   \n",
       "35    2  20240406               QPR  Sheffield Weds        0.552           0   \n",
       "62    2  20240409          Plymouth             QPR        0.369           0   \n",
       "63    2  20240409           Preston    Huddersfield        0.397           0   \n",
       "64    2  20240409    Sheffield Weds         Norwich        0.369           0   \n",
       "65    2  20240409       Southampton        Coventry        0.594           1   \n",
       "67    2  20240410        Birmingham         Cardiff        0.569           0   \n",
       "68    2  20240410      Bristol City       Blackburn        0.466           0   \n",
       "69    2  20240410              Hull   Middlesbrough        0.499           0   \n",
       "70    2  20240410           Ipswich         Watford        0.707           1   \n",
       "71    2  20240410           Swansea           Stoke        0.497           0   \n",
       "13    3  20240405             Lille       Marseille        0.609           1   \n",
       "49    3  20240407             Brest            Metz        0.696           1   \n",
       "53    3  20240407            Monaco          Rennes        0.669           1   \n",
       "54    3  20240407            Nantes            Lyon        0.381           0   \n",
       "52    3  20240407          Toulouse      Strasbourg        0.503           0   \n",
       "14    4  20240405       Salernitana        Sassuolo        0.332           0   \n",
       "43    4  20240406            Empoli          Torino        0.328           0   \n",
       "42    4  20240406              Roma           Lazio        0.553           0   \n",
       "57    4  20240407          Cagliari        Atalanta        0.247           0   \n",
       "55    4  20240407         Frosinone         Bologna        0.269           0   \n",
       "59    4  20240407          Juventus      Fiorentina        0.552           0   \n",
       "56    4  20240407             Monza          Napoli        0.263           0   \n",
       "58    4  20240407            Verona           Genoa        0.418           0   \n",
       "60    4  20240408           Udinese           Inter        0.158           0   \n",
       "10    5  20240404           Granada        Valencia        0.351           0   \n",
       "\n",
       "    FTR2  Correct Prediction   AvgH  AvgD  AvgA  Value Bet  \n",
       "11     0                True   1.79  3.90  4.44       0.04  \n",
       "16     2                True   4.63  4.27  1.69       0.22  \n",
       "17     1               False   7.21  5.88  1.36       0.49  \n",
       "44     1               False   2.25  3.93  2.91       0.03  \n",
       "2      1                True   1.99  3.76  3.69       0.29  \n",
       "3      0                True   2.53  3.49  2.80       0.45  \n",
       "1      1               False   2.71  3.49  2.62       0.25  \n",
       "4      0                True   3.30  4.16  2.01       0.50  \n",
       "6      0                True   2.39  3.79  2.78       0.29  \n",
       "9      1               False   2.02  4.05  3.31       0.16  \n",
       "27     2                True   5.15  4.25  1.64       0.65  \n",
       "21     2                True  10.30  5.59  1.31       0.44  \n",
       "24     2                True   2.37  3.82  2.81       0.14  \n",
       "25     1               False   3.68  4.04  1.91       0.27  \n",
       "26     2                True   2.51  3.58  2.75       0.39  \n",
       "46     0                True   4.69  4.65  1.63       0.50  \n",
       "47     0                True   6.88  5.28  1.41       0.08  \n",
       "48     1                True   1.40  5.30  7.23       0.02  \n",
       "12     2                True   4.07  3.59  1.89       0.33  \n",
       "30     2                True   3.13  3.28  2.33       0.20  \n",
       "32     1               False   2.44  3.11  3.10       0.02  \n",
       "34     1                True   1.82  3.79  4.15       0.20  \n",
       "28     1               False   2.72  3.61  2.45       0.19  \n",
       "35     2                True   1.97  3.34  4.07       0.09  \n",
       "62     0                True   3.08  3.28  2.35       0.14  \n",
       "63     1               False   2.56  3.18  2.87       0.02  \n",
       "64     0                True   3.23  3.40  2.22       0.19  \n",
       "65     1                True   1.78  4.20  3.92       0.06  \n",
       "67     2                True   1.90  3.54  4.05       0.08  \n",
       "68     1               False   2.49  3.21  2.92       0.16  \n",
       "69     0                True   2.40  3.48  2.84       0.20  \n",
       "70     0               False   1.46  4.61  6.51       0.03  \n",
       "71     1               False   2.43  3.23  3.02       0.21  \n",
       "13     1                True   2.09  3.38  3.73       0.27  \n",
       "49     1                True   1.52  4.01  7.10       0.06  \n",
       "53     1                True   1.82  3.98  4.02       0.22  \n",
       "54     2                True   3.21  3.32  2.30       0.22  \n",
       "52     0                True   2.07  3.53  3.57       0.04  \n",
       "14     0                True   3.28  3.46  2.23       0.09  \n",
       "43     1               False   3.51  3.14  2.27       0.15  \n",
       "42     1               False   2.23  3.15  3.61       0.23  \n",
       "57     1               False   4.72  3.93  1.72       0.17  \n",
       "55     0                True   4.13  3.56  1.92       0.11  \n",
       "59     1               False   1.84  3.49  4.56       0.02  \n",
       "56     2                True   4.10  3.72  1.88       0.08  \n",
       "58     2                True   2.72  2.98  2.90       0.14  \n",
       "60     2                True   6.93  4.43  1.47       0.09  \n",
       "10     2                True   3.32  3.19  2.30       0.17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output[(output['Value Bet'] >= 0.01) & (output['AvgH'] >= 1.35)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.59\n",
      "Best Accuracy: 0.70\n",
      "\n",
      "Total Predictions: 73\n",
      "Total Correct Predictions: 51\n",
      "\n",
      "Percentage of Correct Predictions: 69.86%\n"
     ]
    }
   ],
   "source": [
    "# Display the Correct Prediction True / False ratio, and ther percentage of correct predictions\n",
    "correct_predictions = output['Correct Prediction'].sum()\n",
    "total_predictions = len(output)\n",
    "correct_ratio = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
    "print()\n",
    "print(f\"Total Predictions: {total_predictions}\")\n",
    "print(f\"Total Correct Predictions: {correct_predictions}\")\n",
    "print()\n",
    "print(f\"Percentage of Correct Predictions: {correct_ratio * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp\n",
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the current date and time as a string\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# save filtered_df_val[display_columns] to a CSV file\n",
    "output.to_csv(f'data/predictions/predictions_{content}_{timestamp}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 400  # Set Frequency To 2500 Hertz\n",
    "duration = 200  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
