{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = [\n",
    "    '2324', \n",
    "    '2223', \n",
    "    '2122', \n",
    "    '2021',\n",
    "    '1920', \n",
    "    '1819', \n",
    "    #'1718', \n",
    "    #'1617',\n",
    "    #'1516', '1415', '1314', '1213',\n",
    "    #'1112', '1011', \n",
    "    #'0910', '0809',\n",
    "    #'0708', '0607', '0506', '0405',\n",
    "    #'0304', '0203', '0102', '0001',\n",
    "]\n",
    "\n",
    "countries = [\n",
    "\n",
    "    \"ARG\", \"AUT\", \"BRA\", \"CHN\",\n",
    "    \"DNK\", \"FIN\", \"IRL\", \"JPN\",\n",
    "    \"MEX\", \"NOR\", \"POL\", \"ROU\",\n",
    "    \"RUS\", \"SWE\", \"SWZ\", \"USA\",\n",
    "]\n",
    "\n",
    "fixtures = [\n",
    "    \"fixtures_world\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataprep_start_date to the date the data preparation should start\n",
    "# If None, the data preparation will start from the beginning of the data\n",
    "\n",
    "# Make sure the file below already exists if you want to start from a specific date\n",
    "# file should be in the format \"processed_data_<content>.csv\"\n",
    "content = \"world_all\"\n",
    "\n",
    "#dataprep_start_date = None\n",
    "dataprep_start_date = pd.Timestamp(year=2024, month=4, day=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all filepaths into a list\n",
    "matches_files = []\n",
    "fixtures_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fixture in fixtures:    \n",
    "    fixtures_files.append(f'data/fixtures/{fixture}.csv')\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    matches_files.append('data/cleaned/%s.csv' % (country))\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            print(f'Loading {file}')\n",
    "\n",
    "            # Try to read with default utf-8 encoding\n",
    "            try:\n",
    "                df_temp = pd.read_csv(file, encoding='utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                # If utf-8 decoding fails, try reading with ISO-8859-1\n",
    "                df_temp = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "\n",
    "            #df_temp['Season'] = year\n",
    "            df = pd.concat([df, df_temp], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error: {file} not found')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading {file}: {e}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/cleaned/ARG.csv\n",
      "Loading data/cleaned/AUT.csv\n",
      "Loading data/cleaned/BRA.csv\n",
      "Loading data/cleaned/CHN.csv\n",
      "Loading data/cleaned/DNK.csv\n",
      "Loading data/cleaned/FIN.csv\n",
      "Loading data/cleaned/IRL.csv\n",
      "Loading data/cleaned/JPN.csv\n",
      "Loading data/cleaned/MEX.csv\n",
      "Loading data/cleaned/NOR.csv\n",
      "Loading data/cleaned/POL.csv\n",
      "Loading data/cleaned/ROU.csv\n",
      "Loading data/cleaned/RUS.csv\n",
      "Loading data/cleaned/SWE.csv\n",
      "Loading data/cleaned/SWZ.csv\n",
      "Loading data/cleaned/USA.csv\n",
      "Loading data/fixtures/fixtures_world.csv\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "df = load_data(matches_files)\n",
    "df_fixtures = load_data(fixtures_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51981, 125)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(df_fixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Div\n",
       "new_league_fixtures    125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fixtures['Div'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_to_int(date_str):\n",
    "    # Split the date_str by the \"/\" character into day, month, year\n",
    "    components = date_str.split('/')\n",
    "    \n",
    "    # If split was successful but not in expected format, try splitting by absence of separator for '%d%m%Y' or '%d%m%y'\n",
    "    if len(components) == 1:\n",
    "        if len(date_str) in [6, 8]:  # Length 6 for '%d%m%y', 8 for '%d%m%Y'\n",
    "            day, month = int(date_str[:2]), int(date_str[2:4])\n",
    "            year = int(date_str[4:])\n",
    "        else:\n",
    "            return 19000101  # Return default if format does not match expected\n",
    "    else:\n",
    "        day, month = int(components[0]), int(components[1])\n",
    "        year = int(components[2])\n",
    "    \n",
    "    # Adjust the year if it was only 2 characters long\n",
    "    if year < 100:\n",
    "        year += 2000\n",
    "    \n",
    "    # Create a date variable by using the day, month, year integers\n",
    "    # Note: Direct creation of date variable skipped to avoid unnecessary complexity,\n",
    "    # directly formatting to YYYYMMDD integer format instead.\n",
    "    date_int = int(f\"{year:04d}{month:02d}{day:02d}\")\n",
    "    \n",
    "    return date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Div\n",
       "new_league_fixtures    125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fixtures['Div'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_fixtures) > 0:\n",
    "\n",
    "    # Parse the 'Date' column to a datetime object\n",
    "    df_fixtures['Date_temp'] = pd.to_datetime(df_fixtures['Date'], format='%d/%m/%Y')\n",
    "\n",
    "    # Convert the datetime object to an integer in the format YYYYMMDD\n",
    "    df_fixtures['Date_temp'] = df_fixtures['Date_temp'].apply(\n",
    "        lambda x: int(x.strftime('%Y%m%d')) if pd.notnull(x) else 19000101)\n",
    "\n",
    "    # Replace all values with -1 in FTR column\n",
    "    df_fixtures['FTR'].fillna('X', inplace=True)\n",
    "\n",
    "    # Find the lowest fixture date\n",
    "    # This is the date where the data preparation will start\n",
    "    fixture_cutoff = df_fixtures['Date_temp'].min()\n",
    "\n",
    "    # Remove all the rows in df that are after the fixture_cutoff date\n",
    "    #df = df[df['Date'] < fixture_cutoff]\n",
    "\n",
    "    # Concatenate the matches and fixtures dataframes\n",
    "    df = pd.concat([df, df_fixtures], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate column names\n",
    "print(df.columns[df.columns.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52106"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the rows in the dataframe where the 'Div' is not in the list of countries\n",
    "df = df[df['Div'].isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51981"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max index: 15\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for all competitions\n",
    "\n",
    "file_path = f\"data/comps_dict_{content}.txt\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load the dictionary from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        comps_dict = eval(file.read())  # Using eval to convert string back to dictionary\n",
    "    # Find the maximum index currently in the dictionary\n",
    "    max_index = max(comps_dict.values())\n",
    "\n",
    "    print(f\"max index: {max_index}\")\n",
    "else:\n",
    "    comps_dict = {}\n",
    "    max_index = -1  \n",
    "\n",
    "# Get all unique divisions from DataFrame\n",
    "all_comps = df['Div'].dropna().unique()\n",
    "all_comps.sort()\n",
    "\n",
    "# Create a dictionary of new divisions alone\n",
    "new_comps = {div: index for index, div in enumerate(all_comps, start=max_index + 1) if div not in comps_dict}\n",
    "\n",
    "# Update dictionary only with new divisions\n",
    "comps_dict.update(new_comps)\n",
    "\n",
    "# Save the updated dictionary to a file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(str(comps_dict))\n",
    "\n",
    "# Add division ID column to DataFrame\n",
    "df['Div'] = df['Div'].map(comps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max index: 480\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for all teams\n",
    "\n",
    "file_path = f\"data/teams_dict_{content}.txt\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load the dictionary from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        teams_dict = eval(file.read())  \n",
    "    max_index = max(teams_dict.values())\n",
    "\n",
    "    print(f\"max index: {max_index}\")\n",
    "else:\n",
    "    teams_dict = {}\n",
    "    max_index = -1 \n",
    "\n",
    "# Get all teams from DataFrame\n",
    "all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).dropna().unique()\n",
    "all_teams.sort()\n",
    "\n",
    "# Create a dictionary of new teams alone\n",
    "new_teams = {team: index for index, team in enumerate(all_teams) if team not in teams_dict}\n",
    "\n",
    "# Update dictionary only with new teams, starting indices from max_index + 1\n",
    "start_index = max_index + 1\n",
    "teams_dict.update({team: index + start_index for index, team in enumerate(new_teams) if team not in teams_dict})\n",
    "\n",
    "# Save the updated dictionary to a file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(str(teams_dict))\n",
    "\n",
    "# Add team ID columns to DataFrame\n",
    "df['Team_ID'] = df['HomeTeam'].map(teams_dict)\n",
    "df['Opp_ID'] = df['AwayTeam'].map(teams_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duplicates(df):\n",
    "    # Sort the DataFrame so that rows with 'FTR' == -1 come first\n",
    "    df.sort_values(by=['Date', 'Team_ID', 'Opp_ID', 'FTR'], ascending=[True, True, True, False], inplace=True)\n",
    "    \n",
    "    # Drop duplicates based on 'Date', 'Team_ID', and 'Opp_ID' keeping the first occurrence (where 'FTR' is -1)\n",
    "    df = df.drop_duplicates(subset=['Date', 'Team_ID', 'Opp_ID'], keep='first')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = clean_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ELO ratings for each team\n",
    "\n",
    "# Initialize ratings dictionary\n",
    "teams = pd.concat([df['Team_ID'], df['Opp_ID']]).unique()\n",
    "ratings = {team: 1500 for team in teams}\n",
    "\n",
    "def calculate_expected_score(rating_a, rating_b):\n",
    "    return 1 / (1 + 10 ** ((rating_b - rating_a) / 400))\n",
    "\n",
    "def update_elo(rating, actual_score, expected_score, k=30):\n",
    "\n",
    "    rating = rating + k * (actual_score - expected_score)\n",
    "\n",
    "    # Parse the rating as an integer with no decimal points\n",
    "    return int(rating)\n",
    "\n",
    "# Iterate over the DataFrame and update ELO ratings after each match\n",
    "elo_team = []\n",
    "elo_opp = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    home_team, away_team, home_score, away_score = row['Team_ID'], row['Opp_ID'], row['FTHG'], row['FTAG']\n",
    "    home_rating = ratings[home_team]\n",
    "    away_rating = ratings[away_team]\n",
    "    \n",
    "    # Calculate expected scores\n",
    "    expected_home = calculate_expected_score(home_rating, away_rating)\n",
    "    expected_away = calculate_expected_score(away_rating, home_rating)\n",
    "    \n",
    "    # Calculate actual scores\n",
    "    actual_home = 1 if home_score > away_score else 0.5 if home_score == away_score else 0\n",
    "    actual_away = 1 - actual_home\n",
    "    \n",
    "    # Update ratings\n",
    "    new_home_rating = update_elo(home_rating, actual_home, expected_home)\n",
    "    new_away_rating = update_elo(away_rating, actual_away, expected_away)\n",
    "    \n",
    "    # Store updated ratings in the ratings dictionary\n",
    "    ratings[home_team] = new_home_rating\n",
    "    ratings[away_team] = new_away_rating\n",
    "    \n",
    "    # Append current ratings to list\n",
    "    elo_team.append(new_home_rating)\n",
    "    elo_opp.append(new_away_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign new ELO ratings to the DataFrame\n",
    "df['team_elo'] = elo_team\n",
    "df['opp_elo'] = elo_opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Apply the modified function\n",
    "df['Date_temp'] = df['Date'].apply(lambda x: parse_date_to_int(x.strftime('%d/%m/%Y')) if pd.notnull(x) else 19000101)\n",
    "\n",
    "# Day of the week as an integer\n",
    "df['DayOTW'] = df['Date'].dt.dayofweek\n",
    "\n",
    "df['Time'] = df['Time'].fillna('00:00').str.replace(':', '').astype(int)\n",
    "\n",
    "# Only keep the first 2 digits of the Time column, no decimals\n",
    "df['Time'] = df['Time'] // 100\n",
    "\n",
    "# Sort df by Date_temp and Time\n",
    "df = df.sort_values(['Date_temp', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [re.sub(r'[<]', '_st_', str(col)) for col in df.columns]\n",
    "df.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points(df, row, team_column):\n",
    "\n",
    "    # Season of the current match\n",
    "    current_season = row['Season']\n",
    "    \n",
    "    # Date of the current match\n",
    "    current_date = row['Date']\n",
    "\n",
    "    # Define the opponent column based on the team column\n",
    "    opponent_column = 'Opp_ID' if team_column == 'Team_ID' else 'Team_ID'\n",
    "\n",
    "    # Filter DataFrame for matches from the same season before the current date\n",
    "    past_matches = df[\n",
    "        (df['Season'] == current_season) & \n",
    "        (df['Date'] < current_date) &\n",
    "        ((df['Team_ID'] == row[team_column]) | (df['Opp_ID'] == row[team_column]))\n",
    "    ]\n",
    "\n",
    "    # Initialize total points\n",
    "    total_points = 0\n",
    "\n",
    "    # Calculate points for each past match\n",
    "    for match in past_matches.itertuples():\n",
    "        if getattr(match, 'Team_ID') == row[team_column]:\n",
    "            if getattr(match, 'FTR') == 'H':\n",
    "                total_points += 3  # Home win\n",
    "            elif getattr(match, 'FTR') == 'D':\n",
    "                total_points += 1  # Draw\n",
    "        elif getattr(match, 'Opp_ID') == row[team_column]:\n",
    "            if getattr(match, 'FTR') == 'A':\n",
    "                total_points += 3  # Away win\n",
    "            elif getattr(match, 'FTR') == 'D':\n",
    "                total_points += 1  # Draw\n",
    "\n",
    "    # Calculate average points if there are any matches played\n",
    "    matches_played = len(past_matches)\n",
    "    if matches_played > 0:\n",
    "        avg_points = total_points / matches_played\n",
    "    else:\n",
    "        avg_points = 0\n",
    "\n",
    "    # Round to 3 decimal places\n",
    "    return round(avg_points, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23448\\1339961462.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df['team_points'] = df.apply(lambda x: points(df, x, 'Team_ID') \n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdataprep_start_date\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mdataprep_start_date\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m df['opp_points'] = df.apply(lambda x: points(df, x, 'Opp_ID') \n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdataprep_start_date\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mdataprep_start_date\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10343\u001b[0m             \u001b[0mengine_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10344\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10345\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10346\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10347\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"apply\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[1;31m# raw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.chained_assignment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m                 \u001b[1;31m# GH#35462 re-pin mgr in case setitem changed it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m                 \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1271\u001b[0m                 \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6305\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6306\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6307\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6308\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6309\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6311\u001b[0m         \u001b[1;31m# if this fails, go on to more involved attribute setting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['team_points'] = df.apply(lambda x: points(df, x, 'Team_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)\n",
    "df['opp_points'] = df.apply(lambda x: points(df, x, 'Opp_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_vs_opponent_weighted(df, row, team_column):\n",
    "    # Determine opponent column based on team column\n",
    "    opponent_column = 'Team_ID' if team_column == 'Opp_ID' else 'Opp_ID'\n",
    "\n",
    "    # Combine year, month, and day into an integer 'Date_temp'\n",
    "    row_date_temp = row['Date'].year * 10000 + row['Date'].month * 100 + row['Date'].day\n",
    "\n",
    "    # Filter for matches between specified teams, excluding current match\n",
    "    mask = (\n",
    "        ((df[team_column] == row[team_column]) & (df[opponent_column] == row[opponent_column])) |\n",
    "        ((df[team_column] == row[opponent_column]) & (df[opponent_column] == row[team_column]))\n",
    "    ) & (df['Date_temp'] < row_date_temp)\n",
    "\n",
    "    filtered_matches = df[mask]\n",
    "    \n",
    "    if filtered_matches.empty:\n",
    "        return 0  # Return early if no matches found\n",
    "\n",
    "    # Sort by date and select top 5 recent matches\n",
    "    recent_matches = filtered_matches.sort_values(by='Date', ascending=False).head(5)\n",
    "    weights = list(range(len(recent_matches), 0, -1))  # Descending weights\n",
    "\n",
    "    # Calculate weighted score based on match results\n",
    "    weighted_score = sum(\n",
    "        (3 * weight if match.FTR == 'H' and match.__getattribute__(team_column) == match.Team_ID or\n",
    "                      match.FTR == 'A' and match.__getattribute__(team_column) != match.Team_ID else\n",
    "         1 * weight if match.FTR == 'D' else 0)\n",
    "        for match, weight in zip(recent_matches.itertuples(), weights)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize the weighted score by the sum of weights\n",
    "    return round(weighted_score / sum(weights), 3) if weights else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[170], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_hist_vs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: history_vs_opponent_weighted(df, x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam_ID\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataprep_start_date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m dataprep_start_date \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopp_hist_vs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory_vs_opponent_weighted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOpp_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataprep_start_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataprep_start_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10346\u001b[0m )\n\u001b[1;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1079\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1076\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseries_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;49;00m\n\u001b[0;32m   1081\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCSeries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# If we have a view on v, we need to make a copy because\u001b[39;49;00m\n\u001b[0;32m   1084\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#  series_generator will swap out the underlying data\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1271\u001b[0m, in \u001b[0;36mFrameColumnApply.series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arr, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;66;03m# GH#35462 re-pin mgr in case setitem changed it\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m     ser\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m mgr\n\u001b[1;32m-> 1271\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1272\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(ser, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_view:\n\u001b[0;32m   1274\u001b[0m         \u001b[38;5;66;03m# In apply_series_generator we store the a shallow copy of the\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;66;03m# result, which potentially increases the ref count of this reused\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m         \u001b[38;5;66;03m# the refs here to avoid triggering a unnecessary CoW inside the\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m         \u001b[38;5;66;03m# applied function (https://github.com/pandas-dev/pandas/pull/56212)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2075\u001b[0m, in \u001b[0;36mSingleBlockManager.set_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   2072\u001b[0m \u001b[38;5;66;03m# NOTE(CoW) Currently this is only used for FrameColumnApply.series_generator\u001b[39;00m\n\u001b[0;32m   2073\u001b[0m \u001b[38;5;66;03m# which handles CoW by setting the refs manually if necessary\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m-> 2075\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_mgr_locs \u001b[38;5;241m=\u001b[39m \u001b[43mBlockPlacement\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['team_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Team_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)\n",
    "df['opp_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Opp_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_form(df, row, perspective):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Initialize points\n",
    "    points = 0\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Calculate points with weights\n",
    "    weighted_points_sum = 0\n",
    "    total_weights = sum(weights[:len(past_matches)])  # Adjust the total weight in case of less than 5 matches\n",
    "    \n",
    "    for match, weight in zip(past_matches.itertuples(), weights):\n",
    "        if (match.Team_ID == team_id and match.FTR == 'H') or (match.Opp_ID == team_id and match.FTR == 'A'):\n",
    "            points += 3\n",
    "        elif match.FTR == 'D':\n",
    "            points += 1\n",
    "        else:\n",
    "            points += 0\n",
    "\n",
    "        weighted_points_sum += points * weight\n",
    "    \n",
    "    if total_weights > 0:\n",
    "\n",
    "        team_form = round(weighted_points_sum / total_weights, 2)\n",
    "\n",
    "        return team_form\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_form'] = df.apply(lambda x: team_form(df, x, 'Team') if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)\n",
    "df['opp_form'] = df.apply(lambda x: team_form(df, x, 'Opp') if dataprep_start_date is None or x['Date'] >= dataprep_start_date else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avgs_combined(df, row, perspective):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past 5 matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Initialize sums and weighted sums\n",
    "    shots = []\n",
    "    shots_target = []\n",
    "    \n",
    "    # Determine which columns to use and collect the values\n",
    "    for match in past_matches.itertuples():\n",
    "        if match.Team_ID == team_id:\n",
    "            shots.append(getattr(match, 'HS'))  # Home shots\n",
    "            shots_target.append(getattr(match, 'HST'))  # Home shots on target\n",
    "        else:\n",
    "            shots.append(getattr(match, 'AS'))  # Away shots\n",
    "            shots_target.append(getattr(match, 'AST'))  # Away shots on target\n",
    "    \n",
    "    # Calculate the weighted averages of the values\n",
    "    weighted_shots = sum(s * w for s, w in zip(shots, weights))\n",
    "    weighted_shots_target = sum(st * w for st, w in zip(shots_target, weights))\n",
    "    total_weights = sum(weights[:len(shots)])  # Adjust total weight if there are less than 5 matches\n",
    "    \n",
    "    avg_shots = weighted_shots / total_weights if total_weights > 0 else 0\n",
    "    avg_shots_target = weighted_shots_target / total_weights if total_weights > 0 else 0\n",
    "\n",
    "    # Round the averages to 2 decimal places\n",
    "    avg_shots = round(avg_shots, 2)\n",
    "    avg_shots_target = round(avg_shots_target, 2)\n",
    "    \n",
    "    return avg_shots, avg_shots_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>...</th>\n",
       "      <th>Opp_ID</th>\n",
       "      <th>team_elo</th>\n",
       "      <th>opp_elo</th>\n",
       "      <th>DayOTW</th>\n",
       "      <th>team_points</th>\n",
       "      <th>opp_points</th>\n",
       "      <th>team_hist_vs</th>\n",
       "      <th>opp_hist_vs</th>\n",
       "      <th>team_form</th>\n",
       "      <th>opp_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19083</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>19</td>\n",
       "      <td>Derry City</td>\n",
       "      <td>Bohemians</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.73</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>1532</td>\n",
       "      <td>1480</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19082</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>19</td>\n",
       "      <td>Drogheda</td>\n",
       "      <td>Shamrock Rovers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>9.80</td>\n",
       "      <td>...</td>\n",
       "      <td>358</td>\n",
       "      <td>1476</td>\n",
       "      <td>1618</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19084</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>19</td>\n",
       "      <td>St. Patricks</td>\n",
       "      <td>Bray</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.44</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>1536</td>\n",
       "      <td>1499</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19085</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>19</td>\n",
       "      <td>UC Dublin</td>\n",
       "      <td>Cork City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4.02</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>1403</td>\n",
       "      <td>1469</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19086</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>20</td>\n",
       "      <td>Monaghan</td>\n",
       "      <td>Dundalk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>2.90</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>1487</td>\n",
       "      <td>1566</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Div  Season       Date  Time      HomeTeam         AwayTeam  FTHG  \\\n",
       "19083    6    2012 2012-03-02    19    Derry City        Bohemians   1.0   \n",
       "19082    6    2012 2012-03-02    19      Drogheda  Shamrock Rovers   1.0   \n",
       "19084    6    2012 2012-03-02    19  St. Patricks             Bray   1.0   \n",
       "19085    6    2012 2012-03-02    19     UC Dublin        Cork City   1.0   \n",
       "19086    6    2012 2012-03-02    20      Monaghan          Dundalk   0.0   \n",
       "\n",
       "       FTAG FTR  AvgH  ...  Opp_ID  team_elo  opp_elo  DayOTW  team_points  \\\n",
       "19083   0.0   H  1.73  ...      51      1532     1480       4          NaN   \n",
       "19082   2.0   A  9.80  ...     358      1476     1618       4          NaN   \n",
       "19084   0.0   H  1.44  ...      56      1536     1499       4          NaN   \n",
       "19085   0.0   H  4.02  ...      92      1403     1469       4          NaN   \n",
       "19086   0.0   D  2.90  ...     113      1487     1566       4          NaN   \n",
       "\n",
       "       opp_points  team_hist_vs  opp_hist_vs  team_form  opp_form  \n",
       "19083         NaN           NaN          NaN        NaN       NaN  \n",
       "19082         NaN           NaN          NaN        NaN       NaN  \n",
       "19084         NaN           NaN          NaN        NaN       NaN  \n",
       "19085         NaN           NaN          NaN        NaN       NaN  \n",
       "19086         NaN           NaN          NaN        NaN       NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['team_shots'], df['team_shots_target'] = zip(*df.apply(lambda x: rolling_avgs_combined(df, x, 'Team') \n",
    "#    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))\n",
    "#df['opp_shots'], df['opp_shots_target'] = zip(*df.apply(lambda x: rolling_avgs_combined(df, x, 'Opp') \n",
    "#    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_goals(df, row, team_column):\n",
    "    # Season and date of the current match\n",
    "    current_season = row['Season']\n",
    "    current_date = row['Date']\n",
    "\n",
    "    # Determine the columns for goals scored and conceded based on perspective\n",
    "    if team_column == 'Team_ID':\n",
    "        goals_scored_column = 'FTHG'  # Assuming FTHG is the column for home team goals\n",
    "        goals_conceded_column = 'FTAG'  # Assuming FTAG is the column for away team goals\n",
    "    else:\n",
    "        goals_scored_column = 'FTAG'  # Flip the columns if we are looking from the opponent's perspective\n",
    "        goals_conceded_column = 'FTHG'\n",
    "\n",
    "    # Filter matches from the same season and before the current date\n",
    "    past_matches = df[\n",
    "        (df['Season'] == current_season) & \n",
    "        (df['Date'] < current_date) & \n",
    "        ((df['Team_ID'] == row[team_column]) | (df['Opp_ID'] == row[team_column]))\n",
    "    ]\n",
    "\n",
    "    # Calculate the average goals scored and conceded\n",
    "    goals_scored = 0\n",
    "    goals_conceded = 0\n",
    "    total_matches = len(past_matches)\n",
    "\n",
    "    for match in past_matches.itertuples():\n",
    "        if getattr(match, 'Team_ID') == row[team_column]: \n",
    "            goals_scored += getattr(match, goals_scored_column)\n",
    "            goals_conceded += getattr(match, goals_conceded_column)\n",
    "        else:  # Team is playing away\n",
    "            goals_scored += getattr(match, goals_scored_column)\n",
    "            goals_conceded += getattr(match, goals_conceded_column)\n",
    "\n",
    "    avg_goals_for = goals_scored / total_matches if total_matches > 0 else 0\n",
    "    avg_goals_against = goals_conceded / total_matches if total_matches > 0 else 0\n",
    "\n",
    "    avg_goals_for = round(avg_goals_for, 2)\n",
    "    avg_goals_against = round(avg_goals_against, 2)\n",
    "\n",
    "    return avg_goals_for, avg_goals_against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function and create new columns\n",
    "df['team_avg_goals_for'], df['team_avg_goals_against'] = zip(*df.apply(lambda x: avg_goals(df, x, 'Team_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))\n",
    "df['opp_avg_goals_for'], df['opp_avg_goals_against'] = zip(*df.apply(lambda x: avg_goals(df, x, 'Opp_ID') \n",
    "    if dataprep_start_date is None or x['Date'] >= dataprep_start_date else (0, 0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means only for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "means = df[numeric_cols].mean()\n",
    "\n",
    "# Fill missing values in numeric columns with their respective means\n",
    "df[numeric_cols] = df[numeric_cols].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the FTR to 'X' where the value is currently NaN\n",
    "df['FTR'] = df['FTR'].fillna('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop every row where 'FTR' is not 'H', 'D', or 'A', or 'X' (if future matches are included)\n",
    "df = df[df['FTR'].isin(['H', 'D', 'A', 'X'])]\n",
    "\n",
    "# Map 'H', 'D', and 'A' to 0, 1, and 2 respectively\n",
    "df['FTR'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2, 'X': -1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xg(df, row, team_column):\n",
    "    # Initialize the expected goals (xg)\n",
    "    xg_total = 0\n",
    "    count_matches = 0\n",
    "\n",
    "    # Season of the current match\n",
    "    current_season = row['Season']\n",
    "\n",
    "    # Date of the current match\n",
    "    current_date = pd.to_datetime(row['Date'], dayfirst=True)  # Ensure the date format is correct\n",
    "\n",
    "    # Define the opponent column based on the team column\n",
    "    if team_column == 'Team_ID':\n",
    "        goals_col = 'FTHG'\n",
    "        shots_on_target_col = 'HST'\n",
    "    else:\n",
    "        goals_col = 'FTAG'\n",
    "        shots_on_target_col = 'AST'\n",
    "\n",
    "    # Filter DataFrame for matches from the same season before the current date\n",
    "    past_matches = df[\n",
    "        (df['Season'] == current_season) &\n",
    "        (pd.to_datetime(df['Date'], dayfirst=True) < current_date) &\n",
    "        (df[team_column] == row[team_column])\n",
    "    ]\n",
    "\n",
    "    # Calculate efficiency and xg\n",
    "    for match in past_matches.itertuples():\n",
    "        goals = getattr(match, goals_col)\n",
    "        shots_on_target = getattr(match, shots_on_target_col)\n",
    "        if shots_on_target > 0:\n",
    "            efficiency = goals / shots_on_target\n",
    "            xg_total += efficiency\n",
    "            count_matches += 1\n",
    "\n",
    "    # Calculate average xg\n",
    "    if count_matches > 0:\n",
    "        avg_xg = xg_total / count_matches\n",
    "    else:\n",
    "        avg_xg = 0\n",
    "\n",
    "    return avg_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['team_xg'] = df.apply(lambda x: calculate_xg(df, x, 'Team_ID'), axis=1)\n",
    "#df['opp_xg'] = df.apply(lambda x: calculate_xg(df, x, 'Opp_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51981, 28)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    \n",
    "        'Div', 'Season', 'Date_temp', 'Time', 'DayOTW', 'Team_ID', 'Opp_ID', 'FTR',\n",
    "\n",
    "        'team_elo', 'opp_elo',\n",
    "\n",
    "        #'team_xg', 'opp_xg',\n",
    "        \n",
    "        'team_hist_vs', \n",
    "        'opp_hist_vs',\n",
    "\n",
    "        'team_points',\n",
    "        'opp_points',\n",
    "        \n",
    "        'team_form', \n",
    "        'opp_form',\n",
    "\n",
    "        'team_avg_goals_for', \n",
    "        'team_avg_goals_against',\n",
    "        'opp_avg_goals_for',\n",
    "        'opp_avg_goals_against',\n",
    "         \n",
    "        #'team_shots', 'opp_shots',\n",
    "        #'team_shots_target', 'opp_shots_target',\n",
    "\n",
    "        'AvgH', 'AvgD', 'AvgA'\n",
    "         \n",
    "         \n",
    "         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_temp\n",
      "20161211    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the value counts of the Date_temp column where FTR is -1\n",
    "print(df[df['FTR'] == -1]['Date_temp'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Date_temp' to 'Date'\n",
    "df.rename(columns={'Date_temp': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 13] Permission denied: 'data/processed/processed_data_world_all.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "   \n",
    "    if dataprep_start_date is not None:\n",
    "        # Convert date columns to datetime\n",
    "        df['Date_temp'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
    "        \n",
    "        # Filter new data based on start date\n",
    "        df_new = df[df['Date_temp'] >= dataprep_start_date].copy()\n",
    "\n",
    "        # Load existing data\n",
    "        df_existing = pd.read_csv(f'data/processed/processed_data_{content}.csv')\n",
    "\n",
    "        df_existing['Date_temp'] = pd.to_datetime(df_existing['Date'])\n",
    "        \n",
    "        # Filter existing data to remove overlap with new data\n",
    "        df_existing = df_existing[df_existing['Date_temp'] < dataprep_start_date]\n",
    "\n",
    "        # Combine and sort data\n",
    "        df_final = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        df_final.sort_values(['Date_temp', 'Time'], inplace=True)\n",
    "\n",
    "        # Clean up temporary columns\n",
    "        df_final.drop(columns='Date_temp', inplace=True)\n",
    "    else:\n",
    "        df_final = df.copy()\n",
    "\n",
    "    # Save the final DataFrame\n",
    "    df_final.to_csv(f'data/processed/processed_data_{content}.csv', index=False)\n",
    "    print(f\"Data saved: {df_final.shape[0]} matches\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 400  # Set Frequency To 2500 Hertz\n",
    "duration = 200  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
