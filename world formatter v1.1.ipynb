{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    \"ARG\", \"AUT\", \"BRA\", \"CHN\",\n",
    "    \"DNK\", \"FIN\", \"IRL\", \"JPN\",\n",
    "    \"MEX\", \"NOR\", \"POL\", \"ROU\",\n",
    "    \"RUS\", \"SWE\", \"SWZ\", \"USA\",\n",
    "]\n",
    "\n",
    "seasons = [\n",
    "    '2324', \n",
    "    '2223', \n",
    "    '2122', \n",
    "    '2021',\n",
    "    '1920',\n",
    "    '1819',\n",
    "    '1718',\n",
    "    '1617',\n",
    "    '1516',\n",
    "    '1415'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_files = []\n",
    "fixtures_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:    \n",
    "    matches_files.append('data/scraped/other/%s.csv' % (country))\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures_files.append(f'data/fixtures/new_league_fixtures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_season(season):\n",
    "    # Check if the season contains a '/'\n",
    "    if '/' in season:\n",
    "        # Split the string on '/' and take the last two digits of each year\n",
    "        parts = season.split('/')\n",
    "        new_season = parts[0][-2:] + parts[1][-2:]\n",
    "    else:\n",
    "        # If it's just a single year, use the string as is\n",
    "        new_season = season\n",
    "\n",
    "    return new_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapping = {\n",
    "    'Argentina': 'ARG',\n",
    "    'Austria': 'AUT',\n",
    "    'Brazil': 'BRA',\n",
    "    'China': 'CHN',\n",
    "    'Denmark': 'DNK',\n",
    "    'Finland': 'FIN',\n",
    "    'Ireland': 'IRL',\n",
    "    'Japan': 'JPN',\n",
    "    'Norway': 'NOR',\n",
    "    'Poland': 'POL',\n",
    "    'Romania': 'ROU',\n",
    "    'Russia': 'RUS',\n",
    "    'Sweden': 'SWE',\n",
    "    'Switzerland': 'SWZ',\n",
    "    'USA': 'USA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Try to read with default utf-8 encoding\n",
    "            try:\n",
    "                df_temp = pd.read_csv(file, encoding='utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                # If utf-8 decoding fails, try reading with ISO-8859-1\n",
    "                df_temp = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "\n",
    "            # Map the country name to the country code, and add it as a new column 'Div'\n",
    "            df_temp['Div'] = df_temp['Country'].map(country_mapping)            \n",
    "\n",
    "            # Check if 'Season' column exists and convert it\n",
    "            if 'Season' in df_temp.columns:\n",
    "                df_temp['Season'] = df_temp['Season'].astype(str).apply(format_season)\n",
    "            else:\n",
    "                df_temp['Season'] = seasons[0]\n",
    "\n",
    "            df = pd.concat([df, df_temp], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error: {file} not found')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading {file}: {e}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Rename the necessary columns as per the mapping\n",
    "    df.rename(columns={\n",
    "        'Home': 'HomeTeam',\n",
    "        'Away': 'AwayTeam',\n",
    "        'HG': 'FTHG',\n",
    "        'AG': 'FTAG',\n",
    "        'Res': 'FTR',\n",
    "        'AvgH': 'AvgH',\n",
    "        'AvgD': 'AvgD',\n",
    "        'AvgA': 'AvgA'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Convert 'Date' from string to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "    # Convert 'Date' to a String in the format 'DD/MM/YYYY'\n",
    "    df['Date'] = df['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "    # Drop the columns that are not needed\n",
    "    df.drop(columns=['Country', 'League', 'PH', 'PD', 'PA', 'MaxH', 'MaxD', 'MaxA'], inplace=True)\n",
    "\n",
    "    # Create FTHG, FTAG and FTR columns if they don't exist\n",
    "    if 'FTHG' not in df.columns:\n",
    "        df['FTHG'] = None\n",
    "    if 'FTAG' not in df.columns:\n",
    "        df['FTAG'] = None\n",
    "    if 'FTR' not in df.columns:\n",
    "        df['FTR'] = None\n",
    "\n",
    "    # Change the order of the columns\n",
    "    df = df[['Div', 'Season', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'AvgH', 'AvgD', 'AvgA']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DataFrames\n",
    "df = load_data(matches_files)\n",
    "df_fixtures = load_data(fixtures_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data(df)\n",
    "df_fixtures = clean_data(df_fixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51981, 125)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(df_fixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df into separate DataFrames for each country and save them to CSV\n",
    "for country in countries:\n",
    "    df_country = df[df['Div'] == country]\n",
    "    df_country.to_csv(f'data/cleaned/{country}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixtures.to_csv(f'data/fixtures/fixtures_world.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 400  # Set Frequency To 2500 Hertz\n",
    "duration = 200  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
