{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions = [\n",
    "\n",
    "    # Code, Seasons\n",
    "    ['E0', [2324, 2223, 2122, 2021, 1920]],\n",
    "    ['D1', [2324, 2223, 2122, 2021, 1920]],\n",
    "    ['I1', [2324, 2223, 2122, 2021, 1920]],\n",
    "\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in competitions:\n",
    "\n",
    "    for season in comp[1]:\n",
    "\n",
    "        matches_files.append(f\"data/matches/{comp[0]}_{season}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: data/matches/E0_2324.csv not found\n",
      "Error: data/matches/E0_2223.csv not found\n",
      "Error: data/matches/E0_2122.csv not found\n",
      "Error: data/matches/E0_2021.csv not found\n",
      "Error: data/matches/E0_1920.csv not found\n",
      "Data loaded: 3277 matches\n"
     ]
    }
   ],
   "source": [
    "# Load and concatenate matches data into a single DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in matches_files:\n",
    "\n",
    "    try:\n",
    "        df_temp = pd.read_csv(file)\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "    except:\n",
    "        # print an error message\n",
    "        print(f'Error: {file} not found')\n",
    "\n",
    "# print the amount of data loaded\n",
    "print(f\"Data loaded: {df.shape[0]} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to lowercase\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'HomeTeam' to 'Team' in df\n",
    "df.rename(columns={'hometeam': 'team'}, inplace=True)\n",
    "df.rename(columns={'awayteam': 'opponent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>team</th>\n",
       "      <th>opponent</th>\n",
       "      <th>fthg</th>\n",
       "      <th>ftag</th>\n",
       "      <th>ftr</th>\n",
       "      <th>hthg</th>\n",
       "      <th>htag</th>\n",
       "      <th>...</th>\n",
       "      <th>bbmx&gt;2.5</th>\n",
       "      <th>bbav&gt;2.5</th>\n",
       "      <th>bbmx&lt;2.5</th>\n",
       "      <th>bbav&lt;2.5</th>\n",
       "      <th>bbah</th>\n",
       "      <th>bbahh</th>\n",
       "      <th>bbmxahh</th>\n",
       "      <th>bbavahh</th>\n",
       "      <th>bbmxaha</th>\n",
       "      <th>bbavaha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>18/08/2023</td>\n",
       "      <td>19:30</td>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Augsburg</td>\n",
       "      <td>M'gladbach</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>Freiburg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D1</td>\n",
       "      <td>19/08/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  div        date   time           team       opponent  fthg  ftag ftr  hthg  \\\n",
       "0  D1  18/08/2023  19:30  Werder Bremen  Bayern Munich     0     4   A     0   \n",
       "1  D1  19/08/2023  14:30       Augsburg     M'gladbach     4     4   D     3   \n",
       "2  D1  19/08/2023  14:30     Hoffenheim       Freiburg     1     2   A     0   \n",
       "3  D1  19/08/2023  14:30     Leverkusen     RB Leipzig     3     2   H     2   \n",
       "4  D1  19/08/2023  14:30      Stuttgart         Bochum     5     0   H     2   \n",
       "\n",
       "   htag  ... bbmx>2.5  bbav>2.5  bbmx<2.5  bbav<2.5  bbah  bbahh  bbmxahh  \\\n",
       "0     1  ...      NaN       NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "1     3  ...      NaN       NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "2     2  ...      NaN       NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "3     1  ...      NaN       NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "4     0  ...      NaN       NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "\n",
       "   bbavahh  bbmxaha  bbavaha  \n",
       "0      NaN      NaN      NaN  \n",
       "1      NaN      NaN      NaN  \n",
       "2      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Div' to a categorical type, a numeric representation of the division\n",
    "df['div'] = df['div'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique list of HomeTeam and AwayTeam names combined, and add an index to each team\n",
    "teams = pd.concat([df['team'], df['opponent']]).unique()\n",
    "\n",
    "# Sort the teams alphabetically\n",
    "teams.sort()\n",
    "\n",
    "# Convert to an array of dictionaries\n",
    "teams = [{'team': team, 'index': index} for index, team in enumerate(teams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'referee'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'referee'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a unique list of Referees, and add an index to each Referee\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m referees \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreferee\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m])\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Remove any missing values\u001b[39;00m\n\u001b[0;32m      5\u001b[0m referees \u001b[38;5;241m=\u001b[39m referees[\u001b[38;5;241m~\u001b[39mpd\u001b[38;5;241m.\u001b[39misnull(referees)]\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'referee'"
     ]
    }
   ],
   "source": [
    "# Create a unique list of Referees, and add an index to each Referee\n",
    "referees = pd.concat([df['referee']]).unique()\n",
    "\n",
    "# Remove any missing values\n",
    "referees = referees[~pd.isnull(referees)]\n",
    "\n",
    "# Sort the teams alphabetically\n",
    "referees.sort()\n",
    "\n",
    "# Convert to an array of dictionaries\n",
    "referees = [{'referee': referee, 'index': index} for index, referee in enumerate(referees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the referee names to the index\n",
    "df['referee_id'] = df['referee'].map({referee['referee']: referee['index'] for referee in referees})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ftr_code'] = df['ftr']\n",
    "\n",
    "# Map the FTR column to a binary outcome\n",
    "#df['FTR'] = df['FTR'].map({'H': 1, 'D': 0, 'A': 2}).astype(int)\n",
    "#df['HTR'] = df['HTR'].map({'H': 1, 'D': 0, 'A': 2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the team names to the index values in the 'teams' list\n",
    "df['team_id'] = df['team'].map({team['team']: team['index'] for team in teams})\n",
    "df['opp_id'] = df['opponent'].map({team['team']: team['index'] for team in teams})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date is in DD/MM/YYYY format, convert it to a datetime object\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "\n",
    "# Declare Date_temp as a temporary column, an 8 digit integer representation of the date\n",
    "df['date_temp'] = df['date'].dt.year * 10000 + df['date'].dt.month * 100 + df['date'].dt.day\n",
    "\n",
    "# Connvert 'Time', which is now in HH:MM format to a 4 digit integer\n",
    "# Assuming a default time of 00:00 for missing values\n",
    "df['time'] = df['time'].fillna('00:00').str.replace(':', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [re.sub(r'[<]', '_st_', str(col)) for col in df.columns]\n",
    "df.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the modified function to create new columns\n",
    "\n",
    "#df['opp_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'AwayTeam_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['div', 'date', 'date_temp', 'time', 'team_id', 'opp_id', \n",
    "         \n",
    "         #'referee_id',          \n",
    "         \n",
    "#'fthg',\n",
    "#'ftag',\n",
    "'ftr',\n",
    "#'hthg',\n",
    "#'htag',\n",
    "#'htr',\n",
    "#'hs',\n",
    "#'as',\n",
    "#'hst',\n",
    "#'ast',\n",
    "#'hf',\n",
    "#'af',\n",
    "#'hc',\n",
    "#'ac',\n",
    "#'hy',\n",
    "#'ay',\n",
    "#'hr',\n",
    "#'ar',\n",
    "\n",
    "'avgh',\n",
    "'avgd',\n",
    "'avga',  \n",
    "\n",
    "#'team_hist_vs',\n",
    "#'opp_hist_vs'\n",
    "         \n",
    "         \n",
    "         \n",
    "         \n",
    "         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['venue'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "df = df.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assuming df is your original dataframe\n",
    "# duplicate the dataframe\n",
    "df_duplicate = df.copy()\n",
    "\n",
    "# switch the values of hometeam_id and awayteam_id\n",
    "df_duplicate[['team_id', 'opp_id']] = df_duplicate[['opp_id', 'team_id']].values\n",
    "\n",
    "# switch the values of b365h and b365a\n",
    "df_duplicate[['avgh', 'avga']] = df_duplicate[['avga', 'avgh']].values\n",
    "\n",
    "# switch the values of probs_win and probs_not_win\n",
    "#df_duplicate[['probs_win', 'probs_not_win']] = df_duplicate[['probs_not_win', 'probs_win']].values\n",
    "\n",
    "df_duplicate['venue'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original dataframe with the modified duplicate\n",
    "df = pd.concat([df, df_duplicate], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ftr'] = df['ftr'].map({'H': 1, 'D': 0, 'A': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_vs_opponent_weighted(df, row, team_column):\n",
    "    \"\"\"\n",
    "    Calculate the weighted average of points scored by a team against a specific opponent\n",
    "    in their 5 most recent matches before the date of the current match. Points are awarded \n",
    "    based on the match result: 3 points for a win, and 1 point for a draw. The most recent match\n",
    "    has more weight than the older matches.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing match data.\n",
    "    - row (pd.Series): The current row being evaluated, used to identify the team and opponent.\n",
    "    - team_column (str): The column name in df that identifies the team.\n",
    "    \n",
    "    Returns:\n",
    "    float: The normalized weighted score for the team against the specified opponent.\n",
    "    \"\"\"\n",
    "    \n",
    "    opponent_column = 'opp_id'\n",
    "\n",
    "    # Filter DataFrame for relevant matches before the current date_temp\n",
    "    df_temp = df[\n",
    "        (df['date_temp'] < row['date_temp']) & \n",
    "        ((df['team_id'] == row[team_column]) | (df['opp_id'] == row[team_column]))\n",
    "    ].sort_values(by='date_temp', ascending=False).head(5)\n",
    "\n",
    "    # Initialize the weighted score and the total possible weight\n",
    "    weighted_score = 0\n",
    "    total_weight = sum(range(1, len(df_temp) + 1))  # The sum of weights from 1 to n (number of matches)\n",
    "\n",
    "    # Iterate through the matches with a weight from 5 (most recent) to 1 (least recent)\n",
    "    for weight, (index, match) in zip(range(len(df_temp), 0, -1), df_temp.iterrows()):\n",
    "        # Determine points based on match result\n",
    "        points = 0\n",
    "        if match[team_column] == row['team_id']:\n",
    "            if match['ftr'] == 'H':\n",
    "                points = 3\n",
    "            elif match['ftr'] == 'D':\n",
    "                points = 1\n",
    "        else:\n",
    "            if match['ftr'] == 'A':\n",
    "                points = 3\n",
    "            elif match['ftr'] == 'D':\n",
    "                points = 1\n",
    "\n",
    "        # Multiply the points by the match's weight\n",
    "        weighted_score += points * weight\n",
    "\n",
    "    # Normalize the weighted score by the sum of the weights\n",
    "    normalized_weighted_score = weighted_score / total_weight if total_weight > 0 else 0\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "df['team_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'team_id'), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by Date_temp and separate the 200 most recent matches into a validation set\n",
    "df.sort_values('date_temp', inplace=True)\n",
    "df_val = df.tail(100)\n",
    "df = df.iloc[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X and y\n",
    "X = df.drop('ftr', axis=1)\n",
    "y = df['ftr']\n",
    "\n",
    "X.columns = [re.sub(r'[<]', '_st_', str(col)) for col in X.columns]\n",
    "X.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in X.columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('target_encoder', TargetEncoder()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters\n",
    "\n",
    "param_distributions = {\n",
    "\n",
    " \n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=5,\n",
    "    cv=TimeSeriesSplit(n_splits=15),\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the classification report\n",
    "print(classification_report(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the 20 most important features\n",
    "importances = search.best_estimator_['xgb'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[indices][:20], y=X_train.columns[indices][:20])\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the validation set\n",
    "y_val = df_val['ftr']\n",
    "X_val = df_val.drop('ftr', axis=1)\n",
    "y_pred = search.predict(X_val)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
