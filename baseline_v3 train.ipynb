{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2611,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"big5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data csv into a DataFrame\n",
    "df = pd.read_csv(f'data/processed/processed_data_{content}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the date_temp column, which is in YYYYMMDD format, into a datetime object, and store in a new column 'date_temporary'\n",
    "df['date_temporary'] = pd.to_datetime(df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2614,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the current date dynamically\n",
    "date_today = pd.Timestamp.now().normalize()  # .normalize() sets the time to 00:00:00\n",
    "\n",
    "# Calculate the date 2 weeks ago from the current date\n",
    "date_2_weeks_ago = date_today - pd.DateOffset(weeks=4)\n",
    "\n",
    "date_cutoff = date_today - pd.DateOffset(days=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows where the date_temporary column is older than date_cutoff\n",
    "df = df[df['date_temporary'] >= date_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2616,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_validationset = df.tail(250)\n",
    "#df = df.iloc[:-250]\n",
    "\n",
    "# define df_validationset as all the rows in df where the date_temporary column is greater than date_2_weeks_ago\n",
    "df_validationset = df[df['date_temporary'] > date_2_weeks_ago]\n",
    "\n",
    "# define df as all the rows in df where the date_temporary column is less than or equal to date_2_weeks_ago\n",
    "df = df[df['date_temporary'] <= date_2_weeks_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6430, 180)"
      ]
     },
     "execution_count": 2617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(df_validationset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the date_temporary column\n",
    "df.drop(columns=['date_temporary'], inplace=True)\n",
    "df_validationset.drop(columns=['date_temporary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2619,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "teams_dict = {}\n",
    "\n",
    "# Assuming 'teams_dict.txt' contains the dictionary as a single string\n",
    "with open('data/teams_dict.txt', 'r') as file:\n",
    "    # Read the entire file content into a single string\n",
    "    data = file.read()\n",
    "    # Safely evaluate the string as a Python dictionary\n",
    "    teams_dict = ast.literal_eval(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the df and df_validationset DataFrames by the 'Date', 'Div', 'Time' columns\n",
    "df.sort_values(['Date', 'Div', 'Time'], inplace=True)\n",
    "df_validationset.sort_values(['Date', 'Div', 'Time'], inplace=True)\n",
    "\n",
    "# Set the 'Date' and 'FTR2' column as the index\n",
    "df.set_index(['Date', 'FTR2'], inplace=True)\n",
    "df_validationset.set_index(['Date', 'FTR2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2621,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X and y\n",
    "X = df.drop('FTR', axis=1)\n",
    "y = df['FTR']\n",
    "\n",
    "X.columns = [re.sub(r'[<]', '_st_', str(col)) for col in X.columns]\n",
    "X.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in X.columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 1286)"
      ]
     },
     "execution_count": 2622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-102 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-102 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-102 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-102 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-102 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-102 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-102 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-102 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-102 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-102 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-102 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-102 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-102 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-102 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-102 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-102 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-102 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-102 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-102 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-102\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[(&#x27;target_encoder&#x27;,\n",
       "                                              TargetEncoder()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;xgb&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        &#x27;xgb__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001693ADFEDE0&gt;,\n",
       "                                        &#x27;xgb__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000169B15349E0&gt;,\n",
       "                                        &#x27;xgb__scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000169973F3DD0&gt;,\n",
       "                                        &#x27;xgb__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001699EF94470&gt;},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-506\" type=\"checkbox\" ><label for=\"sk-estimator-id-506\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[(&#x27;target_encoder&#x27;,\n",
       "                                              TargetEncoder()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;xgb&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        &#x27;xgb__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001693ADFEDE0&gt;,\n",
       "                                        &#x27;xgb__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000169B15349E0&gt;,\n",
       "                                        &#x27;xgb__scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000169973F3DD0&gt;,\n",
       "                                        &#x27;xgb__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001699EF94470&gt;},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-507\" type=\"checkbox\" ><label for=\"sk-estimator-id-507\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;target_encoder&#x27;, TargetEncoder()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-508\" type=\"checkbox\" ><label for=\"sk-estimator-id-508\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">TargetEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>TargetEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-509\" type=\"checkbox\" ><label for=\"sk-estimator-id-509\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-510\" type=\"checkbox\" ><label for=\"sk-estimator-id-510\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[('target_encoder',\n",
       "                                              TargetEncoder()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('xgb',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        'xgb__reg_alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001693ADFEDE0>,\n",
       "                                        'xgb__reg_lambda': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000169B15349E0>,\n",
       "                                        'xgb__scale_pos_weight': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000169973F3DD0>,\n",
       "                                        'xgb__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001699EF94470>},\n",
       "                   random_state=42, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 2623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('target_encoder', TargetEncoder()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters\n",
    "\n",
    "param_distributions = {\n",
    "\n",
    "    'target_encoder__smoothing': randint(1, 100),\n",
    "    'xgb__n_estimators': randint(100, 1000),\n",
    "    'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.6),\n",
    "    'xgb__subsample': uniform(0.3, 0.7),\n",
    "    'xgb__colsample_bytree': uniform(0.3, 0.7),\n",
    "    'xgb__gamma': randint(0, 5),\n",
    "    'xgb__reg_alpha': uniform(0, 1),\n",
    "    'xgb__reg_lambda': uniform(0, 1),\n",
    "    'xgb__min_child_weight': randint(1, 10),\n",
    "    'xgb__scale_pos_weight': uniform(0.5, 1.5)\n",
    "  \n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=5,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62       717\n",
      "           1       0.54      0.64      0.59       569\n",
      "\n",
      "    accuracy                           0.60      1286\n",
      "   macro avg       0.61      0.61      0.60      1286\n",
      "weighted avg       0.61      0.60      0.60      1286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(classification_report(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_windows(X, window_size, step):\n",
    "    n_samples = len(X)\n",
    "    windows = []\n",
    "    for start_idx in range(0, n_samples - window_size + 1, step):\n",
    "        end_idx = start_idx + window_size\n",
    "        if end_idx > n_samples:\n",
    "            break  # Avoid going beyond the dataset\n",
    "        train_indices = list(range(max(0, start_idx - window_size), start_idx))\n",
    "        test_indices = list(range(start_idx, end_idx))\n",
    "        windows.append((train_indices, test_indices))\n",
    "    return windows\n",
    "\n",
    "negative_count = len(df[df['FTR'] == 0])\n",
    "positive_count = len(df[df['FTR'] == 1])\n",
    "scale_pos_weight_value = negative_count / positive_count\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_dist = {\n",
    "    \n",
    "    #'xgb__clf__max_depth': [1,2,3],\n",
    "    #'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    #'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    #'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    #'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "    #'rf__clf__max_depth': [None, 4, 6],\n",
    "    #'rf__clf__min_samples_split': [2, 5],\n",
    "    #'rf__clf__min_samples_leaf': [1, 2],\n",
    "    #'rf__clf__bootstrap': [True, False],\n",
    "    #'rf__clf__n_estimators': [50, 100, 200],\n",
    "\n",
    "    'lr__clf__C': [0.1, 1, 10],  # Inverse of regularization strength; smaller values specify stronger regularization.\n",
    "    'lr__clf__penalty': ['l1', 'l2', 'elasticnet'],  # Specify the norm of the penalty.\n",
    "    'lr__clf__solver': ['saga'],  # Algorithm to use in the optimization problem, 'saga' supports all penalties.\n",
    "    'lr__clf__l1_ratio': [0.5],  # The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'.\n",
    "\n",
    "    #'cat__clf__depth': [1,2,3,4],\n",
    "    #'cat__clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    #'cat__clf__iterations': [50, 100, 200],\n",
    "    #'cat__clf__l2_leaf_reg': [1, 3, 5],\n",
    "\n",
    "    'gb__clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gb__clf__n_estimators': [50, 100, 200],\n",
    "    'gb__clf__max_depth': [3, 5, 7],\n",
    "    'gb__clf__min_samples_split': [2, 5],\n",
    "    'gb__clf__min_samples_leaf': [1, 2],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "param_test = {\n",
    "    \n",
    "    'xgb__clf__max_depth': [1,2,3],\n",
    "    'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2626,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a custom scoring function\n",
    "def xgb_early_stopping_score(y, estimator, X, y_true, sample_weight=None):\n",
    "    \"\"\"\n",
    "    Custom scorer that uses early stopping.\n",
    "    \"\"\"\n",
    "    # Split X into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_true, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit with early stopping\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    estimator.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_set, verbose=False)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = estimator.predict(X_val)\n",
    "    \n",
    "    # Return the F1 score\n",
    "    return f1_score(y_val, y_pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Training Data Shape: (643, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.9984447900466563\n",
      "\n",
      "Iteration 2 Training Data Shape: (1286, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.9875583203732504\n",
      "\n",
      "Iteration 3 Training Data Shape: (1929, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.9751166407465007\n",
      "\n",
      "Iteration 4 Training Data Shape: (2572, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.9315707620528771\n",
      "\n",
      "Iteration 5 Training Data Shape: (3215, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.8989113530326595\n",
      "\n",
      "Iteration 6 Training Data Shape: (3858, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.8678071539657853\n",
      "\n",
      "Iteration 7 Training Data Shape: (4501, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.8833592534992224\n",
      "\n",
      "Iteration 8 Training Data Shape: (5144, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.8273716951788491\n",
      "\n",
      "Iteration 9 Training Data Shape: (5787, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.8398133748055988\n",
      "\n",
      "Iteration 10 Training Data Shape: (6430, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'lr__clf__solver': 'saga', 'lr__clf__penalty': 'l1', 'lr__clf__l1_ratio': 0.5, 'lr__clf__C': 1, 'gb__clf__n_estimators': 200, 'gb__clf__min_samples_split': 5, 'gb__clf__min_samples_leaf': 2, 'gb__clf__max_depth': 3, 'gb__clf__learning_rate': 0.01}\n",
      "Precision: 0.8055987558320373\n",
      "\n",
      "\n",
      "Best F1 Score: 0.9981916817359855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       374\n",
      "           1       0.76      0.78      0.77       269\n",
      "\n",
      "    accuracy                           0.81       643\n",
      "   macro avg       0.80      0.80      0.80       643\n",
      "weighted avg       0.81      0.81      0.81       643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the F1 score for the '1' class\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_f1_params = None\n",
    "best_window_size = None\n",
    "best_precision = 0\n",
    "best_model = None \n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "\n",
    "\n",
    "# Make the custom scorer\n",
    "custom_scorer = make_scorer(xgb_early_stopping_score, greater_is_better=True, needs_proba=False, X=X, y_true=y)\n",
    "\n",
    "# Set the window_size and step to 5% of the dataset\n",
    "window_size = int(len(X) * 0.1)\n",
    "step = int(len(X) * 0.1)\n",
    "\n",
    "# Initialize an empty list to store precision scores\n",
    "precision_scores = []\n",
    "\n",
    "# Initialize an empty dataframe to store misclassified samples\n",
    "misclassified_samples = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "# Generate windows\n",
    "window_splits = generate_sliding_windows(X, window_size, step)\n",
    "\n",
    "# Initialize training indices with the first window\n",
    "train_end_index = window_size\n",
    "\n",
    "# Iterate over each sliding window\n",
    "for i, (train_index, test_index) in enumerate(window_splits):\n",
    "\n",
    "    # Update training indices to include the next window\n",
    "    train_index = list(range(train_end_index))\n",
    "    train_end_index += window_size\n",
    "\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"Iteration {i+1} Training Data Shape: {X_train.shape}\")\n",
    "\n",
    "    # Combine misclassified samples from previous iterations with current training data\n",
    "    if not misclassified_samples.empty:\n",
    "        X_train_combined = pd.concat([X_train, misclassified_samples[X_train.columns]], axis=0)\n",
    "        y_train_combined = pd.concat([y_train, misclassified_samples['FTR']], axis=0)\n",
    "    else:\n",
    "        X_train_combined = X_train\n",
    "        y_train_combined = y_train\n",
    "\n",
    "    # Calculate misclassification frequency\n",
    "    misclassified_freq = y_train_combined.value_counts(normalize=True)\n",
    "\n",
    "    # Define class weights based on misclassification frequency\n",
    "    class_weights = {0: 1, 1: max(0.6, 1 - misclassified_freq.get(1, 0.5))}  # Adjust dynamically to penalize misclassification of class 1 more heavily\n",
    "\n",
    "    # Define pipelines for each classifier with SMOTE and TargetEncoder\n",
    "    pipeline_xgb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', XGBClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    pipeline_gb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', GradientBoostingClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for logistic regression\n",
    "    pipeline_lr = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for catboost classifier\n",
    "    pipeline_cat = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', CatBoostClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for random forest\n",
    "    pipeline_rf = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', RandomForestClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # LightGBM pipeline\n",
    "    pipeline_lgbm = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LGBMClassifier(random_state=42, force_col_wise='true', verbose=0))\n",
    "    ])\n",
    "\n",
    "    # Adaboost pipeline\n",
    "    pipeline_ada = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', AdaBoostClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Combine them into an ensemble classifier\n",
    "    ensemble_clf = VotingClassifier(estimators=[\n",
    "        ('xgb', pipeline_xgb),\n",
    "        ('gb', pipeline_gb),\n",
    "        ('lr', pipeline_lr),\n",
    "        #('cat', pipeline_cat),\n",
    "        #('rf', pipeline_rf),\n",
    "        ('lgbm', pipeline_lgbm),\n",
    "        ('ada', pipeline_ada)\n",
    "    ], voting='soft')\n",
    "\n",
    "    # Setup RandomizedSearchCV\n",
    "    clf = RandomizedSearchCV(\n",
    "        estimator=ensemble_clf,\n",
    "        param_distributions=param_dist,\n",
    "        #param_distributions=param_test,\n",
    "        n_iter=2,\n",
    "        scoring=f1_scorer,\n",
    "        #scoring='precision',\n",
    "        cv=TimeSeriesSplit(n_splits=2),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )  \n",
    "\n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = clf.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    # Use the best estimator\n",
    "    best_pipe = clf.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    y_proba = best_pipe.predict_proba(X_test)\n",
    "\n",
    "    # Apply threshold\n",
    "    threshold = 0.5  # You can adjust this threshold as needed\n",
    "    y_pred = (y_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    current_f1_score = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    if current_f1_score > best_f1_score:\n",
    "        best_f1_score = current_f1_score\n",
    "        best_f1_params = clf.best_params_\n",
    "        #best_model = clf.best_estimator_ \n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    best_model = clf.best_estimator_ \n",
    "\n",
    "    # Calculate precision score\n",
    "    precision = np.mean(y_test == y_pred)\n",
    "    precision_scores.append(precision)\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    print()\n",
    "\n",
    "# Print the best F1 score and its corresponding parameters\n",
    "print()\n",
    "print(\"Best F1 Score:\", best_f1_score)\n",
    "\n",
    "# print the classification report of the best model on the full dataset\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Put the target column to the front\n",
    "cols = list(corr.columns)\n",
    "cols.insert(0, cols.pop(cols.index('FTR')))\n",
    "corr = corr.loc[cols, cols]\n",
    "\n",
    "# Plot the correlation matrix\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=2)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "importances = search.best_estimator_.named_steps['xgb'].feature_importances_\n",
    "features = X_train.columns\n",
    "importances_df = pd.DataFrame({'features': features, 'importances': importances})\n",
    "importances_df = importances_df.sort_values('importances', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.barplot(x='importances', y='features', data=importances_df)\n",
    "#plt.title('Feature Importances')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.562\n",
      "Best Accuracy: 0.7055555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "df_val = df_validationset.copy()\n",
    "\n",
    "# Calculate the predicted probabilities for the validation set\n",
    "y_val_proba = best_model.predict_proba(df_val.drop(columns=['FTR']))\n",
    "\n",
    "# Initialize variables to track the best threshold and its corresponding accuracy\n",
    "best_threshold = 0.5\n",
    "best_accuracy = 0\n",
    "\n",
    "# Iterate over potential threshold values\n",
    "for threshold in np.arange(0.5, 0.85, 0.001):\n",
    "    # Apply the current threshold to generate predictions\n",
    "    y_val_pred = (y_val_proba[:, 1] >= threshold).astype(int)\n",
    "    \n",
    "    # Evaluate accuracy for the current set of predictions\n",
    "    accuracy = accuracy_score(df_val['FTR'], y_val_pred)\n",
    "    \n",
    "    # Update the best threshold and accuracy as needed\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold \n",
    "\n",
    "# Print the best threshold and its accuracy\n",
    "print(f\"Best Threshold: {best_threshold}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Apply the best threshold to generate the final set of predictions\n",
    "y_val_pred_best = (y_val_proba[:, 1] >= best_threshold).astype(int)\n",
    "\n",
    "# Add the prediction probabilities and final predictions to df_val\n",
    "#df_val['proba_0'] = y_val_proba[:, 0].round(3)\n",
    "df_val['Probability'] = y_val_proba[:, 1].round(3)\n",
    "df_val['Prediction'] = y_val_pred_best\n",
    "\n",
    "# Ensure y_val_pred_best is generated as before with the best threshold applied\n",
    "\n",
    "# Directly filter df_val and add necessary columns without separate reindexing steps\n",
    "filtered_df_val = df_val[df_val['Probability'] > best_threshold].copy()\n",
    "\n",
    "filtered_df_val.reset_index(inplace=True)\n",
    "\n",
    "filtered_df_val['Prediction'] = (filtered_df_val['Probability'] >= best_threshold).astype(int)\n",
    "#filtered_df_val['Actual Result'] = filtered_df_val['FTR']\n",
    "filtered_df_val['Correct Prediction'] = (filtered_df_val['Prediction'] == filtered_df_val['FTR']).astype(bool)\n",
    "\n",
    "index_to_team = {v: k for k, v in teams_dict.items()}\n",
    "filtered_df_val['Team'] = filtered_df_val['Team_ID'].map(index_to_team)\n",
    "filtered_df_val['Opponent'] = filtered_df_val['Opp_ID'].map(index_to_team)\n",
    "\n",
    "\n",
    "display_columns = [\n",
    "    'Date', 'Team', 'Opponent', 'Probability', 'Prediction',\n",
    "    'FTR', 'FTR2', 'Correct Prediction', 'AvgH', 'AvgD', 'AvgA'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2631,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = filtered_df_val[display_columns]\n",
    "\n",
    "\n",
    "output = output.sort_values('Date', ascending=False)\n",
    "\n",
    "output = output[output['Probability'] > best_threshold].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTR2</th>\n",
       "      <th>Correct Prediction</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>0.656</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7.04</td>\n",
       "      <td>13.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>Salernitana</td>\n",
       "      <td>0.678</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.44</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Hull</td>\n",
       "      <td>0.663</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.75</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>0.570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>0.637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.28</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20240401</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>0.690</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>0.720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.37</td>\n",
       "      <td>5.63</td>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>Darmstadt</td>\n",
       "      <td>0.657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.18</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20240331</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Heidenheim</td>\n",
       "      <td>0.682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6.35</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.84</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>0.715</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.22</td>\n",
       "      <td>7.36</td>\n",
       "      <td>11.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20240330</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>Mainz</td>\n",
       "      <td>0.717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5.30</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>0.668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.40</td>\n",
       "      <td>5.71</td>\n",
       "      <td>6.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Las Palmas</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6.34</td>\n",
       "      <td>10.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.96</td>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20240330</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Luton</td>\n",
       "      <td>0.759</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.22</td>\n",
       "      <td>7.47</td>\n",
       "      <td>11.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20240329</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.02</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20240329</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.66</td>\n",
       "      <td>6.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>0.569</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.34</td>\n",
       "      <td>5.39</td>\n",
       "      <td>8.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Roma</td>\n",
       "      <td>Sassuolo</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.37</td>\n",
       "      <td>5.09</td>\n",
       "      <td>7.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>Genoa</td>\n",
       "      <td>0.659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.52</td>\n",
       "      <td>3.99</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Reims</td>\n",
       "      <td>Metz</td>\n",
       "      <td>0.623</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Millwall</td>\n",
       "      <td>0.724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.98</td>\n",
       "      <td>9.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20240317</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>0.619</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20240316</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>Alaves</td>\n",
       "      <td>0.731</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.97</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20240316</td>\n",
       "      <td>Ipswich</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.32</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20240316</td>\n",
       "      <td>Mainz</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>0.655</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20240315</td>\n",
       "      <td>Sociedad</td>\n",
       "      <td>Cadiz</td>\n",
       "      <td>0.590</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.03</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20240313</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Luton</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.77</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20240310</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>0.739</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.66</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20240310</td>\n",
       "      <td>Paris SG</td>\n",
       "      <td>Reims</td>\n",
       "      <td>0.675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.40</td>\n",
       "      <td>5.17</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20240310</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2.42</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20240310</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>0.633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.69</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20240310</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>0.661</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.34</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20240310</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Celta</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.94</td>\n",
       "      <td>9.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>0.688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.23</td>\n",
       "      <td>6.84</td>\n",
       "      <td>12.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240309</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>Darmstadt</td>\n",
       "      <td>0.656</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.73</td>\n",
       "      <td>17.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Everton</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.89</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.34</td>\n",
       "      <td>5.51</td>\n",
       "      <td>8.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Luton</td>\n",
       "      <td>0.569</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3.89</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>Mainz</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.23</td>\n",
       "      <td>6.88</td>\n",
       "      <td>11.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>0.672</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.27</td>\n",
       "      <td>5.75</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.62</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>Getafe</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Girona</td>\n",
       "      <td>Osasuna</td>\n",
       "      <td>0.626</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240309</td>\n",
       "      <td>Augsburg</td>\n",
       "      <td>Heidenheim</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date            Team          Opponent  Probability  Prediction  FTR  \\\n",
       "48  20240401           Inter            Empoli        0.656           1    1   \n",
       "47  20240401         Bologna       Salernitana        0.678           1    1   \n",
       "46  20240401           Leeds              Hull        0.663           1    1   \n",
       "45  20240401   Middlesbrough    Sheffield Weds        0.570           1    1   \n",
       "44  20240401        Coventry           Cardiff        0.637           1    0   \n",
       "43  20240401       Leicester           Norwich        0.690           1    1   \n",
       "42  20240331     Real Madrid        Ath Bilbao        0.667           1    1   \n",
       "41  20240331        Man City           Arsenal        0.610           1    0   \n",
       "40  20240331       Liverpool          Brighton        0.720           1    1   \n",
       "39  20240331          Bochum         Darmstadt        0.657           1    0   \n",
       "38  20240331       Stuttgart        Heidenheim        0.682           1    0   \n",
       "34  20240330       Newcastle          West Ham        0.583           1    1   \n",
       "31  20240330      Leverkusen        Hoffenheim        0.715           1    1   \n",
       "32  20240330      RB Leipzig             Mainz        0.717           1    0   \n",
       "33  20240330   Bayern Munich          Dortmund        0.668           1    0   \n",
       "37  20240330       Barcelona        Las Palmas        0.567           1    1   \n",
       "35  20240330         Chelsea           Burnley        0.669           1    0   \n",
       "36  20240330       Tottenham             Luton        0.759           1    1   \n",
       "30  20240329         Preston         Rotherham        0.636           1    1   \n",
       "29  20240329         Norwich          Plymouth        0.658           1    1   \n",
       "25  20240317          Monaco           Lorient        0.569           1    0   \n",
       "28  20240317            Roma          Sassuolo        0.719           1    1   \n",
       "27  20240317        Juventus             Genoa        0.659           1    0   \n",
       "26  20240317           Reims              Metz        0.623           1    1   \n",
       "24  20240317           Leeds          Millwall        0.724           1    1   \n",
       "23  20240317        Dortmund     Ein Frankfurt        0.619           1    1   \n",
       "22  20240316      Ath Bilbao            Alaves        0.731           1    1   \n",
       "21  20240316         Ipswich    Sheffield Weds        0.685           1    1   \n",
       "20  20240316           Mainz            Bochum        0.655           1    1   \n",
       "19  20240315        Sociedad             Cadiz        0.590           1    1   \n",
       "18  20240313     Bournemouth             Luton        0.589           1    1   \n",
       "12  20240310      Leverkusen         Wolfsburg        0.739           1    1   \n",
       "14  20240310        Paris SG             Reims        0.675           1    0   \n",
       "13  20240310     Aston Villa         Tottenham        0.600           1    0   \n",
       "16  20240310           Milan            Empoli        0.633           1    1   \n",
       "15  20240310       Marseille            Nantes        0.661           1    1   \n",
       "17  20240310     Real Madrid             Celta        0.710           1    1   \n",
       "6   20240309         Arsenal         Brentford        0.688           1    1   \n",
       "2   20240309      RB Leipzig         Darmstadt        0.656           1    1   \n",
       "3   20240309      Man United           Everton        0.567           1    1   \n",
       "4   20240309     Bournemouth  Sheffield United        0.651           1    0   \n",
       "5   20240309  Crystal Palace             Luton        0.569           1    0   \n",
       "1   20240309   Bayern Munich             Mainz        0.725           1    1   \n",
       "7   20240309       Blackburn          Plymouth        0.581           1    0   \n",
       "8   20240309         Norwich         Rotherham        0.672           1    1   \n",
       "9   20240309     Southampton        Sunderland        0.693           1    1   \n",
       "10  20240309        Valencia            Getafe        0.583           1    1   \n",
       "11  20240309          Girona           Osasuna        0.626           1    1   \n",
       "0   20240309        Augsburg        Heidenheim        0.589           1    1   \n",
       "\n",
       "    FTR2  Correct Prediction  AvgH  AvgD   AvgA  \n",
       "48     1                True  1.20  7.04  13.25  \n",
       "47     1                True  1.29  5.44  11.25  \n",
       "46     1                True  1.43  4.75   6.98  \n",
       "45     1                True  1.80  3.76   4.32  \n",
       "44     2               False  1.53  4.28   6.00  \n",
       "43     1                True  1.65  4.17   4.83  \n",
       "42     1                True  1.55  4.29   5.87  \n",
       "41     0               False  1.92  3.80   3.86  \n",
       "40     1                True  1.37  5.63   7.37  \n",
       "39     0               False  1.65  4.18   5.06  \n",
       "38     0               False  1.27  6.35  10.32  \n",
       "34     1                True  1.84  4.16   3.87  \n",
       "31     1                True  1.22  7.36  11.77  \n",
       "32     0               False  1.38  5.30   7.65  \n",
       "33     2               False  1.40  5.71   6.47  \n",
       "37     1                True  1.27  6.34  10.15  \n",
       "35     0               False  1.30  5.96   9.44  \n",
       "36     1                True  1.22  7.47  11.31  \n",
       "30     1                True  1.53  4.02   6.63  \n",
       "29     1                True  1.47  4.66   6.37  \n",
       "25     0               False  1.34  5.39   8.53  \n",
       "28     1                True  1.37  5.09   7.90  \n",
       "27     0               False  1.52  3.99   7.24  \n",
       "26     1                True  1.56  4.10   6.09  \n",
       "24     1                True  1.34  4.98   9.01  \n",
       "23     1                True  1.62  4.43   4.92  \n",
       "22     1                True  1.55  3.97   6.69  \n",
       "21     1                True  1.53  4.32   6.00  \n",
       "20     1                True  1.78  3.88   4.47  \n",
       "19     1                True  1.48  4.03   8.40  \n",
       "18     1                True  1.50  4.77   6.00  \n",
       "12     1                True  1.32  5.66   8.97  \n",
       "14     0               False  1.40  5.17   7.08  \n",
       "13     2               False  2.42  4.08   2.62  \n",
       "16     1                True  1.44  4.69   7.17  \n",
       "15     1                True  1.50  4.34   6.72  \n",
       "17     1                True  1.30  5.94   9.62  \n",
       "6      1                True  1.23  6.84  12.02  \n",
       "2      1                True  1.15  8.73  17.28  \n",
       "3      1                True  1.85  3.89   4.09  \n",
       "4      0               False  1.34  5.51   8.58  \n",
       "5      0               False  1.78  3.89   4.49  \n",
       "1      1                True  1.23  6.88  11.56  \n",
       "7      0               False  1.78  3.84   4.40  \n",
       "8      1                True  1.27  5.75  11.12  \n",
       "9      1                True  1.45  4.62   6.72  \n",
       "10     1                True  2.00  3.18   4.38  \n",
       "11     1                True  1.62  4.20   5.41  \n",
       "0      1                True  1.89  3.92   3.87  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.56\n",
      "Best Accuracy: 0.71\n",
      "\n",
      "Total Predictions: 49\n",
      "Total Correct Predictions: 35\n",
      "\n",
      "Percentage of Correct Predictions: 71.43%\n"
     ]
    }
   ],
   "source": [
    "# Display the Correct Prediction True / False ratio, and ther percentage of correct predictions\n",
    "correct_predictions = output['Correct Prediction'].sum()\n",
    "total_predictions = len(output)\n",
    "correct_ratio = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
    "print()\n",
    "print(f\"Total Predictions: {total_predictions}\")\n",
    "print(f\"Total Correct Predictions: {correct_predictions}\")\n",
    "print()\n",
    "print(f\"Percentage of Correct Predictions: {correct_ratio * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp\n",
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the current date and time as a string\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# save filtered_df_val[display_columns] to a CSV file\n",
    "output.to_csv(f'data/predictions/predictions_{content}_{timestamp}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2635,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 400  # Set Frequency To 2500 Hertz\n",
    "duration = 200  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
