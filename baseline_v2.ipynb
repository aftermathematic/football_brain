{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2070,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler  # Assuming you might need it\n",
    "\n",
    "# Specific models and tools\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Encoding and feature selection\n",
    "from category_encoders import TargetEncoder  # Fixed the import based on usage\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Model persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Miscellaneous settings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2071,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions = [\n",
    "\n",
    "    # Code, Seasons\n",
    "    ['E0', [2324, 2223, 2122, 2021, 1920]],\n",
    "    ['D1', [2324, 2223, 2122, 2021, 1920]],\n",
    "    ['I1', [2324, 2223, 2122, 2021, 1920]],\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2072,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2073,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in competitions:\n",
    "\n",
    "    for season in comp[1]:\n",
    "\n",
    "        matches_files.append(f\"data/matches/{comp[0]}_{season}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 5080 matches\n"
     ]
    }
   ],
   "source": [
    "# Load and concatenate matches data into a single DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in matches_files:\n",
    "\n",
    "    try:\n",
    "        df_temp = pd.read_csv(file)\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "    except:\n",
    "        # print an error message\n",
    "        print(f'Error: {file} not found')\n",
    "\n",
    "# print the amount of data loaded\n",
    "print(f\"Data loaded: {df.shape[0]} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>BbMx&gt;2.5</th>\n",
       "      <th>BbAv&gt;2.5</th>\n",
       "      <th>BbMx&lt;2.5</th>\n",
       "      <th>BbAv&lt;2.5</th>\n",
       "      <th>BbAH</th>\n",
       "      <th>BbAHh</th>\n",
       "      <th>BbMxAHH</th>\n",
       "      <th>BbAvAHH</th>\n",
       "      <th>BbMxAHA</th>\n",
       "      <th>BbAvAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Luton</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/08/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time     HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
       "0  E0  11/08/2023  20:00      Burnley       Man City     0     3   A     0   \n",
       "1  E0  12/08/2023  12:30      Arsenal  Nott'm Forest     2     1   H     2   \n",
       "2  E0  12/08/2023  15:00  Bournemouth       West Ham     1     1   D     0   \n",
       "3  E0  12/08/2023  15:00     Brighton          Luton     4     1   H     1   \n",
       "4  E0  12/08/2023  15:00      Everton         Fulham     0     1   A     0   \n",
       "\n",
       "   HTAG  ... BbMx>2.5 BbAv>2.5  BbMx<2.5  BbAv<2.5  BbAH  BbAHh  BbMxAHH  \\\n",
       "0     2  ...      NaN      NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "1     0  ...      NaN      NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "2     0  ...      NaN      NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "3     0  ...      NaN      NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "4     0  ...      NaN      NaN       NaN       NaN   NaN    NaN      NaN   \n",
       "\n",
       "   BbAvAHH  BbMxAHA  BbAvAHA  \n",
       "0      NaN      NaN      NaN  \n",
       "1      NaN      NaN      NaN  \n",
       "2      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 2075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2076,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Div' to a categorical type, a numeric representation of the division\n",
    "df['Div'] = df['Div'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2077,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique list of HomeTeam and AwayTeam names combined, and add an index to each team\n",
    "teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "\n",
    "# Sort the teams alphabetically\n",
    "teams.sort()\n",
    "\n",
    "# Convert to an array of dictionaries\n",
    "teams = [{'team': team, 'index': index} for index, team in enumerate(teams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2078,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique list of Referees, and add an index to each Referee\n",
    "referees = pd.concat([df['Referee']]).unique()\n",
    "\n",
    "# Convert to an array of dictionaries\n",
    "referees = [{'referee': referee, 'index': index} for index, referee in enumerate(referees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2079,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the team names to the index values in the 'teams' list\n",
    "df['Team_ID'] = df['HomeTeam'].map({team['team']: team['index'] for team in teams})\n",
    "df['Opp_ID'] = df['AwayTeam'].map({team['team']: team['index'] for team in teams})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2080,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the creation of a unique list of Referees and adding an index to each Referee\n",
    "referees = df['Referee'].unique()  # This should directly refer to the 'Referee' column\n",
    "\n",
    "# Convert to a dictionary with referee names as keys and their indices as values\n",
    "referee_dict = {referee: index for index, referee in enumerate(referees)}\n",
    "\n",
    "# Now map the 'Referee' column to these indices\n",
    "df['Ref_ID'] = df['Referee'].map(referee_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2081,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date is in DD/MM/YYYY format, convert it to a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Declare Date_temp as a temporary column, an 8 digit integer representation of the date\n",
    "df['Date_temp'] = df['Date'].dt.year * 10000 + df['Date'].dt.month * 100 + df['Date'].dt.day\n",
    "\n",
    "# Parse Date_temp to an 8 digit integer\n",
    "df['Date_temp'] = df['Date_temp'].astype(int)\n",
    "\n",
    "# Connvert 'Time', which is now in HH:MM format to a 4 digit integer\n",
    "# Assuming a default time of 00:00 for missing values\n",
    "df['Time'] = df['Time'].fillna('00:00').str.replace(':', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2082,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of all HomeTeam and AwayTeam names\n",
    "teams = np.append(df['HomeTeam'].unique(), df['AwayTeam'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2083,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [re.sub(r'[<]', '_st_', str(col)) for col in df.columns]\n",
    "df.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2084,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort df by Date_temp and Time\n",
    "df = df.sort_values(['Date_temp', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2085,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_vs_opponent_weighted(df, row, team_column):\n",
    "    # Initialize the total weighted score\n",
    "    weighted_score = 0\n",
    "    opponent_column = 'Opp_ID'\n",
    "\n",
    "    row_date_temp = row['Date'].year * 10000 + row['Date'].month * 100 + row['Date'].day\n",
    "\n",
    "    \n",
    "    # Filter the DataFrame for matches between the specified team and opponent from the same season, excluding the current match\n",
    "    filtered_matches = df[(df[team_column] == row[team_column]) & \n",
    "                          (df[opponent_column] == row[opponent_column]) &\n",
    "                          (df['Date_temp'] < row_date_temp)]\n",
    "    \n",
    "    recent_matches = filtered_matches.sort_values(by='Date', ascending=False).head(5)\n",
    "    \n",
    "    # Calculate weights - newer matches have higher weights\n",
    "    weights = range(len(recent_matches), 0, -1)  # Descending list based on the number of matches\n",
    "    \n",
    "    # Calculate score based on the match result\n",
    "    for match, weight in zip(recent_matches.itertuples(), weights):\n",
    "        if getattr(match, 'FTR') == 'H' and getattr(match, team_column) == getattr(match, 'Team_ID') or \\\n",
    "           getattr(match, 'FTR') == 'A' and getattr(match, team_column) != getattr(match, 'Team_ID'):\n",
    "            weighted_score += 3 * weight  # Team won\n",
    "        elif getattr(match, 'FTR') == 'A':\n",
    "            weighted_score += 1 * weight  # Draw\n",
    "        \n",
    "    # Normalize the weighted score by the sum of weights\n",
    "    normalized_weighted_score = weighted_score / sum(weights) if weights else 0\n",
    "\n",
    "    #print(f\"Weighted score: {weighted_score}, Normalized weighted score: {normalized_weighted_score}\")\n",
    "\n",
    "    return normalized_weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2086,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the modified function to create new columns\n",
    "df['team_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Team_ID'), axis=1)\n",
    "df['opp_hist_vs'] = df.apply(lambda x: history_vs_opponent_weighted(df, x, 'Opp_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2087,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function adapted for DataFrame application\n",
    "def convert_odds(row):\n",
    "    odds_win, odds_draw, odds_lose = row['AvgH'], row['AvgD'], row['AvgA']\n",
    "    prob_win = 1 / odds_win\n",
    "    prob_draw = 1 / odds_draw\n",
    "    prob_lose = 1 / odds_lose\n",
    "    prob_not_win = prob_draw + prob_lose\n",
    "    return pd.Series([prob_win, prob_not_win], index=['probs_win', 'probs_not_win'])\n",
    "\n",
    "# Apply the function and create new columns\n",
    "df[['probs_win', 'probs_not_win']] = df.apply(convert_odds, axis=1)\n",
    "\n",
    "#df = df.drop(columns=['AvgH', 'AvgD', 'AvgA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2088,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "#df = df.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>BbMxAHA</th>\n",
       "      <th>BbAvAHA</th>\n",
       "      <th>Team_ID</th>\n",
       "      <th>Opp_ID</th>\n",
       "      <th>Ref_ID</th>\n",
       "      <th>Date_temp</th>\n",
       "      <th>team_hist_vs</th>\n",
       "      <th>opp_hist_vs</th>\n",
       "      <th>probs_win</th>\n",
       "      <th>probs_not_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1130</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>Salernitana</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>37</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.272712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1400</td>\n",
       "      <td>Cagliari</td>\n",
       "      <td>Verona</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>0.589234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1400</td>\n",
       "      <td>Sassuolo</td>\n",
       "      <td>Udinese</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.348432</td>\n",
       "      <td>0.699511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1700</td>\n",
       "      <td>Lecce</td>\n",
       "      <td>Roma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.816006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.217517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Div       Date  Time  HomeTeam     AwayTeam  FTHG  FTAG FTR  HTHG  HTAG  \\\n",
       "3555    2 2024-04-01  1130   Bologna  Salernitana     3     0   H     2     0   \n",
       "3556    2 2024-04-01  1400  Cagliari       Verona     1     1   D     0     1   \n",
       "3557    2 2024-04-01  1400  Sassuolo      Udinese     1     1   D     1     1   \n",
       "3558    2 2024-04-01  1700     Lecce         Roma     0     0   D     0     0   \n",
       "3559    2 2024-04-01  1945     Inter       Empoli     2     0   H     1     0   \n",
       "\n",
       "      ... BbMxAHA BbAvAHA  Team_ID  Opp_ID  Ref_ID  Date_temp  team_hist_vs  \\\n",
       "3555  ...     NaN     NaN        8      59      37   20240401      1.000000   \n",
       "3556  ...     NaN     NaN       14      73      37   20240401      0.833333   \n",
       "3557  ...     NaN     NaN       61      70      37   20240401      0.500000   \n",
       "3558  ...     NaN     NaN       39      58      37   20240401      0.333333   \n",
       "3559  ...     NaN     NaN       36      22      37   20240401      1.666667   \n",
       "\n",
       "      opp_hist_vs  probs_win  probs_not_win  \n",
       "3555          0.0   0.775194       0.272712  \n",
       "3556          1.0   0.458716       0.589234  \n",
       "3557          1.6   0.348432       0.699511  \n",
       "3558          1.8   0.230947       0.816006  \n",
       "3559          1.4   0.833333       0.217517  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 2089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2090,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_form(df, row, perspective):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Initialize points\n",
    "    points = 0\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    \n",
    "    # Calculate points with weights\n",
    "    weighted_points_sum = 0\n",
    "    total_weights = sum(weights[:len(past_matches)])  # Adjust the total weight in case of less than 5 matches\n",
    "    \n",
    "    for match, weight in zip(past_matches.itertuples(), weights):\n",
    "        if (match.Team_ID == team_id and match.FTR == 'H') or (match.Opp_ID == team_id and match.FTR == 'A'):\n",
    "            points += 3\n",
    "        elif match.FTR == 'D':\n",
    "            points += 1\n",
    "        else:\n",
    "            points += 0\n",
    "\n",
    "        weighted_points_sum += points * weight\n",
    "    \n",
    "    if total_weights > 0:\n",
    "        return weighted_points_sum / total_weights\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2091,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to each row for 'Team'\n",
    "df['team_form_team'] = df.apply(lambda row: team_form(df, row, 'Team'), axis=1)\n",
    "\n",
    "# Applying the function to each row for 'Opp'\n",
    "#df['team_form_opp'] = df.apply(lambda row: team_form(df, row, 'Opp'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2092,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avgs(df, row, perspective, home_column, away_column):\n",
    "    # Determine the team ID based on the perspective ('Team' or 'Opp')\n",
    "    if perspective == 'Team':\n",
    "        team_id = row['Team_ID']\n",
    "    elif perspective == 'Opp':\n",
    "        team_id = row['Opp_ID']\n",
    "    else:\n",
    "        raise ValueError(\"Perspective must be 'Team' or 'Opp'\")\n",
    "    \n",
    "    # Get the current match date\n",
    "    current_date = row['Date_temp']\n",
    "    \n",
    "    # Filter past 5 matches for the team\n",
    "    past_matches = df[((df['Team_ID'] == team_id) | (df['Opp_ID'] == team_id)) &\n",
    "                      (df['Date_temp'] < current_date)].sort_values(by='Date_temp', ascending=False).head(5)\n",
    "    \n",
    "    # Weights for the matches (most recent match has the highest weight)\n",
    "    weights = [5, 4, 3, 2, 1]\n",
    "    values = []\n",
    "    \n",
    "    # Determine which column to use and collect the values\n",
    "    for match in past_matches.itertuples():\n",
    "        if match.Team_ID == team_id:\n",
    "            values.append(getattr(match, home_column))  # Use home_column for home team\n",
    "        else:\n",
    "            values.append(getattr(match, away_column))  # Use away_column for away team\n",
    "    \n",
    "    # Calculate the weighted average of the values\n",
    "    weighted_sum = sum(value * weight for value, weight in zip(values, weights))\n",
    "    total_weights = sum(weights[:len(values)])  # Adjust total weight if there are less than 5 matches\n",
    "    \n",
    "    if total_weights > 0:\n",
    "        return weighted_sum / total_weights\n",
    "    else:\n",
    "        return 0  # Return 0 if no past matches found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2093,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_shots'] = df.apply(lambda row: rolling_avgs(df, row, 'Team', 'HS', 'AS'), axis=1)\n",
    "df['opp_shots'] = df.apply(lambda row: rolling_avgs(df, row, 'Opp', 'HS', 'AS'), axis=1)\n",
    "\n",
    "df['team_shots_target'] = df.apply(lambda row: rolling_avgs(df, row, 'Team', 'HST', 'AST'), axis=1)\n",
    "df['opp_shots_target'] = df.apply(lambda row: rolling_avgs(df, row, 'Opp', 'HST', 'AST'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2094,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def avg_games_played(df, row, team_column):\n",
    "    team = row[team_column]\n",
    "    # Ensure current_match_date is a Timestamp for comparison\n",
    "    current_match_date = pd.to_datetime(row['Date'], dayfirst=True)  # Assuming 'Date' format is 'dd/mm/yy'\n",
    "\n",
    "    delta = 30\n",
    "    start_date = current_match_date - timedelta(days=delta)\n",
    "\n",
    "    # Ensure 'Date' column is in datetime format for comparison\n",
    "    #df['Date_temp'] = pd.to_datetime(df['Date'], dayfirst=True)  # Convert 'Date' column to datetime if not already done\n",
    "\n",
    "    # Filter the DataFrame for matches within the last 30 days\n",
    "    if team_column == 'Team_ID':\n",
    "        past_matches = df[((df[team_column] == team) | (df['Opp_ID'] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "    else:\n",
    "        past_matches = df[((df['Team_ID'] == team) | (df[team_column] == team)) &\n",
    "                          (df['Date'] >= start_date) & (df['Date'] < current_match_date)]\n",
    "\n",
    "    # If no matches were played in the last 30 days\n",
    "    if past_matches.empty:\n",
    "        return 0\n",
    "\n",
    "    # Calculate weights based on the recency of each match\n",
    "    weights = (current_match_date - past_matches['Date']).dt.days\n",
    "    weighted_count = sum(delta - weights + 1)  # '+ 1' to include the match day in the weight\n",
    "\n",
    "    # Normalize weights to sum to 1 and calculate the weighted average\n",
    "    total_weight = sum(delta - weights + 1)\n",
    "    weighted_avg = weighted_count / total_weight\n",
    "\n",
    "    return weighted_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2095,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function for each team and opponent\n",
    "#df['team_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Team_ID'), axis=1)\n",
    "#df['opp_avg_games'] = df.apply(lambda x: avg_games_played(df, x, 'Opp_ID'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2096,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means only for numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "means = df[numeric_cols].mean()\n",
    "\n",
    "# Fill missing values in numeric columns with their respective means\n",
    "df[numeric_cols] = df[numeric_cols].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2097,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FTR'] = df['FTR'].map({'H': 1, 'D': 0, 'A': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2098,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>Date_temp</th>\n",
       "      <th>team_hist_vs</th>\n",
       "      <th>opp_hist_vs</th>\n",
       "      <th>probs_win</th>\n",
       "      <th>probs_not_win</th>\n",
       "      <th>team_form_team</th>\n",
       "      <th>team_shots</th>\n",
       "      <th>opp_shots</th>\n",
       "      <th>team_shots_target</th>\n",
       "      <th>opp_shots_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1130</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>Salernitana</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.272712</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.266667</td>\n",
       "      <td>13.133333</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>3.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1400</td>\n",
       "      <td>Cagliari</td>\n",
       "      <td>Verona</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>0.589234</td>\n",
       "      <td>3.466667</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1400</td>\n",
       "      <td>Sassuolo</td>\n",
       "      <td>Udinese</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.348432</td>\n",
       "      <td>0.699511</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>13.133333</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1700</td>\n",
       "      <td>Lecce</td>\n",
       "      <td>Roma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20240401</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.816006</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>14.266667</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>3.466667</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1945</td>\n",
       "      <td>Inter</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20240401</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.217517</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>2.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Div       Date  Time  HomeTeam     AwayTeam  FTHG  FTAG  FTR  HTHG  \\\n",
       "3555    2 2024-04-01  1130   Bologna  Salernitana     3     0    1     2   \n",
       "3556    2 2024-04-01  1400  Cagliari       Verona     1     1    0     0   \n",
       "3557    2 2024-04-01  1400  Sassuolo      Udinese     1     1    0     1   \n",
       "3558    2 2024-04-01  1700     Lecce         Roma     0     0    0     0   \n",
       "3559    2 2024-04-01  1945     Inter       Empoli     2     0    1     1   \n",
       "\n",
       "      HTAG  ... Date_temp team_hist_vs  opp_hist_vs  probs_win  probs_not_win  \\\n",
       "3555     0  ...  20240401     1.000000          0.0   0.775194       0.272712   \n",
       "3556     1  ...  20240401     0.833333          1.0   0.458716       0.589234   \n",
       "3557     1  ...  20240401     0.500000          1.6   0.348432       0.699511   \n",
       "3558     0  ...  20240401     0.333333          1.8   0.230947       0.816006   \n",
       "3559     0  ...  20240401     1.666667          1.4   0.833333       0.217517   \n",
       "\n",
       "      team_form_team  team_shots  opp_shots  team_shots_target  \\\n",
       "3555        5.000000   16.266667  13.133333           5.600000   \n",
       "3556        3.466667    9.533333  12.333333           3.200000   \n",
       "3557        2.000000    9.866667  13.133333           2.733333   \n",
       "3558        3.400000   14.266667  10.066667           3.466667   \n",
       "3559        5.000000   13.600000  10.066667           5.466667   \n",
       "\n",
       "      opp_shots_target  \n",
       "3555          3.933333  \n",
       "3556          4.400000  \n",
       "3557          3.000000  \n",
       "3558          4.600000  \n",
       "3559          2.533333  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 2098,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2099,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    \n",
    "        'Div', 'Date_temp', 'Time', 'Team_ID', 'Opp_ID', 'Ref_ID', 'FTR', \n",
    "        'team_hist_vs', \n",
    "        #'opp_hist_vs',\n",
    "\n",
    "        #'probs_win',         \n",
    "        #'probs_not_win', \n",
    "        \n",
    "        #'team_form_team', \n",
    "        #'team_form_opp',\n",
    "         \n",
    "        #'team_shots', 'opp_shots',\n",
    "        #'team_shots_target', 'opp_shots_target',\n",
    "\n",
    "        #'team_avg_games', 'opp_avg_games',\n",
    "\n",
    "        'AvgH', 'AvgD', 'AvgA'\n",
    "         \n",
    "         \n",
    "         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2124,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_44816\\1902893630.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sort the DataFrame by Date_temp and separate the 200 most recent matches into a validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Date_temp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Drop the 'Date_temp' column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Date_temp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7169\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7170\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7171\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7173\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7175\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vermeerbergenj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1906\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1910\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_temp'"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by Date_temp and separate the 200 most recent matches into a validation set\n",
    "df.sort_values('Date_temp', inplace=True)\n",
    "\n",
    "# Drop the 'Date_temp' column\n",
    "df.drop('Date_temp', axis=1, inplace=True)\n",
    "\n",
    "df_val = df.tail(200)\n",
    "df = df.iloc[:-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X and y\n",
    "X = df.drop('FTR', axis=1)\n",
    "y = df['FTR']\n",
    "\n",
    "X.columns = [re.sub(r'[<]', '_st_', str(col)) for col in X.columns]\n",
    "X.columns = [re.sub(r'[>]', '_gt_', str(col)) for col in X.columns]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3984, 996)"
      ]
     },
     "execution_count": 2102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-45 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-45 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-45 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-45 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-45 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-45 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-45 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-45 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-45 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-45 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-45 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-45 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-45 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-45 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-45 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-45 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-45 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-45 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-45 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-45\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[(&#x27;target_encoder&#x27;,\n",
       "                                              TargetEncoder()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;xgb&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        &#x27;xgb__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC825C290&gt;,\n",
       "                                        &#x27;xgb__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC82E5D60&gt;,\n",
       "                                        &#x27;xgb__scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023D8E8515B0&gt;,\n",
       "                                        &#x27;xgb__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC825F320&gt;},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-221\" type=\"checkbox\" ><label for=\"sk-estimator-id-221\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[(&#x27;target_encoder&#x27;,\n",
       "                                              TargetEncoder()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;xgb&#x27;,\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        &#x27;xgb__reg_alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC825C290&gt;,\n",
       "                                        &#x27;xgb__reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC82E5D60&gt;,\n",
       "                                        &#x27;xgb__scale_pos_weight&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023D8E8515B0&gt;,\n",
       "                                        &#x27;xgb__subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC825F320&gt;},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-222\" type=\"checkbox\" ><label for=\"sk-estimator-id-222\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;target_encoder&#x27;, TargetEncoder()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-223\" type=\"checkbox\" ><label for=\"sk-estimator-id-223\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">TargetEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>TargetEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-224\" type=\"checkbox\" ><label for=\"sk-estimator-id-224\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-225\" type=\"checkbox\" ><label for=\"sk-estimator-id-225\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=Pipeline(steps=[('target_encoder',\n",
       "                                              TargetEncoder()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('xgb',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None...\n",
       "                                        'xgb__reg_alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC825C290>,\n",
       "                                        'xgb__reg_lambda': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC82E5D60>,\n",
       "                                        'xgb__scale_pos_weight': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023D8E8515B0>,\n",
       "                                        'xgb__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000023EC825F320>},\n",
       "                   random_state=42, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 2103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('target_encoder', TargetEncoder()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters\n",
    "\n",
    "param_distributions = {\n",
    "\n",
    "    'target_encoder__smoothing': randint(1, 100),\n",
    "    'xgb__n_estimators': randint(100, 1000),\n",
    "    'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.6),\n",
    "    'xgb__subsample': uniform(0.3, 0.7),\n",
    "    'xgb__colsample_bytree': uniform(0.3, 0.7),\n",
    "    'xgb__gamma': randint(0, 5),\n",
    "    'xgb__reg_alpha': uniform(0, 1),\n",
    "    'xgb__reg_lambda': uniform(0, 1),\n",
    "    'xgb__min_child_weight': randint(1, 10),\n",
    "    'xgb__scale_pos_weight': uniform(0.5, 1.5)\n",
    "  \n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=5,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63       531\n",
      "           1       0.58      0.60      0.59       465\n",
      "\n",
      "    accuracy                           0.61       996\n",
      "   macro avg       0.61      0.61      0.61       996\n",
      "weighted avg       0.61      0.61      0.61       996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(classification_report(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_windows(X, window_size, step):\n",
    "    n_samples = len(X)\n",
    "    windows = []\n",
    "    for start_idx in range(0, n_samples - window_size + 1, step):\n",
    "        end_idx = start_idx + window_size\n",
    "        if end_idx > n_samples:\n",
    "            break  # Avoid going beyond the dataset\n",
    "        train_indices = list(range(max(0, start_idx - window_size), start_idx))\n",
    "        test_indices = list(range(start_idx, end_idx))\n",
    "        windows.append((train_indices, test_indices))\n",
    "    return windows\n",
    "\n",
    "negative_count = len(df[df['FTR'] == 0])\n",
    "positive_count = len(df[df['FTR'] == 1])\n",
    "scale_pos_weight_value = negative_count / positive_count\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_dist = {\n",
    "    \n",
    "    'xgb__clf__max_depth': [1,2,3],\n",
    "    'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "    'rf__clf__max_depth': [None, 4, 6],\n",
    "    'rf__clf__min_samples_split': [2, 5],\n",
    "    'rf__clf__min_samples_leaf': [1, 2],\n",
    "    'rf__clf__bootstrap': [True, False],\n",
    "    'rf__clf__n_estimators': [50, 100, 200],\n",
    "\n",
    "    'lr__clf__C': [0.1, 1, 10],  # Inverse of regularization strength; smaller values specify stronger regularization.\n",
    "    'lr__clf__penalty': ['l1', 'l2', 'elasticnet'],  # Specify the norm of the penalty.\n",
    "    'lr__clf__solver': ['saga'],  # Algorithm to use in the optimization problem, 'saga' supports all penalties.\n",
    "    'lr__clf__l1_ratio': [0.5],  # The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'.\n",
    "\n",
    "    'cat__clf__depth': [1,2,3,4],\n",
    "    'cat__clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'cat__clf__iterations': [50, 100, 200],\n",
    "    'cat__clf__l2_leaf_reg': [1, 3, 5],\n",
    "\n",
    "    'gb__clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gb__clf__n_estimators': [50, 100, 200],\n",
    "    'gb__clf__max_depth': [3, 5, 7],\n",
    "    'gb__clf__min_samples_split': [2, 5],\n",
    "    'gb__clf__min_samples_leaf': [1, 2],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "param_test = {\n",
    "    \n",
    "    'xgb__clf__max_depth': [1,2,3],\n",
    "    'xgb__clf__learning_rate': [0.001, 0.01, 0.1],\n",
    "    'xgb__clf__lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'xgb__clf__alpha': [0, 0.5, 1],  # L1 regularization term on weights\n",
    "    'xgb__clf__n_estimators': [1, 5, 100],\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a custom scoring function\n",
    "def xgb_early_stopping_score(y, estimator, X, y_true, sample_weight=None):\n",
    "    \"\"\"\n",
    "    Custom scorer that uses early stopping.\n",
    "    \"\"\"\n",
    "    # Split X into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_true, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit with early stopping\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    estimator.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_set, verbose=False)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = estimator.predict(X_val)\n",
    "    \n",
    "    # Return the F1 score\n",
    "    return f1_score(y_val, y_pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Training Data Shape: (996, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 100, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.01, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 0.5}\n",
      "Precision: 0.6455823293172691\n",
      "\n",
      "Iteration 2 Training Data Shape: (1992, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 5, 'xgb__clf__max_depth': 2, 'xgb__clf__learning_rate': 0.1, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 1}\n",
      "Precision: 0.6937751004016064\n",
      "\n",
      "Iteration 3 Training Data Shape: (2988, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 5, 'xgb__clf__max_depth': 2, 'xgb__clf__learning_rate': 0.1, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 1}\n",
      "Precision: 0.6646586345381527\n",
      "\n",
      "Iteration 4 Training Data Shape: (3984, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 100, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.01, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 0.5}\n",
      "Precision: 0.6616465863453815\n",
      "\n",
      "Iteration 5 Training Data Shape: (4980, 9)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Best Parameters: {'xgb__clf__n_estimators': 100, 'xgb__clf__max_depth': 3, 'xgb__clf__learning_rate': 0.01, 'xgb__clf__lambda': 2, 'xgb__clf__alpha': 0.5}\n",
      "Precision: 0.6716867469879518\n",
      "\n",
      "\n",
      "Best F1 Score: 0.6402640264026402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       540\n",
      "           1       0.64      0.64      0.64       456\n",
      "\n",
      "    accuracy                           0.67       996\n",
      "   macro avg       0.67      0.67      0.67       996\n",
      "weighted avg       0.67      0.67      0.67       996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the F1 score for the '1' class\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_f1_params = None\n",
    "best_window_size = None\n",
    "best_precision = 0\n",
    "best_model = None \n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Define your dataset\n",
    "# Assuming 'df' is your DataFrame\n",
    "#X = train_set.drop(columns=['result'])\n",
    "#y = train_set['result']\n",
    "\n",
    "# Make the custom scorer\n",
    "custom_scorer = make_scorer(xgb_early_stopping_score, greater_is_better=True, needs_proba=False, X=X, y_true=y)\n",
    "\n",
    "# Set the window_size and step to 5% of the dataset\n",
    "window_size = int(len(X) * 0.2)\n",
    "step = int(len(X) * 0.2)\n",
    "\n",
    "# Initialize an empty list to store precision scores\n",
    "precision_scores = []\n",
    "\n",
    "# Initialize an empty dataframe to store misclassified samples\n",
    "misclassified_samples = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "# Generate windows\n",
    "window_splits = generate_sliding_windows(X, window_size, step)\n",
    "\n",
    "# Initialize training indices with the first window\n",
    "train_end_index = window_size\n",
    "\n",
    "# Iterate over each sliding window\n",
    "for i, (train_index, test_index) in enumerate(window_splits):\n",
    "\n",
    "    # Update training indices to include the next window\n",
    "    train_index = list(range(train_end_index))\n",
    "    train_end_index += window_size\n",
    "\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"Iteration {i+1} Training Data Shape: {X_train.shape}\")\n",
    "\n",
    "    # Combine misclassified samples from previous iterations with current training data\n",
    "    if not misclassified_samples.empty:\n",
    "        X_train_combined = pd.concat([X_train, misclassified_samples[X_train.columns]], axis=0)\n",
    "        y_train_combined = pd.concat([y_train, misclassified_samples['FTR']], axis=0)\n",
    "    else:\n",
    "        X_train_combined = X_train\n",
    "        y_train_combined = y_train\n",
    "\n",
    "    # Calculate misclassification frequency\n",
    "    misclassified_freq = y_train_combined.value_counts(normalize=True)\n",
    "\n",
    "    # Define class weights based on misclassification frequency\n",
    "    class_weights = {0: 1, 1: max(0.6, 1 - misclassified_freq.get(1, 0.5))}  # Adjust dynamically to penalize misclassification of class 1 more heavily\n",
    "\n",
    "    # Define pipelines for each classifier with SMOTE and TargetEncoder\n",
    "    pipeline_xgb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', XGBClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    pipeline_gb = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', GradientBoostingClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for logistic regression\n",
    "    pipeline_lr = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for catboost classifier\n",
    "    pipeline_cat = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', CatBoostClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # pipeline for random forest\n",
    "    pipeline_rf = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', RandomForestClassifier(random_state=42, verbose=0))\n",
    "    ])\n",
    "\n",
    "    # LightGBM pipeline\n",
    "    pipeline_lgbm = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LGBMClassifier(random_state=42, force_col_wise='true', verbose=0))\n",
    "    ])\n",
    "\n",
    "    # Adaboost pipeline\n",
    "    pipeline_ada = ImbPipeline([\n",
    "        ('target_encoder', TargetEncoder()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', AdaBoostClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Combine them into an ensemble classifier\n",
    "    ensemble_clf = VotingClassifier(estimators=[\n",
    "        ('xgb', pipeline_xgb),\n",
    "        #('gb', pipeline_gb),\n",
    "        ('lr', pipeline_lr),\n",
    "        #('cat', pipeline_cat),\n",
    "        #\n",
    "        #('rf', pipeline_rf),\n",
    "        #('lgbm', pipeline_lgbm),\n",
    "        ('ada', pipeline_ada)\n",
    "    ], voting='soft')\n",
    "\n",
    "    # Setup RandomizedSearchCV\n",
    "    clf = RandomizedSearchCV(\n",
    "        estimator=ensemble_clf,\n",
    "        param_distributions=param_test,\n",
    "        n_iter=5,\n",
    "        scoring=f1_scorer,\n",
    "        cv=TimeSeriesSplit(n_splits=3),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )  \n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = clf.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    # Use the best estimator\n",
    "    best_pipe = clf.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    y_proba = best_pipe.predict_proba(X_test)\n",
    "\n",
    "    # Apply threshold\n",
    "    threshold = 0.5  # You can adjust this threshold as needed\n",
    "    y_pred = (y_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    current_f1_score = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    if current_f1_score > best_f1_score:\n",
    "        best_f1_score = current_f1_score\n",
    "        best_f1_params = clf.best_params_\n",
    "        #best_model = clf.best_estimator_ \n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    best_model = clf.best_estimator_ \n",
    "\n",
    "    # Calculate precision score\n",
    "    precision = np.mean(y_test == y_pred)\n",
    "    precision_scores.append(precision)\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    print()\n",
    "\n",
    "# Print the best F1 score and its corresponding parameters\n",
    "print()\n",
    "print(\"Best F1 Score:\", best_f1_score)\n",
    "\n",
    "# print the classification report of the best model on the full dataset\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Put the target column to the front\n",
    "cols = list(corr.columns)\n",
    "cols.insert(0, cols.pop(cols.index('FTR')))\n",
    "corr = corr.loc[cols, cols]\n",
    "\n",
    "# Plot the correlation matrix\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=2)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "importances = search.best_estimator_.named_steps['xgb'].feature_importances_\n",
    "features = X_train.columns\n",
    "importances_df = pd.DataFrame({'features': features, 'importances': importances})\n",
    "importances_df = importances_df.sort_values('importances', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "#plt.figure(figsize=(10, 8))\n",
    "#sns.barplot(x='importances', y='features', data=importances_df)\n",
    "#plt.title('Feature Importances')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        60\n",
      "           1       0.88      0.38      0.53        40\n",
      "\n",
      "    accuracy                           0.73       100\n",
      "   macro avg       0.79      0.67      0.67       100\n",
      "weighted avg       0.77      0.73      0.70       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.589\n",
    "\n",
    "# Apply the best estimator to the validation set\n",
    "y_val_proba = best_model.predict_proba(df_val.drop(columns=['FTR']))\n",
    "y_val_pred = (y_val_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(df_val['FTR'], y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prediction  Actual\n",
      "3514           0       0\n",
      "256            1       1\n",
      "3513           1       1\n",
      "2007           0       0\n",
      "3517           0       1\n",
      "...          ...     ...\n",
      "3558           0       0\n",
      "3555           1       1\n",
      "3556           0       0\n",
      "3557           0       0\n",
      "3559           1       1\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the predictions and actual results of the validation set side by side\n",
    "predictions = pd.DataFrame({'Prediction': y_val_pred, 'Actual': df_val['FTR']})\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        60\n",
      "           1       0.48      0.70      0.57        40\n",
      "\n",
      "    accuracy                           0.58       100\n",
      "   macro avg       0.60      0.60      0.58       100\n",
      "weighted avg       0.62      0.58      0.58       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the model to the validation set\n",
    "y_val = df_val['FTR']\n",
    "X_val = df_val.drop('FTR', axis=1)\n",
    "y_pred = search.predict(X_val)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
